{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16HPmkfhYZn4fuhpGKto63nt0nbPOgwEb",
      "authorship_tag": "ABX9TyPzZDJ5tFF/aQvvdPKgyYDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prodramp/DeepWorks/blob/main/TopicModelling/BaseWorkshop/Topic_Modeling_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Topic Modeling Workshop Steps:**\n",
        "\n",
        "- LDA modeling in Python using the Gensim implementation\n",
        "- Not original work, Get more info in the following README.md\n",
        "  - https://github.com/prodramp/DeepWorks/tree/main/TopicModelling/BaseWorkshop"
      ],
      "metadata": {
        "id": "2Z55ZCuBL-s8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latent Dirichlet Allocation (LDA):\n",
        "\n",
        "- LDA states that each document in a corpus is a combination of a fixed number of topics. \n",
        "- A topic has a probability of generating various words, where the words are all the observed words in the corpus. \n",
        "- These ‘hidden’ topics are then surfaced based on the likelihood of word co-occurrence"
      ],
      "metadata": {
        "id": "R1qUaKnxSWfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U__yabbuSRYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Use Cases:**\n",
        "- Getting the gist of a super large text content\n",
        "- Uncovering the hidden context or structure of a collection of text \n",
        "- User can get an idea about what the given super large collection of text is"
      ],
      "metadata": {
        "id": "-xaAex2jMCem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Steps:**\n",
        "1. Reading and Loading Data\n",
        "   - NIPS Papers as our source dataset\n",
        "2. Data Preparation\n",
        "   - Select required columns\n",
        "   - Remove Punctuations marks\n",
        "3. Exploratory Data Analysis\n",
        "   - Word Cloud\n",
        "   - Document Term Matrix\n",
        "4. Data Modeling and tokenization \n",
        "   - Stop words removal\n",
        "   - bigram and trigram\n",
        "   - Vectorization and Tokenization\n",
        "5. Model Building\n",
        "   - LDA Modelling\n",
        "6. Model Evaluations\n",
        "   - Model Visualization\n",
        "   - Coherance Score"
      ],
      "metadata": {
        "id": "26avmpWCCn6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset used in this workshop**\n",
        "- NIPS papers\n",
        "  - https://www.kaggle.com/datasets/benhamner/nips-papers"
      ],
      "metadata": {
        "id": "YZJ91hIg4VCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Dupg64ZnGfyB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/devdata/nips-papers/papers.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXC8NZF85DqH",
        "outputId": "d8ff3669-dac3-4a12-fbc4-25b08e459e2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/devdata/nips-papers/papers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RNJd5g5Z5CuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers_location = '/content/drive/MyDrive/devdata/nips-papers/papers.csv'"
      ],
      "metadata": {
        "id": "yjIdHqEY6KZy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d8xghQ-f4Cea"
      },
      "outputs": [],
      "source": [
        "papers = pd.read_csv(papers_location)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "QAklurJq4nqL",
        "outputId": "10aa22bb-aece-482c-ccef-bf79b88c6f3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  year                                              title  \\\n",
              "6570  6943  2017      Certified Defenses for Data Poisoning Attacks   \n",
              "2099  2906  2005                            Correlated Topic Models   \n",
              "6533   691  1992  Intersecting regions: The Key to combinatorial...   \n",
              "1119  2020  2001  On Discriminative vs. Generative Classifiers: ...   \n",
              "6357  6750  2017  Learning Affinity via Spatial Propagation Netw...   \n",
              "5657  6119  2016  Maximizing Influence in an Ising Network: A Me...   \n",
              "2506  3273  2007  An in-silico Neural Model of Dynamic Routing t...   \n",
              "5791   624  1992  Analogy-- Watershed or Waterloo? Structural al...   \n",
              "3949  4575  2012    Selective Labeling via Error Bound Minimization   \n",
              "2794  3533  2008  A ``Shape Aware'' Model for semi-supervised Le...   \n",
              "\n",
              "     event_type                                           pdf_name  \\\n",
              "6570     Poster  6943-certified-defenses-for-data-poisoning-att...   \n",
              "2099        NaN                   2906-correlated-topic-models.pdf   \n",
              "6533        NaN  691-intersecting-regions-the-key-to-combinator...   \n",
              "1119        NaN  2020-on-discriminative-vs-generative-classifie...   \n",
              "6357     Poster  6750-learning-affinity-via-spatial-propagation...   \n",
              "5657     Poster  6119-maximizing-influence-in-an-ising-network-...   \n",
              "2506        NaN  3273-an-in-silico-neural-model-of-dynamic-rout...   \n",
              "5791        NaN  624-analogy-watershed-or-waterloo-structural-a...   \n",
              "3949        NaN  4575-selective-labeling-via-error-bound-minimi...   \n",
              "2794        NaN  3533-a-shape-aware-model-for-semi-supervised-l...   \n",
              "\n",
              "                                               abstract  \\\n",
              "6570  Machine learning systems trained on user-provi...   \n",
              "2099                                   Abstract Missing   \n",
              "6533                                   Abstract Missing   \n",
              "1119                                   Abstract Missing   \n",
              "6357  In this paper, we propose a spatial propagatio...   \n",
              "5657  Influence maximization in social networks has ...   \n",
              "2506                                   Abstract Missing   \n",
              "5791                                   Abstract Missing   \n",
              "3949  In many practical machine learning problems, t...   \n",
              "2794  Integrating semantic and syntactic analysis is...   \n",
              "\n",
              "                                             paper_text  \n",
              "6570  Certified Defenses for Data Poisoning Attacks\\...  \n",
              "2099  Correlated Topic Models\\n\\nDavid M. Blei\\nDepa...  \n",
              "6533  Intersecting regions: The key to combinatorial...  \n",
              "1119  On Discriminative vs. Generative\\nclassifiers:...  \n",
              "6357  Learning Affinity via Spatial Propagation Netw...  \n",
              "5657  Maximizing Influence in an Ising Network:\\nA M...  \n",
              "2506  An in-silico Neural Model of Dynamic Routing\\n...  \n",
              "5791  Analogy--Watershed or Waterloo?\\nStructural al...  \n",
              "3949  Selective Labeling via Error Bound Minimizatio...  \n",
              "2794  A ?Shape Aware? Model for semi-supervised\\nLea...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8f7fc04-efa1-416b-9242-ed4a9d4b308a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6570</th>\n",
              "      <td>6943</td>\n",
              "      <td>2017</td>\n",
              "      <td>Certified Defenses for Data Poisoning Attacks</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6943-certified-defenses-for-data-poisoning-att...</td>\n",
              "      <td>Machine learning systems trained on user-provi...</td>\n",
              "      <td>Certified Defenses for Data Poisoning Attacks\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2099</th>\n",
              "      <td>2906</td>\n",
              "      <td>2005</td>\n",
              "      <td>Correlated Topic Models</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2906-correlated-topic-models.pdf</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Correlated Topic Models\\n\\nDavid M. Blei\\nDepa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6533</th>\n",
              "      <td>691</td>\n",
              "      <td>1992</td>\n",
              "      <td>Intersecting regions: The Key to combinatorial...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>691-intersecting-regions-the-key-to-combinator...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Intersecting regions: The key to combinatorial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>2020</td>\n",
              "      <td>2001</td>\n",
              "      <td>On Discriminative vs. Generative Classifiers: ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-on-discriminative-vs-generative-classifie...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>On Discriminative vs. Generative\\nclassifiers:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6357</th>\n",
              "      <td>6750</td>\n",
              "      <td>2017</td>\n",
              "      <td>Learning Affinity via Spatial Propagation Netw...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6750-learning-affinity-via-spatial-propagation...</td>\n",
              "      <td>In this paper, we propose a spatial propagatio...</td>\n",
              "      <td>Learning Affinity via Spatial Propagation Netw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5657</th>\n",
              "      <td>6119</td>\n",
              "      <td>2016</td>\n",
              "      <td>Maximizing Influence in an Ising Network: A Me...</td>\n",
              "      <td>Poster</td>\n",
              "      <td>6119-maximizing-influence-in-an-ising-network-...</td>\n",
              "      <td>Influence maximization in social networks has ...</td>\n",
              "      <td>Maximizing Influence in an Ising Network:\\nA M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2506</th>\n",
              "      <td>3273</td>\n",
              "      <td>2007</td>\n",
              "      <td>An in-silico Neural Model of Dynamic Routing t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3273-an-in-silico-neural-model-of-dynamic-rout...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>An in-silico Neural Model of Dynamic Routing\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>624</td>\n",
              "      <td>1992</td>\n",
              "      <td>Analogy-- Watershed or Waterloo? Structural al...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>624-analogy-watershed-or-waterloo-structural-a...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Analogy--Watershed or Waterloo?\\nStructural al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3949</th>\n",
              "      <td>4575</td>\n",
              "      <td>2012</td>\n",
              "      <td>Selective Labeling via Error Bound Minimization</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4575-selective-labeling-via-error-bound-minimi...</td>\n",
              "      <td>In many practical machine learning problems, t...</td>\n",
              "      <td>Selective Labeling via Error Bound Minimizatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2794</th>\n",
              "      <td>3533</td>\n",
              "      <td>2008</td>\n",
              "      <td>A ``Shape Aware'' Model for semi-supervised Le...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3533-a-shape-aware-model-for-semi-supervised-l...</td>\n",
              "      <td>Integrating semantic and syntactic analysis is...</td>\n",
              "      <td>A ?Shape Aware? Model for semi-supervised\\nLea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8f7fc04-efa1-416b-9242-ed4a9d4b308a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8f7fc04-efa1-416b-9242-ed4a9d4b308a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8f7fc04-efa1-416b-9242-ed4a9d4b308a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers.columns"
      ],
      "metadata": {
        "id": "N0aSyWIl6TAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two options to select the target data:\n",
        "1. Create a new dataframe using the selected columns\n",
        "2. Drop the not necessary or unrequired columns from the dataframe"
      ],
      "metadata": {
        "id": "VA4DNG-66Zs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers = papers.drop(columns=['id', 'event_type', 'pdf_name'], axis=1)"
      ],
      "metadata": {
        "id": "-ex7-O696YAW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Xe0SFp8s61tr",
        "outputId": "a700a86d-10a6-4df1-b725-48a5b71b3ce2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      year                                              title  \\\n",
              "0     1987  Self-Organization of Associative Database and ...   \n",
              "1     1987  A Mean Field Theory of Layer IV of Visual Cort...   \n",
              "2     1988  Storing Covariance by the Associative Long-Ter...   \n",
              "3     1994  Bayesian Query Construction for Neural Network...   \n",
              "4     1994  Neural Network Ensembles, Cross Validation, an...   \n",
              "...    ...                                                ...   \n",
              "7236  1994                Single Transistor Learning Synapses   \n",
              "7237  1994  Bias, Variance and the Combination of Least Sq...   \n",
              "7238  1994          A Real Time Clustering CMOS Neural Engine   \n",
              "7239  1994  Learning direction in global motion: two class...   \n",
              "7240  1994  Correlation and Interpolation Networks for Rea...   \n",
              "\n",
              "              abstract                                         paper_text  \n",
              "0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1     Abstract Missing  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2     Abstract Missing  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3     Abstract Missing  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4     Abstract Missing  Neural Network Ensembles, Cross\\nValidation, a...  \n",
              "...                ...                                                ...  \n",
              "7236  Abstract Missing  Single Transistor Learning Synapses\\n\\nPaul Ha...  \n",
              "7237  Abstract Missing  Bias, Variance and the Combination of\\nLeast S...  \n",
              "7238  Abstract Missing  A Real Time Clustering CMOS\\nNeural Engine\\nT....  \n",
              "7239  Abstract Missing  Learning direction in global motion: two\\nclas...  \n",
              "7240  Abstract Missing  Correlation and Interpolation Networks for\\nRe...  \n",
              "\n",
              "[7241 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9760079-7a6d-4f1a-a029-437e5b58c515\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>1994</td>\n",
              "      <td>Single Transistor Learning Synapses</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Single Transistor Learning Synapses\\n\\nPaul Ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7237</th>\n",
              "      <td>1994</td>\n",
              "      <td>Bias, Variance and the Combination of Least Sq...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bias, Variance and the Combination of\\nLeast S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7238</th>\n",
              "      <td>1994</td>\n",
              "      <td>A Real Time Clustering CMOS Neural Engine</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>A Real Time Clustering CMOS\\nNeural Engine\\nT....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>1994</td>\n",
              "      <td>Learning direction in global motion: two class...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Learning direction in global motion: two\\nclas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7240</th>\n",
              "      <td>1994</td>\n",
              "      <td>Correlation and Interpolation Networks for Rea...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Correlation and Interpolation Networks for\\nRe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7241 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9760079-7a6d-4f1a-a029-437e5b58c515')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9760079-7a6d-4f1a-a029-437e5b58c515 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9760079-7a6d-4f1a-a029-437e5b58c515');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Suggestion:**\n",
        "- If your machine has low resources you can randomly Select N documents \n",
        "- N = 1000\n",
        "- papers.sample(N) "
      ],
      "metadata": {
        "id": "pHsB7e6X64-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers = papers.sample(100)"
      ],
      "metadata": {
        "id": "7mylCXOu32p1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "wUH_jiCYdRyE",
        "outputId": "94b84171-d746-42d5-bbe8-c57aa7a5de86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      year                                              title  \\\n",
              "6632  1987  On the Power of Neural Networks for Solving Ha...   \n",
              "3726  2011  On the Completeness of First-Order Knowledge C...   \n",
              "1719  2004  Edge of Chaos Computation in Mixed-Mode VLSI -...   \n",
              "1722  2004  Instance-Specific Bayesian Model Averaging for...   \n",
              "3919  2012  A Simple and Practical Algorithm for Different...   \n",
              "2861  2008       Support Vector Machines with a Reject Option   \n",
              "3050  2009  fMRI-Based Inter-Subject Cortical Alignment Us...   \n",
              "1294  2002  Mismatch String Kernels for SVM Protein Classi...   \n",
              "246   1996  Learning Appearance Based Models: Mixtures of ...   \n",
              "3274  2010  Stability Approach to Regularization Selection...   \n",
              "\n",
              "                                               abstract  \\\n",
              "6632                                   Abstract Missing   \n",
              "3726  Probabilistic logics are receiving a lot of at...   \n",
              "1719                                   Abstract Missing   \n",
              "1722                                   Abstract Missing   \n",
              "3919  We present a new algorithm for differentially ...   \n",
              "2861  We consider the problem of binary classificati...   \n",
              "3050  The inter-subject alignment of functional MRI ...   \n",
              "1294                                   Abstract Missing   \n",
              "246                                    Abstract Missing   \n",
              "3274  A challenging problem in estimating high-dimen...   \n",
              "\n",
              "                                             paper_text  \n",
              "6632  137\\n\\nOn the Power of Neural Networks for\\nSo...  \n",
              "3726  On the Completeness of First-Order Knowledge\\n...  \n",
              "1719  Edge of Chaos Computation in\\nMixed-Mode VLSI ...  \n",
              "1722  Instance-Specific Bayesian Model\\nAveraging f ...  \n",
              "3919  A Simple and Practical Algorithm\\nfor Differen...  \n",
              "2861  Support Vector Machines with a Reject Option\\n...  \n",
              "3050  fMRI-Based Inter-Subject Cortical Alignment Us...  \n",
              "1294  Mismatch String Kernels for SVM Protein\\nClass...  \n",
              "246   Learning Appearance Based Models:\\nMixtures of...  \n",
              "3274  Stability Approach to Regularization Selection...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef8097c6-07ee-4938-9dc8-710ea49aa70a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6632</th>\n",
              "      <td>1987</td>\n",
              "      <td>On the Power of Neural Networks for Solving Ha...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>137\\n\\nOn the Power of Neural Networks for\\nSo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3726</th>\n",
              "      <td>2011</td>\n",
              "      <td>On the Completeness of First-Order Knowledge C...</td>\n",
              "      <td>Probabilistic logics are receiving a lot of at...</td>\n",
              "      <td>On the Completeness of First-Order Knowledge\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>2004</td>\n",
              "      <td>Edge of Chaos Computation in Mixed-Mode VLSI -...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Edge of Chaos Computation in\\nMixed-Mode VLSI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1722</th>\n",
              "      <td>2004</td>\n",
              "      <td>Instance-Specific Bayesian Model Averaging for...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Instance-Specific Bayesian Model\\nAveraging f ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3919</th>\n",
              "      <td>2012</td>\n",
              "      <td>A Simple and Practical Algorithm for Different...</td>\n",
              "      <td>We present a new algorithm for differentially ...</td>\n",
              "      <td>A Simple and Practical Algorithm\\nfor Differen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>2008</td>\n",
              "      <td>Support Vector Machines with a Reject Option</td>\n",
              "      <td>We consider the problem of binary classificati...</td>\n",
              "      <td>Support Vector Machines with a Reject Option\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>2009</td>\n",
              "      <td>fMRI-Based Inter-Subject Cortical Alignment Us...</td>\n",
              "      <td>The inter-subject alignment of functional MRI ...</td>\n",
              "      <td>fMRI-Based Inter-Subject Cortical Alignment Us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>2002</td>\n",
              "      <td>Mismatch String Kernels for SVM Protein Classi...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Mismatch String Kernels for SVM Protein\\nClass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>1996</td>\n",
              "      <td>Learning Appearance Based Models: Mixtures of ...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Learning Appearance Based Models:\\nMixtures of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3274</th>\n",
              "      <td>2010</td>\n",
              "      <td>Stability Approach to Regularization Selection...</td>\n",
              "      <td>A challenging problem in estimating high-dimen...</td>\n",
              "      <td>Stability Approach to Regularization Selection...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef8097c6-07ee-4938-9dc8-710ea49aa70a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef8097c6-07ee-4938-9dc8-710ea49aa70a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef8097c6-07ee-4938-9dc8-710ea49aa70a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Data Preperation :**\n",
        "## 2.1. Removing punctuations ## \n",
        "Cleaning original paper content by removing any punctuations as they are not needed for analysis and just adding weight to cause unnecessary processing."
      ],
      "metadata": {
        "id": "0HdN8cOO7LJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "tIxFsX3y7f2k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers['clean_text'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))"
      ],
      "metadata": {
        "id": "lFPTctNH7lTA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers['clean_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl-stAYa78Uu",
        "outputId": "0cdabe0d-38ac-43e4-bfd2-8963de3dacd3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2462    Fitted Q-iteration in continuous action-space ...\n",
              "4500    Efficient Online Inference for Bayesian\\nNonpa...\n",
              "5761    Diffusion-Convolutional Neural Networks\\nJames...\n",
              "2914    Hierarchical Mixture of Classification Experts...\n",
              "1008    FaceSync: A linear operator for measuring\\nsyn...\n",
              "                              ...                        \n",
              "2601    C O F I R ANK\\nMaximum Margin Matrix Factoriza...\n",
              "1691    Auction Mechanism Design for Multi-Robot\\nCoor...\n",
              "1374    Mean-Field Approach to a Probabilistic Model\\n...\n",
              "3626    t-divergence Based Approximate Inference\\nNan ...\n",
              "6632    137\\n\\nOn the Power of Neural Networks for\\nSo...\n",
              "Name: clean_text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. Removing Digits and all words with digits into it**\n"
      ],
      "metadata": {
        "id": "M7wNF_I_9rtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers['clean_text'] = papers['clean_text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"
      ],
      "metadata": {
        "id": "rO3MXUlL9zig"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.3. Lowercase all text:**\n",
        "- lowering the case will create a homogeneous text content for processing"
      ],
      "metadata": {
        "id": "3DEvTl3X7uKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "papers['clean_text'] = papers['clean_text'].map(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "IwgpDRdu73Qw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "papers['clean_text'].sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmBRuBEl7_it",
        "outputId": "3c356b39-1c8c-4776-bd35-a4e53f82027a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2428    psvm: parallelizing support vector machines\\no...\n",
              "6269    safe and nested subgame solving for\\nimperfect...\n",
              "259     blind separation of delayed and convolved\\nsou...\n",
              "2068    dynamic social network analysis using latent\\n...\n",
              "4759    graph clustering with missing data : convex\\na...\n",
              "3626    t-divergence based approximate inference\\nnan ...\n",
              "2544    colored maximum variance unfolding\\n\\nle song ...\n",
              "6367    destabilization and route to chaos\\nin neural ...\n",
              "899     a support vector method for clustering\\n\\nasab...\n",
              "6326    fixed-rank approximation of a\\npositive-semide...\n",
              "Name: clean_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X7w-eVWpDOfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Exploratory Data (Text) analysis:**\n",
        "- Word Cloud\n",
        "- Document Term Matrix"
      ],
      "metadata": {
        "id": "o2YpCDAn8NZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. Creating the word cloud (EDA)**"
      ],
      "metadata": {
        "id": "qd2pXP6__EuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "def create_word_cloud(target_df, column_name):\n",
        "  print('Joining all words into long text....')\n",
        "  full_text = ','.join(list(target_df[column_name].values))\n",
        "  wordcloud = WordCloud(background_color=\"black\", \n",
        "                        max_words=100,  # top 100 words in the\n",
        "                        contour_width=2, \n",
        "                        contour_color='yellow')\n",
        "  print('Creating word cloud')\n",
        "  wordcloud.generate(full_text)\n",
        "  return wordcloud"
      ],
      "metadata": {
        "id": "qnC29qqy8Krf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For 7240 records the text will be quite a large so this step may take some time to complete.\n",
        "wordcloud = create_word_cloud(papers, 'clean_text')\n",
        "wordcloud.to_image() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "EsPDla5f8131",
        "outputId": "7fcc2b8f-aa17-4096-9c5c-4bc97409fd34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joining all words into long text....\n",
            "Creating word cloud\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=400x200 at 0x7F5E55C8DC10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Document Term Matrix**\n",
        "\n",
        "- I am going to San Francisco.\n",
        "- I am not happy today.\n"
      ],
      "metadata": {
        "id": "CWXytjS9A0FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Document Term Matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def create_document_term_matrix(dataframe, column_name):\n",
        "  cv = CountVectorizer(analyzer='word')\n",
        "  data = cv.fit_transform(dataframe[column_name])\n",
        "  df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names_out())\n",
        "  df_dtm.index=dataframe.index\n",
        "  return df_dtm"
      ],
      "metadata": {
        "id": "uwHrg31wB_t_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm = create_document_term_matrix(papers, 'clean_text')"
      ],
      "metadata": {
        "id": "wX3_ySVIGJMa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "4iq8OUTg4EOt",
        "outputId": "20d59cf0-1761-459d-def4-eb07d092b1cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      __  ___  ____  ______  _______  ____c_  _e  _i  _in  _izm  ...  ztijk  \\\n",
              "3726   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "2701   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "1231   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "2631   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "246    0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "2462   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "3050   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "3202   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "3626   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "4625   0    0     0       0        0       0   0   0    0     0  ...      0   \n",
              "\n",
              "      ztlxd  ztlxt  zu  zuowei  zurich  zv  zx  zy  zz  \n",
              "3726      0      0   0       0       0   0   0   0   0  \n",
              "2701      0      0   0       0       0   0   0   0   0  \n",
              "1231      0      0   0       0       0   0   0   0   0  \n",
              "2631      0      0   0       0       0   0   0   0   0  \n",
              "246       0      0   0       0       0   0   0   0   0  \n",
              "2462      0      0   0       0       0   0   0   0   0  \n",
              "3050      0      0   0       0       0   0   0   0   0  \n",
              "3202      0      0   0       0       0   0   0   0   0  \n",
              "3626      0      0   0       0       0   0   0   0   0  \n",
              "4625      0      0   0       0       0   0   0   0   0  \n",
              "\n",
              "[10 rows x 16959 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6217c705-b108-45aa-a175-401eb9e24205\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__</th>\n",
              "      <th>___</th>\n",
              "      <th>____</th>\n",
              "      <th>______</th>\n",
              "      <th>_______</th>\n",
              "      <th>____c_</th>\n",
              "      <th>_e</th>\n",
              "      <th>_i</th>\n",
              "      <th>_in</th>\n",
              "      <th>_izm</th>\n",
              "      <th>...</th>\n",
              "      <th>ztijk</th>\n",
              "      <th>ztlxd</th>\n",
              "      <th>ztlxt</th>\n",
              "      <th>zu</th>\n",
              "      <th>zuowei</th>\n",
              "      <th>zurich</th>\n",
              "      <th>zv</th>\n",
              "      <th>zx</th>\n",
              "      <th>zy</th>\n",
              "      <th>zz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3726</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2701</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2631</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2462</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3202</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3626</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4625</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 16959 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6217c705-b108-45aa-a175-401eb9e24205')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6217c705-b108-45aa-a175-401eb9e24205 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6217c705-b108-45aa-a175-401eb9e24205');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Data Modeling and Tokenization**"
      ],
      "metadata": {
        "id": "DgeyJ-sSEmnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. Removing stop words and Lemmatization**"
      ],
      "metadata": {
        "id": "BvxaRy0d_ph7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Stopwords**\n",
        "- Text Classification\n",
        "  - Spam Filtering\n",
        "  - Language Classification\n",
        "  - Genre Classification\n",
        "- Caption Generation\n",
        "- Auto-Tag Generation\n",
        "- Topic Modeling\n",
        " \n",
        "**Avoid Stopword Removal**\n",
        "- Machine Translation\n",
        "- Language Modeling\n",
        "- Text Summarization\n",
        "- Question-Answering problems\n",
        "\n",
        "Source: https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/"
      ],
      "metadata": {
        "id": "jno1qoBSATvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1.1 Using gensim NLTK library for removing stop words ###"
      ],
      "metadata": {
        "id": "6_YLDS-Rn8m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk"
      ],
      "metadata": {
        "id": "qS4aMW5qoAfo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnPnPU8FoHAS",
        "outputId": "b3b5dbd7-26ec-4f02-d5a1-fd1f7c2853e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "3XBPqYtroJbv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['has', 'been', 're', 'com', 'edu', 'use'])"
      ],
      "metadata": {
        "id": "nb86XM8noSjn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you set deacc=True which will removes the punctuations\n",
        "def convert_sentences_to_words(sentences):\n",
        "    for sentence in sentences:        \n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
      ],
      "metadata": {
        "id": "gcQH45NTofzz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_all_stop_words(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) \n",
        "             if word not in stop_words] for doc in texts]"
      ],
      "metadata": {
        "id": "JOBuqFe6opsX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_list = papers.clean_text.values.tolist()"
      ],
      "metadata": {
        "id": "wk7JMqXPot1_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_to_list)\n",
        "# all 7241 lines are sentenses now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZtT2gBo8QI",
        "outputId": "32dba5ec-bc5e-49e8-8f3b-4d7f6562054c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "7_lLDZhX4USu",
        "outputId": "bd8b3218-ba5c-455f-d68e-e426efe10779"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fitted q-iteration in continuous action-space mdps\\n\\nandras antos\\ncomputer and automation research inst\\nof the hungarian academy of sciences\\nkende u - budapest  hungary\\nantos@sztakihu\\n\\nremi munos\\nsequel project-team inria lille\\n villeneuve dascq france\\nremimunos@inriafr\\n\\ncsaba szepesvari\\ndepartment of computing science\\nuniversity of alberta\\nedmonton   canada\\nszepesva@csualbertaca\\n\\nabstract\\nwe consider continuous state continuous action batch reinforcement learning\\nwhere the goal is to learn a good policy from a sufficiently rich trajectory generated by some policy we study a variant of fitted q-iteration where the greedy\\naction selection is replaced by searching for a policy in a restricted set of candidate policies by maximizing the average action values we provide a rigorous\\nanalysis of this algorithm proving what we believe is the first finite-time bound\\nfor value-function based algorithms for continuous state and action problems\\n\\n\\n\\npreliminaries\\n\\nwe will build on the results from [  ] and for this reason we use the same notation as these\\npapers the unattributed results cited in this section can be found in the book []\\na discounted mdp is defined by a quintuple (x  a p s ) where x is the (possible infinite)\\nstate space a is the set of actions p : x  a  m (x ) is the transition probability kernel with\\np (|x a) defining the next-state distribution upon taking action a from state x s(|x a) gives the\\ncorresponding distribution of immediate rewards and   ( ) is the discount factor here x is\\na measurable space and m (x ) denotes the set of all probability measures over x  the lebesguemeasure shall be denoted by  we start with the following mild assumption on the mdp:\\nassumption  (mdp regularity) x is a compact subset of the dx -dimensional euclidean space\\n max\\na is a compact subset of [a  a ]da  the random immediate\\nrewards are bounded by r\\nr\\nand that the expected immediate reward function r(x a) = rs(dr|x a) is uniformly bounded\\nby rmax : krk  rmax \\na policy determines the next action given the past observations here we shall deal with stationary\\n(markovian) policies which choose an action in a stochastic way based on the last observation only\\nthe value of a policy  when it is started from a state x is defined as the\\nexpected discounted\\nptotal\\n\\nreward that is encountered while the policy is executed: v  (x) = e [ t=  t rt | = x] here\\nrt  s(|xt  at ) is the reward received at time step t the state xt  evolves according to xt+ \\n\\nalso with: computer and automation research inst of the hungarian academy of sciences kende u\\n- budapest  hungary\\n\\n\\n\\n\\x0cp (|xt  at ) where at is sampled from the distribution determined\\nby  we use q : x  a  r\\np\\nto denote the action-value function of policy : q (x a) = e [ t=  t rt | = x  = a]\\nthe goal is to find a policy that attains the best possible values v  (x) = sup v  (x) at all states\\n\\nx  x  here v  is called the optimal value function and a policy   that satisfies v  (x) =\\n\\n\\n\\nv (x) for all x  x is called optimal the optimal action-value function q (x a) is q (x a) =\\nsup q (x a) we say that a (deterministic stationary) policy  is greedy wrt an action-value\\nfunction q  b(x  a) and we write  = \\n (; q) if for all x  x  (x)  argmaxaa q(x a)\\nunder mild technical assumptions such a greedy policy always exists any greedy policy wrt q\\n\\nis optimal for  : x  a we\\n a) by\\nr define its evaluation operator t : b(x  a)  b(x\\n\\n(t q)(x a) = r(x a) +  x q(y (y)) p (dy|x a) it is known that q = t q  further if\\nwer let the bellman operator t : b(x  a)  b(x  a) defined by (t q)(x a) = r(x a) +\\n x supba q(y b) p (dy|x a) then q = t q  it is known that v  and q are bounded by\\nrmax /(  ) just like q and v   for  : x  a the operator e  : b(x  a)  b(x ) is\\ndefined by (e  q)(x) = q(x (x)) while e : b(x  a)  b(x ) is defined by (eq)(x) =\\nsupaa q(x a)\\nthroughout the paper f  {f : x  a  r} will denote a subset of real-valued functions over\\nthe state-action space x  a and   ax will\\nr be a set of policies for   m (x ) and f : x  r\\np\\nmeasurable we let (for p  ) kf kp = x |f (x)|p (dx) we simply write kf k for kf  \\nr r\\n\\nfurther we extend kk to f by kf k = a x |f | (x a) d(x) da (a) where ra is the uniform\\ndistribution over a we shall use the shorthand notation f to denote the integral f (x)(dx) we\\ndenote the space of bounded measurable functions with domain x by b(x ) further the space of\\nmeasurable functions bounded by  < k <  shall be denoted by b(x ; k) we let kk denote\\nthe supremum norm\\n\\n\\n\\nfitted q-iteration with approximate policy maximization\\n\\nwe assume that we are given a finite trajectory {(xt  at  rt )}  generated by some stochastic\\nstationary policy b  called the behavior policy: at  b (|xt ) xt+  p (|xt  at ) rt \\ndef\\ns(|xt  at ) where b (|x) is a density with  = inf (xa)x a b (a|x) > \\nthe generic recipe for fitted q-iteration (fqi) [] is\\nqk+ = regress(dk (qk ))\\n\\n()\\n\\nwhere regress is an appropriate regression procedure and dk (qk ) is a dataset defining a regression\\nproblem in the form of a list of data-point pairs:\\nh\\n\\ni\\ndk (qk ) =\\n(xt  at ) rt +  max qk (xt+  b)\\n\\nba\\n\\n\\n\\nfitted q-iteration can be viewed as approximate value iteration applied to action-value functions\\nto see this note that value iteration would assign the value (t qk )(x a) = r(x a) +\\nr\\n maxba qk (y b) p (dy|x a) to qk+ (x a) [] now remember that the regression function for\\nthe jointly distributed random variables (z y ) is defined by the conditional expectation of y given\\nz: m(z) = e [y |z] since for any fixed function q e [rt +  maxba q(xt+  b)|xt  at ] =\\n(t q)(xt  at ) the regression function corresponding to the data dk (q) is indeed t q and hence if\\nfqi solved the regression problem defined by qk exactly it would simulate value iteration exactly\\nhowever this argument itself does not directly lead to a rigorous analysis of fqi: since qk is\\nobtained based on the data it is itself a random function hence after the first iteration the target\\nfunction in fqi becomes random furthermore this function depends on the same data that is used\\nto define the regression problem will fqi still work despite these issues to illustrate the potential\\ndifficulties consider a dataset where       xn is a sequence of independent random variables\\nwhich are all distributed uniformly at random in [ ] further let m be a random integer greater\\nthan n which is independent of the dataset (xt )n\\nt=  let u be another random variable uniformly\\ndistributed in [ ] now define the regression problem by yt = fmu (xt ) where fmu (x) =\\nsgn(sin( (x + u ))) then it is not hard to see that no matter how big n is no procedure can\\n\\n\\nsince the designer controls qk  we may assume that it is continuous hence the maximum exists\\n\\n\\n\\n\\x0cestimate the regression function fmu with a small error (in expectation or with high probability)\\neven if the procedure could exploit the knowledge of the specific form of fmu  on the other hand\\nif we restricted m to a finite range then the estimation problem could be solved successfully the\\nexample shows that if the complexity of the random functions defining the regression problem is\\nuncontrolled then successful estimation might be impossible\\namongst the many regression methods in this paper we have chosen to work with least-squares\\nmethods in this case equation () takes the form\\n\\n\\n\\nn\\nx\\n\\nq(xt  at )  rt +  max qk (xt+  b)\\nqk+ = argmin\\n\\n()\\nba\\nqf t= b (at |xt )\\nwe call this method the least-squares fitted q-iteration (lsfqi) method here we introduced the\\nweighting /b (at |xt ) since we do not want to give more weight to those actions that are preferred\\nby the behavior policy\\nbesides this weighting the only parameter of the method is the function set f this function set\\nshould be chosen carefully to keep a balance between the representation power and the number of\\nsamples as a specific example for f consider neural networks with some fixed architecture in\\nthis case the function set is generated by assigning weights in all possible ways to the neural net\\nthen the above minimization becomes the problem of tuning the weights another example is to use\\nlinearly parameterized function approximation methods with appropriately selected basis functions\\nin this case the weight tuning problem would be less demanding yet another possibility is to let f\\nbe an appropriate restriction of a reproducing kernel hilbert space (eg in a ball) in this case the\\ntraining procedure becomes similar to ls-svm training []\\nas indicated above the analysis of this algorithm is complicated by the fact that the new dataset\\nis defined in terms of the previous iterate which is already a function of the dataset another\\ncomplication is that the samples in a trajectory are in general correlated and that the bias introduced\\nby the imperfections of the approximation architecture may yield to an explosion of the error of the\\nprocedure as documented in a number of cases in eg []\\nnevertheless at least for finite action sets the tools developed in [  ] look suitable to show\\nthat under appropriate conditions these problems can be overcome if the function set is chosen in\\na judicious way however the results of these works would become essentially useless in the case\\nof an infinite number of actions since these previous bounds grow to infinity with the number of\\nactions actually we believe that this is not an artifact of the proof techniques of these works as\\nsuggested by the counterexample that involved random targets the following result elaborates this\\npoint further:\\nproposition  let f  b(x  a) then even if the pseudo-dimension of f is finite the fatshattering function of\\n\\n\\n\\nfmax\\n= vq : vq () = max q( a) q  f\\naa\\n\\n\\n\\ncan be infinite over ( /)\\n\\nwithout going into further details let us just note that the finiteness of the fat-shattering function is a\\nsufficient and necessary condition for learnability and the finiteness of the fat-shattering function is\\nimplied by the finiteness of the pseudo-dimension []the above proposition thus shows that without\\nimposing further special conditions on f the learning problem may become infeasible\\none possibility is of course to discretize the action space eg by using a uniform grid however if\\nthe action space has a really high dimensionality this approach becomes unfeasible (even enumerating  points could be impossible when da is large) therefore we prefer alternate solutions\\nanother possibility is to make the functions in f eg uniformly lipschitz in their state coordinates\\n\\nthen the same property will hold for functions in fmax\\nand hence by a classical result we can bound\\nthe capacity of this set (cf pp  of []) one potential problem with this approach is that\\nthis way it might be difficult to get a fine control of the capacity of the resulting set\\n\\nthe proof of this and the other results are given in the appendix available in the extended version of this\\npaper downloadable from http://halinriafr/inria-/en/\\n\\n\\n\\n\\x0cin the approach explored here we modify the fitted q-iteration algorithm by introducing a policy\\nset  and a search over this set for an approximately greedy policy in a sense that will be made\\nprecise in a minute our algorithm thus has four parameters: f  k   here f is as before \\nis a user-chosen set of policies (mappings from x to a) k is the number of iterations and  is an\\ninitial value function (a typical choice is   ) the algorithm computes a sequence of iterates\\n(qk  \\nk ) k =      k defined by the following equations:\\n\\n\\nqk+\\n\\nk+\\n\\n=\\n\\nargmax\\n\\n\\n=\\n\\nargmin\\n\\nn\\nx\\n\\nargmax\\n\\n\\n (xt  (xt ))\\n\\nt=\\n\\nqf\\n\\n=\\n\\nn\\nx\\n\\nt=\\nn\\nx\\n\\n\\n\\n\\n\\nq(xt  at )  rt + qk (xt+  \\nk (xt+ )) \\nb (at |xt )\\n\\n()\\n\\nqk+ (xt  (xt ))\\n\\n()\\n\\nt=\\n\\nthus () is similar to () while () defines the policy search problem the policy search will\\ngenerally be solved by a gradient procedure or some other appropriate method the cost of this step\\nwill be primarily determined by how well-behaving the iterates qk+ are in their action arguments\\nfor example if they were quadratic and if  was linear then the problem would be a quadratic\\noptimization problem however except for special  the action value functions will be more\\ncomplicated in which case this step can be expensive still this cost could be similar to that of\\nsearching for the maximizing actions for each t =      n if the approximately maximizing actions\\nare similar across similar states\\nthis algorithm which we could also call a fitted actor-critic algorithm will be shown to overcome\\nthe above mentioned complexity control problem provided that the complexity of  is controlled\\nappropriately indeed in this case the set of possible regression problems is determined by the set\\nf = { v : v () = q( ()) q  f    } \\nand the proof will rely on controlling the complexity of f by selecting f and  appropriately\\n\\n\\n\\n\\nthe main theoretical result\\noutline of the analysis\\n\\nin order to gain some insight into the behavior of the algorithm we provide a brief summary of its\\nerror analysis the main result will be presented subsequently for f q  f and a policy  we\\ndefine the tth td-error as follows:\\ndt (f ; q ) = rt + q(xt+  (xt+ ))  f (xt  at )\\nfurther we define the empirical loss function by\\nn\\nx\\n (f ; q )\\n n (f ; q ) = \\n\\nl\\nn t= (a)b (at |xt )\\n\\nwhere the normalization with (a) is introduced for mathematical convenience then () can be\\n n (f ; qk  \\nwritten compactly as qk+ = argminf f l\\nk )\\n n (f ; q ) is an\\nthe algorithm can then be motivated by the observation that for any f q and  l\\nunbiased estimate of\\ndef\\n\\nl(f ; q ) = kf  t  qk + l (q )\\n()\\nwhere the first term is the error we are interested in and the second term captures the variance of the\\nrandom samples:\\nz\\nl (q ) =\\ne [var [ + q(  ( ))|   = a]] da (a)\\na\\n\\nlinear quadratic regulation is such a nice case it is interesting to note that in this special case the obvious\\nchoices for f and  yield zero error in the limit as can be proven based on the main result of this paper\\n\\n\\n\\n\\x0ch\\ni\\n n (f ; q ) = l(f ; q )\\nthis result is stated formally by e l\\nsince the variance term in () is independent of f  argminf f l(f ; q )\\n=\\n\\n\\nargminf f kf  t qk  thus if \\nk were greedy wrt qk then argminf f l(f ; qk  \\nk ) =\\n\\nargminf f kf  t qk k  hence we can still think of the procedure as approximate value iteration\\nover the space of action-value functions projecting t qk using empirical risk minimization on the\\nspace f wrt kk distances in an approximate manner since \\nk is only approximately greedy we\\nwill have to deal with both the error coming from the approximate projection and the error coming\\nfrom the choice of \\nk  to make this clear we write the iteration in the form\\nqk+ = t k qk +  = t qk +  + (t k qk  t qk ) = t qk + k \\ndef\\n\\nwhere  is the error committed while computing t k qk   = t k qk  t qk is the error committed because the greedy policy is computed approximately and k =  +  is the total error of step\\nk hence in order to show that the procedure is well behaved one needs to show that both errors are\\ncontrolled and that when the errors are propagated through these equations the resulting error stays\\ncontrolled too since we are ultimately interested in the performance of the policy obtained we\\nwill also need to show that small action-value approximation errors yield small performance losses\\nfor these we need a number of assumptions that concern either the training data the mdp or the\\nfunction sets used for learning\\n\\n\\nassumptions\\n\\n\\n\\nassumptions on the training data\\n\\nwe shall assume that the data is rich is in a steady state and is fast-mixing where informally\\nmixing means that future depends weakly on the past\\nassumption  (sample path properties) assume that {(xt  at  rt )}t= is the sample path\\nof b  a stochastic stationary policy further assume that {xt } is strictly stationary (xt   \\nm (x )) and exponentially -mixing with the actual rate given by the parameters ( b ) we\\nfurther assume that the sampling policy b satisfies  = inf (xa)x a b (a|x) > \\nthe -mixing property will be used to establish tail inequalities for certain empirical \\nnote that the mixing coefficients do not need to be known in the case when no mixing condition is\\nsatisfied learning might be impossible to see this just consider the case when  =  =    =\\nxn  thus in this case the learner has many copies of the same random variable and successful\\ngeneralization is thus impossible we believe that the assumption that the process is in a steady state\\nis not essential for our result as when the process reaches its steady state quickly then (at the price\\nof a more involved proof) the result would still hold\\n\\n\\nassumptions on the mdp\\n\\nin order to prevent the uncontrolled growth of the errors as they are propagated through the updates\\nwe shall need some assumptions on the mdp a convenient assumption is the following one []:\\nassumption  (uniformly stochastic transitions) for all x  x and a  a assume that\\np (|x a) is absolutely continuous wrt  and the\\nderivative of p wrt  is bounded\\n\\n radon-nikodym\\ndef\\n dp (|xa) \\nuniformly with bound c : c = supxx aa  d  < +\\n\\n\\nnote that by the definition of measure differentiation assumption  means that p (|x a) \\nc () this assumption essentially requires the transitions to be noisy we will also prove (weaker)\\nresults under the following weaker assumption:\\n\\n\\nfor the definition of -mixing see eg []\\nwe say empirical process and empirical measure but note that in this work these are based on dependent (mixing) samples\\n\\n\\n\\n\\n\\x0cassumption  (discounted-average concentrability of future-state distributions) given \\n m   and an arbitrary sequence of stationary policies {m }  assume that the futuredef\\nstate distribution\\np  p    p m is absolutely continuous wrt  assume that c(m) =\\n\\n \\nm \\np\\ndef\\n\\n m  d(p pd p )  satisfies  m  c(m) < + we shall call c =\\n\\n\\n\\np\\np\\nmax (  )  m  c(m) (  )   m c(m) the discounted-average concentrability coefficient of the future-state distributions\\nthe number c(m) measures how much  can get amplified in m steps as compared to the reference\\ndistribution  hence in general we expect c(m) to grow with m in fact the condition that c is\\nfinite is a growth rate condition on c(m) thanks to discounting c is finite for a reasonably large\\nclass of systems (see the discussion in [])\\na related assumption is needed in the error analysis of the approximate greedy step of the algorithm:\\nassumption  (the random policy makes no peak-states) consider the distribution  = ( \\na )p which is the distribution of a state that results from sampling an initial state according to  and\\nthen executing an action which is selected uniformly at  then  = kd/dk < +\\nnote that under assumption  we have   c  this (very mild) assumption means that after\\none step starting from  and executing this random policy the probability of the next state being in\\na set is upper bounded by  -times the probability of the starting state being in the same set\\ndef\\n\\nbesides we assume that a has the following regularity property:\\nlet py(a h ) =\\n\\n\\n(  v)  rda + : ka        v/h    ka    / denote the pyramid with hight\\n\\ndef \\nh and base given by the ` -ball b(a ) =   rda : ka      centered at a\\nassumption  (regularity of the action space) we assume that there exists  >  such that for\\nall a  a for all  > \\n\\n\\n(py(a  )  (a  r))\\n(a)\\n min \\n\\n(py(a  ))\\n(b(a ))\\nfor example if a is an ` -ball itself then this assumption will be satisfied with  =  \\nwithout assuming any smoothness of the mdp learning in infinite mdps looks hard (see eg\\n[ ]) here we employ the following extra condition:\\nassumption  (lipschitzness of the mdp in the actions) assume that the transition probabilities\\nand rewards are lipschitz wrt their action variable ie there exists lp  lr >  such that for all\\n(x a  )  x  a  a and measurable set b of x \\n|p (b|x a)  p (b|x  )|  lp ka    \\n\\n|r(x a)  r(x  )|  lr ka    \\n\\nnote that previously lipschitzness wrt the state variables was used eg in [] to construct consistent planning algorithms\\n\\n\\nassumptions on the function sets used by the algorithm\\n\\nthese assumptions are less demanding since they are under the control of the user of the algorithm\\nhowever the choice of these function sets will greatly influence the performance of the algorithm\\nas we shall see it from the bounds the first assumption concerns the class f:\\nassumption  (lipschitzness of candidate action-value functions) assume f  b(x  a)\\nand that any elements of f is uniformly lipschitz in its action-argument in the sense that |q(x a) \\nq(x  )|  la ka    holds for any x  x    a and q  f \\n\\n\\nremember that a denotes the uniform distribution over the action set a\\n\\n\\n\\n\\x0cwe shall also need to control the capacity of our function sets we assume that the reader is familiar\\nwith the concept of vc- here we use the pseudo-dimension of function sets that builds\\nupon the concept of vc-dimension:\\ndefinition  (pseudo-dimension) the pseudo-dimension vf + of f is defined as the vcdimension of the subgraphs of functions in f (hence it is also called the vc-subgraph dimension of\\nf)\\nsince a is multidimensional we define v+ to be the sum of the pseudo-dimensions of the coordinate projection spaces k of :\\nv\\n\\n+\\n\\n=\\n\\nda\\nx\\n\\nv + \\n\\nk=\\n\\nk\\n\\nk = { k : x  r :  = (      k      da )   } \\n\\nnow we are ready to state our assumptions on our function sets:\\nassumption  (capacity of the function and policy sets) assume that f  b(x  a; qmax )\\nfor qmax >  and vf + < + also a  [a  a ]da and v+ < +\\nbesides their capacity one shall also control the approximation power of the function sets involved\\nlet us first consider the policy set  introduce\\ne (f ) = sup inf (eq  e  q)\\nqf \\n\\nnote that inf  (eq  e  q) measures the quality of approximating eq by e  q hence\\ne (f ) measures the worst-case approximation error of eq as q is changed within f this can\\nbe made small by choosing  large\\nanother related quantity is the one-step bellman-error of f wrt  this is defined as follows: for\\na fixed policy  the one-step bellman-error of f wrt t  is defined as\\n (f; ) = sup inf\\n  t  qk \\n\\nqf q f\\n\\ntaking again a pessimistic approach the one-step bellman-error of f is defined as\\n (f ) = sup  (f; )\\n\\n\\ntypically by increasing f  (f ) can be made smaller (this is discussed at some length in\\n[]) however it also holds for both  and f that making them bigger will increase their capacity\\n(pseudo-dimensions) which leads to an increase of the estimation errors hence f and  must be\\nselected to balance the approximation and estimation errors just like in supervised learning\\n\\n\\nthe main result\\n\\ntheorem  let k be a greedy policy wrt qk  ie k (x)  argmaxaa qk (x a) then\\nunder assumptions   and  for all  >  we have with probability at least   : given\\nassumption  (respectively ) kv   v k k (resp kv   v k  ) is bounded by\\n\\n\\n d +\\n+\\n\\n\\na\\n\\n\\n\\n(log n + log(k/))\\nk\\n\\n+\\n\\n\\nc  (f ) + e (f ) +\\n/\\n\\n\\nn\\n\\n\\na\\nwhere c depends on da  vf +  (v+ )dk=\\n   b  c (resp c )   la  lp lr   (a)  \\nk\\n\\n+\\n\\n max  and a  in particular c scales with v (da +)  where v =  + + v+\\nqmax  rmax  r\\nplays the role of the combined effective dimension of f and \\n\\nreaders not familiar with vc-dimension are suggested to consult a book such as the one by anthony and\\nbartlett []\\n\\n\\n\\n\\x0c\\n\\ndiscussion\\n\\nwe have presented what we believe is the first finite-time bounds for continuous-state and actionspace rl that uses value functions further this is the first analysis of fitted q-iteration an algorithm\\nthat has proved to be useful in a number of cases even when used with non-averagers for which no\\nprevious theoretical analysis existed (eg [ ]) in fact our main motivation was to show that\\nthere is a systematic way of making these algorithms work and to point at possible problem sources\\nthe same time we discussed why it can be difficult to make these algorithms work in practice we\\nsuggested that either the set of action-value candidates has to be carefully controlled (eg assuming\\nuniform lipschitzness wrt the state variables) or a policy search step is needed just like in actorcritic algorithms the bound in this paper is similar in many respects to a previous bound of a\\nbellman-residual minimization algorithm [] it looks that the techniques developed here can be\\nused to obtain results for that algorithm when it is applied to continuous action spaces finally\\nalthough we have not explored them here consistency results for fqi can be obtained from our\\nresults using standard methods like the methods of sieves we believe that the methods developed\\nhere will eventually lead to algorithms where the function approximation methods are chosen based\\non the data (similar to adaptive regression methods) so as to optimize performance which in our\\nopinion is one of the biggest open questions in rl currently we are exploring this possibility\\nacknowledgments\\nandras antos would like to acknowledge support for this project from the hungarian academy of sciences\\n(bolyai fellowship) csaba szepesvari greatly acknowledges the support received from the alberta ingenuity\\nfund nserc the computer and automation research institute of the hungarian academy of sciences\\n\\nreferences\\n[] a antos cs szepesvari and r munos learning near-optimal policies with bellman-residual minimization based fitted policy iteration and a single sample path in colt- pages  \\n[] a antos cs szepesvari and r munos learning near-optimal policies with bellman-residual minimization based fitted policy iteration and a single sample path machine learning  (accepted)\\n[] a antos cs szepesvari and r munos value-iteration based fitted policy iteration: learning with a\\nsingle trajectory in ieee adprl pages  \\n[] d p bertsekas and se shreve stochastic optimal control (the discrete time case) academic press\\nnew york \\n[] d ernst p geurts and l wehenkel tree-based batch mode reinforcement learning journal of machine\\nlearning research : \\n[] rs sutton and ag barto reinforcement learning: an introduction bradford book mit press \\n[] n cristianini and j shawe-taylor an introduction to support vector machines (and other kernel-based\\nlearning methods) cambridge university press \\n[] ja boyan and aw moore generalization in reinforcement learning: safely approximating the value\\nfunction in nips- pages  \\n[] pl bartlett pm long and rc williamson fat-shattering and the learnability of real-valued functions\\njournal of computer and system sciences : \\n[] an kolmogorov and vm tihomirov -entropy and -capacity of sets in functional space american\\nmathematical society translations (): \\n[] r munos and cs szepesvari finite time bounds for sampling based fitted value iteration technical\\nreport computer and automation research institute of the hungarian academy of sciences kende u\\n- budapest  hungary \\n[] ay ng and m jordan pegasus: a policy search method for large mdps and pomdps in proceedings of the  conference in uncertainty in artificial intelligence pages  \\n[] pl bartlett and a tewari sample complexity of policy search with known dynamics in nips- mit\\npress \\n[] m anthony and p l bartlett neural network learning: theoretical foundations cambridge university\\npress \\n[] m riedmiller neural fitted q iteration  first experiences with a data efficient neural reinforcement\\nlearning method in  european conference on machine learning pages  \\n[] s kalyanakrishnan and p stone batch reinforcement learning in a complex domain in aamas-\\n\\n\\n\\n\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_words = list(convert_sentences_to_words(text_to_list))"
      ],
      "metadata": {
        "id": "H3B5VPNNo7p3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_as_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15epgDTUpT1A",
        "outputId": "b1fc9174-9c43-4233-ff4e-dbb5f253d65c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_as_words[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnSudT1a4MRt",
        "outputId": "e7dfa435-fbac-446a-cc63-aca8873e6d2c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fitted', 'iteration', 'in', 'continuous', 'action', 'space', 'mdps', 'andras', 'antos', 'computer', 'and', 'automation', 'research', 'inst', 'of', 'the', 'hungarian', 'academy', 'of', 'sciences', 'kende', 'budapest', 'hungary', 'antos', 'sztakihu', 'remi', 'munos', 'sequel', 'project', 'team', 'inria', 'lille', 'villeneuve', 'dascq', 'france', 'remimunos', 'inriafr', 'csaba', 'szepesvari', 'department', 'of', 'computing', 'science', 'university', 'of', 'alberta', 'edmonton', 'canada', 'szepesva', 'csualbertaca', 'abstract', 'we', 'consider', 'continuous', 'state', 'continuous', 'action', 'batch', 'reinforcement', 'learning', 'where', 'the', 'goal', 'is', 'to', 'learn', 'good', 'policy', 'from', 'sufficiently', 'rich', 'trajectory', 'generated', 'by', 'some', 'policy', 'we', 'study', 'variant', 'of', 'fitted', 'iteration', 'where', 'the', 'greedy', 'action', 'selection', 'is', 'replaced', 'by', 'searching', 'for', 'policy', 'in', 'restricted', 'set', 'of', 'candidate', 'policies', 'by', 'maximizing', 'the', 'average', 'action', 'values', 'we', 'provide', 'rigorous', 'analysis', 'of', 'this', 'algorithm', 'proving', 'what', 'we', 'believe', 'is', 'the', 'first', 'finite', 'time', 'bound', 'for', 'value', 'function', 'based', 'algorithms', 'for', 'continuous', 'state', 'and', 'action', 'problems', 'preliminaries', 'we', 'will', 'build', 'on', 'the', 'results', 'from', 'and', 'for', 'this', 'reason', 'we', 'use', 'the', 'same', 'notation', 'as', 'these', 'papers', 'the', 'unattributed', 'results', 'cited', 'in', 'this', 'section', 'can', 'be', 'found', 'in', 'the', 'book', 'discounted', 'mdp', 'is', 'defined', 'by', 'quintuple', 'where', 'is', 'the', 'possible', 'infinite', 'state', 'space', 'is', 'the', 'set', 'of', 'actions', 'is', 'the', 'transition', 'probability', 'kernel', 'with', 'defining', 'the', 'next', 'state', 'distribution', 'upon', 'taking', 'action', 'from', 'state', 'gives', 'the', 'corresponding', 'distribution', 'of', 'immediate', 'rewards', 'and', 'is', 'the', 'discount', 'factor', 'here', 'is', 'measurable', 'space', 'and', 'denotes', 'the', 'set', 'of', 'all', 'probability', 'measures', 'over', 'the', 'lebesguemeasure', 'shall', 'be', 'denoted', 'by', 'we', 'start', 'with', 'the', 'following', 'mild', 'assumption', 'on', 'the', 'mdp', 'assumption', 'mdp', 'regularity', 'is', 'compact', 'subset', 'of', 'the', 'dx', 'dimensional', 'euclidean', 'space', 'max', 'is', 'compact', 'subset', 'of', 'da', 'the', 'random', 'immediate', 'rewards', 'are', 'bounded', 'by', 'and', 'that', 'the', 'expected', 'immediate', 'reward', 'function', 'rs', 'dr', 'is', 'uniformly', 'bounded', 'by', 'rmax', 'krk', 'rmax', 'policy', 'determines', 'the', 'next', 'action', 'given', 'the', 'past', 'observations', 'here', 'we', 'shall', 'deal', 'with', 'stationary', 'markovian', 'policies', 'which', 'choose', 'an', 'action', 'in', 'stochastic', 'way', 'based', 'on', 'the', 'last', 'observation', 'only', 'the', 'value', 'of', 'policy', 'when', 'it', 'is', 'started', 'from', 'state', 'is', 'defined', 'as', 'the', 'expected', 'discounted', 'ptotal', 'reward', 'that', 'is', 'encountered', 'while', 'the', 'policy', 'is', 'executed', 'rt', 'here', 'rt', 'xt', 'at', 'is', 'the', 'reward', 'received', 'at', 'time', 'step', 'the', 'state', 'xt', 'evolves', 'according', 'to', 'xt', 'also', 'with', 'computer', 'and', 'automation', 'research', 'inst', 'of', 'the', 'hungarian', 'academy', 'of', 'sciences', 'kende', 'budapest', 'hungary', 'xt', 'at', 'where', 'at', 'is', 'sampled', 'from', 'the', 'distribution', 'determined', 'by', 'we', 'use', 'to', 'denote', 'the', 'action', 'value', 'function', 'of', 'policy', 'rt', 'the', 'goal', 'is', 'to', 'find', 'policy', 'that', 'attains', 'the', 'best', 'possible', 'values', 'sup', 'at', 'all', 'states', 'here', 'is', 'called', 'the', 'optimal', 'value', 'function', 'and', 'policy', 'that', 'satisfies', 'for', 'all', 'is', 'called', 'optimal', 'the', 'optimal', 'action', 'value', 'function', 'is', 'sup', 'we', 'say', 'that', 'deterministic', 'stationary', 'policy', 'is', 'greedy', 'wrt', 'an', 'action', 'value', 'function', 'and', 'we', 'write', 'if', 'for', 'all', 'argmaxaa', 'under', 'mild', 'technical', 'assumptions', 'such', 'greedy', 'policy', 'always', 'exists', 'any', 'greedy', 'policy', 'wrt', 'is', 'optimal', 'for', 'we', 'by', 'define', 'its', 'evaluation', 'operator', 'dy', 'it', 'is', 'known', 'that', 'further', 'if', 'wer', 'let', 'the', 'bellman', 'operator', 'defined', 'by', 'supba', 'dy', 'then', 'it', 'is', 'known', 'that', 'and', 'are', 'bounded', 'by', 'rmax', 'just', 'like', 'and', 'for', 'the', 'operator', 'is', 'defined', 'by', 'while', 'is', 'defined', 'by', 'eq', 'supaa', 'throughout', 'the', 'paper', 'will', 'denote', 'subset', 'of', 'real', 'valued', 'functions', 'over', 'the', 'state', 'action', 'space', 'and', 'ax', 'will', 'be', 'set', 'of', 'policies', 'for', 'and', 'measurable', 'we', 'let', 'for', 'kf', 'kp', 'dx', 'we', 'simply', 'write', 'kf', 'for', 'kf', 'further', 'we', 'extend', 'kk', 'to', 'by', 'kf', 'da', 'where', 'ra', 'is', 'the', 'uniform', 'distribution', 'over', 'we', 'shall', 'use', 'the', 'shorthand', 'notation', 'to', 'denote', 'the', 'integral', 'dx', 'we', 'denote', 'the', 'space', 'of', 'bounded', 'measurable', 'functions', 'with', 'domain', 'by', 'further', 'the', 'space', 'of', 'measurable', 'functions', 'bounded', 'by', 'shall', 'be', 'denoted', 'by', 'we', 'let', 'kk', 'denote', 'the', 'supremum', 'norm', 'fitted', 'iteration', 'with', 'approximate', 'policy', 'maximization', 'we', 'assume', 'that', 'we', 'are', 'given', 'finite', 'trajectory', 'xt', 'at', 'rt', 'generated', 'by', 'some', 'stochastic', 'stationary', 'policy', 'called', 'the', 'behavior', 'policy', 'at', 'xt', 'xt', 'xt', 'at', 'rt', 'def', 'xt', 'at', 'where', 'is', 'density', 'with', 'inf', 'xa', 'the', 'generic', 'recipe', 'for', 'fitted', 'iteration', 'fqi', 'is', 'qk', 'regress', 'dk', 'qk', 'where', 'regress', 'is', 'an', 'appropriate', 'regression', 'procedure', 'and', 'dk', 'qk', 'is', 'dataset', 'defining', 'regression', 'problem', 'in', 'the', 'form', 'of', 'list', 'of', 'data', 'point', 'pairs', 'dk', 'qk', 'xt', 'at', 'rt', 'max', 'qk', 'xt', 'ba', 'fitted', 'iteration', 'can', 'be', 'viewed', 'as', 'approximate', 'value', 'iteration', 'applied', 'to', 'action', 'value', 'functions', 'to', 'see', 'this', 'note', 'that', 'value', 'iteration', 'would', 'assign', 'the', 'value', 'qk', 'maxba', 'qk', 'dy', 'to', 'qk', 'now', 'remember', 'that', 'the', 'regression', 'function', 'for', 'the', 'jointly', 'distributed', 'random', 'variables', 'is', 'defined', 'by', 'the', 'conditional', 'expectation', 'of', 'given', 'since', 'for', 'any', 'fixed', 'function', 'rt', 'maxba', 'xt', 'xt', 'at', 'xt', 'at', 'the', 'regression', 'function', 'corresponding', 'to', 'the', 'data', 'dk', 'is', 'indeed', 'and', 'hence', 'if', 'fqi', 'solved', 'the', 'regression', 'problem', 'defined', 'by', 'qk', 'exactly', 'it', 'would', 'simulate', 'value', 'iteration', 'exactly', 'however', 'this', 'argument', 'itself', 'does', 'not', 'directly', 'lead', 'to', 'rigorous', 'analysis', 'of', 'fqi', 'since', 'qk', 'is', 'obtained', 'based', 'on', 'the', 'data', 'it', 'is', 'itself', 'random', 'function', 'hence', 'after', 'the', 'first', 'iteration', 'the', 'target', 'function', 'in', 'fqi', 'becomes', 'random', 'furthermore', 'this', 'function', 'depends', 'on', 'the', 'same', 'data', 'that', 'is', 'used', 'to', 'define', 'the', 'regression', 'problem', 'will', 'fqi', 'still', 'work', 'despite', 'these', 'issues', 'to', 'illustrate', 'the', 'potential', 'difficulties', 'consider', 'dataset', 'where', 'xn', 'is', 'sequence', 'of', 'independent', 'random', 'variables', 'which', 'are', 'all', 'distributed', 'uniformly', 'at', 'random', 'in', 'further', 'let', 'be', 'random', 'integer', 'greater', 'than', 'which', 'is', 'independent', 'of', 'the', 'dataset', 'xt', 'let', 'be', 'another', 'random', 'variable', 'uniformly', 'distributed', 'in', 'now', 'define', 'the', 'regression', 'problem', 'by', 'yt', 'fmu', 'xt', 'where', 'fmu', 'sgn', 'sin', 'then', 'it', 'is', 'not', 'hard', 'to', 'see', 'that', 'no', 'matter', 'how', 'big', 'is', 'no', 'procedure', 'can', 'since', 'the', 'designer', 'controls', 'qk', 'we', 'may', 'assume', 'that', 'it', 'is', 'continuous', 'hence', 'the', 'maximum', 'exists', 'estimate', 'the', 'regression', 'function', 'fmu', 'with', 'small', 'error', 'in', 'expectation', 'or', 'with', 'high', 'probability', 'even', 'if', 'the', 'procedure', 'could', 'exploit', 'the', 'knowledge', 'of', 'the', 'specific', 'form', 'of', 'fmu', 'on', 'the', 'other', 'hand', 'if', 'we', 'restricted', 'to', 'finite', 'range', 'then', 'the', 'estimation', 'problem', 'could', 'be', 'solved', 'successfully', 'the', 'example', 'shows', 'that', 'if', 'the', 'complexity', 'of', 'the', 'random', 'functions', 'defining', 'the', 'regression', 'problem', 'is', 'uncontrolled', 'then', 'successful', 'estimation', 'might', 'be', 'impossible', 'amongst', 'the', 'many', 'regression', 'methods', 'in', 'this', 'paper', 'we', 'have', 'chosen', 'to', 'work', 'with', 'least', 'squares', 'methods', 'in', 'this', 'case', 'equation', 'takes', 'the', 'form', 'xt', 'at', 'rt', 'max', 'qk', 'xt', 'qk', 'argmin', 'ba', 'qf', 'at', 'xt', 'we', 'call', 'this', 'method', 'the', 'least', 'squares', 'fitted', 'iteration', 'lsfqi', 'method', 'here', 'we', 'introduced', 'the', 'weighting', 'at', 'xt', 'since', 'we', 'do', 'not', 'want', 'to', 'give', 'more', 'weight', 'to', 'those', 'actions', 'that', 'are', 'preferred', 'by', 'the', 'behavior', 'policy', 'besides', 'this', 'weighting', 'the', 'only', 'parameter', 'of', 'the', 'method', 'is', 'the', 'function', 'set', 'this', 'function', 'set', 'should', 'be', 'chosen', 'carefully', 'to', 'keep', 'balance', 'between', 'the', 'representation', 'power', 'and', 'the', 'number', 'of', 'samples', 'as', 'specific', 'example', 'for', 'consider', 'neural', 'networks', 'with', 'some', 'fixed', 'architecture', 'in', 'this', 'case', 'the', 'function', 'set', 'is', 'generated', 'by', 'assigning', 'weights', 'in', 'all', 'possible', 'ways', 'to', 'the', 'neural', 'net', 'then', 'the', 'above', 'minimization', 'becomes', 'the', 'problem', 'of', 'tuning', 'the', 'weights', 'another', 'example', 'is', 'to', 'use', 'linearly', 'parameterized', 'function', 'approximation', 'methods', 'with', 'appropriately', 'selected', 'basis', 'functions', 'in', 'this', 'case', 'the', 'weight', 'tuning', 'problem', 'would', 'be', 'less', 'demanding', 'yet', 'another', 'possibility', 'is', 'to', 'let', 'be', 'an', 'appropriate', 'restriction', 'of', 'reproducing', 'kernel', 'hilbert', 'space', 'eg', 'in', 'ball', 'in', 'this', 'case', 'the', 'training', 'procedure', 'becomes', 'similar', 'to', 'ls', 'svm', 'training', 'as', 'indicated', 'above', 'the', 'analysis', 'of', 'this', 'algorithm', 'is', 'complicated', 'by', 'the', 'fact', 'that', 'the', 'new', 'dataset', 'is', 'defined', 'in', 'terms', 'of', 'the', 'previous', 'iterate', 'which', 'is', 'already', 'function', 'of', 'the', 'dataset', 'another', 'complication', 'is', 'that', 'the', 'samples', 'in', 'trajectory', 'are', 'in', 'general', 'correlated', 'and', 'that', 'the', 'bias', 'introduced', 'by', 'the', 'imperfections', 'of', 'the', 'approximation', 'architecture', 'may', 'yield', 'to', 'an', 'explosion', 'of', 'the', 'error', 'of', 'the', 'procedure', 'as', 'documented', 'in', 'number', 'of', 'cases', 'in', 'eg', 'nevertheless', 'at', 'least', 'for', 'finite', 'action', 'sets', 'the', 'tools', 'developed', 'in', 'look', 'suitable', 'to', 'show', 'that', 'under', 'appropriate', 'conditions', 'these', 'problems', 'can', 'be', 'overcome', 'if', 'the', 'function', 'set', 'is', 'chosen', 'in', 'judicious', 'way', 'however', 'the', 'results', 'of', 'these', 'works', 'would', 'become', 'essentially', 'useless', 'in', 'the', 'case', 'of', 'an', 'infinite', 'number', 'of', 'actions', 'since', 'these', 'previous', 'bounds', 'grow', 'to', 'infinity', 'with', 'the', 'number', 'of', 'actions', 'actually', 'we', 'believe', 'that', 'this', 'is', 'not', 'an', 'artifact', 'of', 'the', 'proof', 'techniques', 'of', 'these', 'works', 'as', 'suggested', 'by', 'the', 'counterexample', 'that', 'involved', 'random', 'targets', 'the', 'following', 'result', 'elaborates', 'this', 'point', 'further', 'proposition', 'let', 'then', 'even', 'if', 'the', 'pseudo', 'dimension', 'of', 'is', 'finite', 'the', 'fatshattering', 'function', 'of', 'fmax', 'vq', 'vq', 'max', 'aa', 'can', 'be', 'infinite', 'over', 'without', 'going', 'into', 'further', 'details', 'let', 'us', 'just', 'note', 'that', 'the', 'finiteness', 'of', 'the', 'fat', 'shattering', 'function', 'is', 'sufficient', 'and', 'necessary', 'condition', 'for', 'learnability', 'and', 'the', 'finiteness', 'of', 'the', 'fat', 'shattering', 'function', 'is', 'implied', 'by', 'the', 'finiteness', 'of', 'the', 'pseudo', 'dimension', 'the', 'above', 'proposition', 'thus', 'shows', 'that', 'without', 'imposing', 'further', 'special', 'conditions', 'on', 'the', 'learning', 'problem', 'may', 'become', 'infeasible', 'one', 'possibility', 'is', 'of', 'course', 'to', 'discretize', 'the', 'action', 'space', 'eg', 'by', 'using', 'uniform', 'grid', 'however', 'if', 'the', 'action', 'space', 'has', 'really', 'high', 'dimensionality', 'this', 'approach', 'becomes', 'unfeasible', 'even', 'enumerating', 'points', 'could', 'be', 'impossible', 'when', 'da', 'is', 'large', 'therefore', 'we', 'prefer', 'alternate', 'solutions', 'another', 'possibility', 'is', 'to', 'make', 'the', 'functions', 'in', 'eg', 'uniformly', 'lipschitz', 'in', 'their', 'state', 'coordinates', 'then', 'the', 'same', 'property', 'will', 'hold', 'for', 'functions', 'in', 'fmax', 'and', 'hence', 'by', 'classical', 'result', 'we', 'can', 'bound', 'the', 'capacity', 'of', 'this', 'set', 'cf', 'pp', 'of', 'one', 'potential', 'problem', 'with', 'this', 'approach', 'is', 'that', 'this', 'way', 'it', 'might', 'be', 'difficult', 'to', 'get', 'fine', 'control', 'of', 'the', 'capacity', 'of', 'the', 'resulting', 'set', 'the', 'proof', 'of', 'this', 'and', 'the', 'other', 'results', 'are', 'given', 'in', 'the', 'appendix', 'available', 'in', 'the', 'extended', 'version', 'of', 'this', 'paper', 'downloadable', 'from', 'http', 'halinriafr', 'inria', 'en', 'in', 'the', 'approach', 'explored', 'here', 'we', 'modify', 'the', 'fitted', 'iteration', 'algorithm', 'by', 'introducing', 'policy', 'set', 'and', 'search', 'over', 'this', 'set', 'for', 'an', 'approximately', 'greedy', 'policy', 'in', 'sense', 'that', 'will', 'be', 'made', 'precise', 'in', 'minute', 'our', 'algorithm', 'thus', 'has', 'four', 'parameters', 'here', 'is', 'as', 'before', 'is', 'user', 'chosen', 'set', 'of', 'policies', 'mappings', 'from', 'to', 'is', 'the', 'number', 'of', 'iterations', 'and', 'is', 'an', 'initial', 'value', 'function', 'typical', 'choice', 'is', 'the', 'algorithm', 'computes', 'sequence', 'of', 'iterates', 'qk', 'defined', 'by', 'the', 'following', 'equations', 'qk', 'argmax', 'argmin', 'argmax', 'xt', 'xt', 'qf', 'xt', 'at', 'rt', 'qk', 'xt', 'xt', 'at', 'xt', 'qk', 'xt', 'xt', 'thus', 'is', 'similar', 'to', 'while', 'defines', 'the', 'policy', 'search', 'problem', 'the', 'policy', 'search', 'will', 'generally', 'be', 'solved', 'by', 'gradient', 'procedure', 'or', 'some', 'other', 'appropriate', 'method', 'the', 'cost', 'of', 'this', 'step', 'will', 'be', 'primarily', 'determined', 'by', 'how', 'well', 'behaving', 'the', 'iterates', 'qk', 'are', 'in', 'their', 'action', 'arguments', 'for', 'example', 'if', 'they', 'were', 'quadratic', 'and', 'if', 'was', 'linear', 'then', 'the', 'problem', 'would', 'be', 'quadratic', 'optimization', 'problem', 'however', 'except', 'for', 'special', 'the', 'action', 'value', 'functions', 'will', 'be', 'more', 'complicated', 'in', 'which', 'case', 'this', 'step', 'can', 'be', 'expensive', 'still', 'this', 'cost', 'could', 'be', 'similar', 'to', 'that', 'of', 'searching', 'for', 'the', 'maximizing', 'actions', 'for', 'each', 'if', 'the', 'approximately', 'maximizing', 'actions', 'are', 'similar', 'across', 'similar', 'states', 'this', 'algorithm', 'which', 'we', 'could', 'also', 'call', 'fitted', 'actor', 'critic', 'algorithm', 'will', 'be', 'shown', 'to', 'overcome', 'the', 'above', 'mentioned', 'complexity', 'control', 'problem', 'provided', 'that', 'the', 'complexity', 'of', 'is', 'controlled', 'appropriately', 'indeed', 'in', 'this', 'case', 'the', 'set', 'of', 'possible', 'regression', 'problems', 'is', 'determined', 'by', 'the', 'set', 'and', 'the', 'proof', 'will', 'rely', 'on', 'controlling', 'the', 'complexity', 'of', 'by', 'selecting', 'and', 'appropriately', 'the', 'main', 'theoretical', 'result', 'outline', 'of', 'the', 'analysis', 'in', 'order', 'to', 'gain', 'some', 'insight', 'into', 'the', 'behavior', 'of', 'the', 'algorithm', 'we', 'provide', 'brief', 'summary', 'of', 'its', 'error', 'analysis', 'the', 'main', 'result', 'will', 'be', 'presented', 'subsequently', 'for', 'and', 'policy', 'we', 'define', 'the', 'tth', 'td', 'error', 'as', 'follows', 'dt', 'rt', 'xt', 'xt', 'xt', 'at', 'further', 'we', 'define', 'the', 'empirical', 'loss', 'function', 'by', 'at', 'xt', 'where', 'the', 'normalization', 'with', 'is', 'introduced', 'for', 'mathematical', 'convenience', 'then', 'can', 'be', 'qk', 'written', 'compactly', 'as', 'qk', 'argminf', 'is', 'an', 'the', 'algorithm', 'can', 'then', 'be', 'motivated', 'by', 'the', 'observation', 'that', 'for', 'any', 'and', 'unbiased', 'estimate', 'of', 'def', 'kf', 'qk', 'where', 'the', 'first', 'term', 'is', 'the', 'error', 'we', 'are', 'interested', 'in', 'and', 'the', 'second', 'term', 'captures', 'the', 'variance', 'of', 'the', 'random', 'samples', 'var', 'da', 'linear', 'quadratic', 'regulation', 'is', 'such', 'nice', 'case', 'it', 'is', 'interesting', 'to', 'note', 'that', 'in', 'this', 'special', 'case', 'the', 'obvious', 'choices', 'for', 'and', 'yield', 'zero', 'error', 'in', 'the', 'limit', 'as', 'can', 'be', 'proven', 'based', 'on', 'the', 'main', 'result', 'of', 'this', 'paper', 'this', 'result', 'is', 'stated', 'formally', 'by', 'since', 'the', 'variance', 'term', 'in', 'is', 'independent', 'of', 'argminf', 'argminf', 'kf', 'qk', 'thus', 'if', 'were', 'greedy', 'wrt', 'qk', 'then', 'argminf', 'qk', 'argminf', 'kf', 'qk', 'hence', 'we', 'can', 'still', 'think', 'of', 'the', 'procedure', 'as', 'approximate', 'value', 'iteration', 'over', 'the', 'space', 'of', 'action', 'value', 'functions', 'projecting', 'qk', 'using', 'empirical', 'risk', 'minimization', 'on', 'the', 'space', 'wrt', 'kk', 'distances', 'in', 'an', 'approximate', 'manner', 'since', 'is', 'only', 'approximately', 'greedy', 'we', 'will', 'have', 'to', 'deal', 'with', 'both', 'the', 'error', 'coming', 'from', 'the', 'approximate', 'projection', 'and', 'the', 'error', 'coming', 'from', 'the', 'choice', 'of', 'to', 'make', 'this', 'clear', 'we', 'write', 'the', 'iteration', 'in', 'the', 'form', 'qk', 'qk', 'qk', 'qk', 'qk', 'qk', 'def', 'where', 'is', 'the', 'error', 'committed', 'while', 'computing', 'qk', 'qk', 'qk', 'is', 'the', 'error', 'committed', 'because', 'the', 'greedy', 'policy', 'is', 'computed', 'approximately', 'and', 'is', 'the', 'total', 'error', 'of', 'step', 'hence', 'in', 'order', 'to', 'show', 'that', 'the', 'procedure', 'is', 'well', 'behaved', 'one', 'needs', 'to', 'show', 'that', 'both', 'errors', 'are', 'controlled', 'and', 'that', 'when', 'the', 'errors', 'are', 'propagated', 'through', 'these', 'equations', 'the', 'resulting', 'error', 'stays', 'controlled', 'too', 'since', 'we', 'are', 'ultimately', 'interested', 'in', 'the', 'performance', 'of', 'the', 'policy', 'obtained', 'we', 'will', 'also', 'need', 'to', 'show', 'that', 'small', 'action', 'value', 'approximation', 'errors', 'yield', 'small', 'performance', 'losses', 'for', 'these', 'we', 'need', 'number', 'of', 'assumptions', 'that', 'concern', 'either', 'the', 'training', 'data', 'the', 'mdp', 'or', 'the', 'function', 'sets', 'used', 'for', 'learning', 'assumptions', 'assumptions', 'on', 'the', 'training', 'data', 'we', 'shall', 'assume', 'that', 'the', 'data', 'is', 'rich', 'is', 'in', 'steady', 'state', 'and', 'is', 'fast', 'mixing', 'where', 'informally', 'mixing', 'means', 'that', 'future', 'depends', 'weakly', 'on', 'the', 'past', 'assumption', 'sample', 'path', 'properties', 'assume', 'that', 'xt', 'at', 'rt', 'is', 'the', 'sample', 'path', 'of', 'stochastic', 'stationary', 'policy', 'further', 'assume', 'that', 'xt', 'is', 'strictly', 'stationary', 'xt', 'and', 'exponentially', 'mixing', 'with', 'the', 'actual', 'rate', 'given', 'by', 'the', 'parameters', 'we', 'further', 'assume', 'that', 'the', 'sampling', 'policy', 'satisfies', 'inf', 'xa', 'the', 'mixing', 'property', 'will', 'be', 'used', 'to', 'establish', 'tail', 'inequalities', 'for', 'certain', 'empirical', 'note', 'that', 'the', 'mixing', 'coefficients', 'do', 'not', 'need', 'to', 'be', 'known', 'in', 'the', 'case', 'when', 'no', 'mixing', 'condition', 'is', 'satisfied', 'learning', 'might', 'be', 'impossible', 'to', 'see', 'this', 'just', 'consider', 'the', 'case', 'when', 'xn', 'thus', 'in', 'this', 'case', 'the', 'learner', 'has', 'many', 'copies', 'of', 'the', 'same', 'random', 'variable', 'and', 'successful', 'generalization', 'is', 'thus', 'impossible', 'we', 'believe', 'that', 'the', 'assumption', 'that', 'the', 'process', 'is', 'in', 'steady', 'state', 'is', 'not', 'essential', 'for', 'our', 'result', 'as', 'when', 'the', 'process', 'reaches', 'its', 'steady', 'state', 'quickly', 'then', 'at', 'the', 'price', 'of', 'more', 'involved', 'proof', 'the', 'result', 'would', 'still', 'hold', 'assumptions', 'on', 'the', 'mdp', 'in', 'order', 'to', 'prevent', 'the', 'uncontrolled', 'growth', 'of', 'the', 'errors', 'as', 'they', 'are', 'propagated', 'through', 'the', 'updates', 'we', 'shall', 'need', 'some', 'assumptions', 'on', 'the', 'mdp', 'convenient', 'assumption', 'is', 'the', 'following', 'one', 'assumption', 'uniformly', 'stochastic', 'transitions', 'for', 'all', 'and', 'assume', 'that', 'is', 'absolutely', 'continuous', 'wrt', 'and', 'the', 'derivative', 'of', 'wrt', 'is', 'bounded', 'radon', 'nikodym', 'def', 'dp', 'xa', 'uniformly', 'with', 'bound', 'supxx', 'aa', 'note', 'that', 'by', 'the', 'definition', 'of', 'measure', 'differentiation', 'assumption', 'means', 'that', 'this', 'assumption', 'essentially', 'requires', 'the', 'transitions', 'to', 'be', 'noisy', 'we', 'will', 'also', 'prove', 'weaker', 'results', 'under', 'the', 'following', 'weaker', 'assumption', 'for', 'the', 'definition', 'of', 'mixing', 'see', 'eg', 'we', 'say', 'empirical', 'process', 'and', 'empirical', 'measure', 'but', 'note', 'that', 'in', 'this', 'work', 'these', 'are', 'based', 'on', 'dependent', 'mixing', 'samples', 'assumption', 'discounted', 'average', 'concentrability', 'of', 'future', 'state', 'distributions', 'given', 'and', 'an', 'arbitrary', 'sequence', 'of', 'stationary', 'policies', 'assume', 'that', 'the', 'futuredef', 'state', 'distribution', 'is', 'absolutely', 'continuous', 'wrt', 'assume', 'that', 'def', 'pd', 'satisfies', 'we', 'shall', 'call', 'max', 'the', 'discounted', 'average', 'concentrability', 'coefficient', 'of', 'the', 'future', 'state', 'distributions', 'the', 'number', 'measures', 'how', 'much', 'can', 'get', 'amplified', 'in', 'steps', 'as', 'compared', 'to', 'the', 'reference', 'distribution', 'hence', 'in', 'general', 'we', 'expect', 'to', 'grow', 'with', 'in', 'fact', 'the', 'condition', 'that', 'is', 'finite', 'is', 'growth', 'rate', 'condition', 'on', 'thanks', 'to', 'discounting', 'is', 'finite', 'for', 'reasonably', 'large', 'class', 'of', 'systems', 'see', 'the', 'discussion', 'in', 'related', 'assumption', 'is', 'needed', 'in', 'the', 'error', 'analysis', 'of', 'the', 'approximate', 'greedy', 'step', 'of', 'the', 'algorithm', 'assumption', 'the', 'random', 'policy', 'makes', 'no', 'peak', 'states', 'consider', 'the', 'distribution', 'which', 'is', 'the', 'distribution', 'of', 'state', 'that', 'results', 'from', 'sampling', 'an', 'initial', 'state', 'according', 'to', 'and', 'then', 'executing', 'an', 'action', 'which', 'is', 'selected', 'uniformly', 'at', 'then', 'kd', 'dk', 'note', 'that', 'under', 'assumption', 'we', 'have', 'this', 'very', 'mild', 'assumption', 'means', 'that', 'after', 'one', 'step', 'starting', 'from', 'and', 'executing', 'this', 'random', 'policy', 'the', 'probability', 'of', 'the', 'next', 'state', 'being', 'in', 'set', 'is', 'upper', 'bounded', 'by', 'times', 'the', 'probability', 'of', 'the', 'starting', 'state', 'being', 'in', 'the', 'same', 'set', 'def', 'besides', 'we', 'assume', 'that', 'has', 'the', 'following', 'regularity', 'property', 'let', 'py', 'rda', 'ka', 'ka', 'denote', 'the', 'pyramid', 'with', 'hight', 'def', 'and', 'base', 'given', 'by', 'the', 'ball', 'rda', 'ka', 'centered', 'at', 'assumption', 'regularity', 'of', 'the', 'action', 'space', 'we', 'assume', 'that', 'there', 'exists', 'such', 'that', 'for', 'all', 'for', 'all', 'py', 'min', 'py', 'for', 'example', 'if', 'is', 'an', 'ball', 'itself', 'then', 'this', 'assumption', 'will', 'be', 'satisfied', 'with', 'without', 'assuming', 'any', 'smoothness', 'of', 'the', 'mdp', 'learning', 'in', 'infinite', 'mdps', 'looks', 'hard', 'see', 'eg', 'here', 'we', 'employ', 'the', 'following', 'extra', 'condition', 'assumption', 'lipschitzness', 'of', 'the', 'mdp', 'in', 'the', 'actions', 'assume', 'that', 'the', 'transition', 'probabilities', 'and', 'rewards', 'are', 'lipschitz', 'wrt', 'their', 'action', 'variable', 'ie', 'there', 'exists', 'lp', 'lr', 'such', 'that', 'for', 'all', 'and', 'measurable', 'set', 'of', 'lp', 'ka', 'lr', 'ka', 'note', 'that', 'previously', 'lipschitzness', 'wrt', 'the', 'state', 'variables', 'was', 'used', 'eg', 'in', 'to', 'construct', 'consistent', 'planning', 'algorithms', 'assumptions', 'on', 'the', 'function', 'sets', 'used', 'by', 'the', 'algorithm', 'these', 'assumptions', 'are', 'less', 'demanding', 'since', 'they', 'are', 'under', 'the', 'control', 'of', 'the', 'user', 'of', 'the', 'algorithm', 'however', 'the', 'choice', 'of', 'these', 'function', 'sets', 'will', 'greatly', 'influence', 'the', 'performance', 'of', 'the', 'algorithm', 'as', 'we', 'shall', 'see', 'it', 'from', 'the', 'bounds', 'the', 'first', 'assumption', 'concerns', 'the', 'class', 'assumption', 'lipschitzness', 'of', 'candidate', 'action', 'value', 'functions', 'assume', 'and', 'that', 'any', 'elements', 'of', 'is', 'uniformly', 'lipschitz', 'in', 'its', 'action', 'argument', 'in', 'the', 'sense', 'that', 'la', 'ka', 'holds', 'for', 'any', 'and', 'remember', 'that', 'denotes', 'the', 'uniform', 'distribution', 'over', 'the', 'action', 'set', 'we', 'shall', 'also', 'need', 'to', 'control', 'the', 'capacity', 'of', 'our', 'function', 'sets', 'we', 'assume', 'that', 'the', 'reader', 'is', 'familiar', 'with', 'the', 'concept', 'of', 'vc', 'here', 'we', 'use', 'the', 'pseudo', 'dimension', 'of', 'function', 'sets', 'that', 'builds', 'upon', 'the', 'concept', 'of', 'vc', 'dimension', 'definition', 'pseudo', 'dimension', 'the', 'pseudo', 'dimension', 'vf', 'of', 'is', 'defined', 'as', 'the', 'vcdimension', 'of', 'the', 'subgraphs', 'of', 'functions', 'in', 'hence', 'it', 'is', 'also', 'called', 'the', 'vc', 'subgraph', 'dimension', 'of', 'since', 'is', 'we', 'define', 'to', 'be', 'the', 'sum', 'of', 'the', 'pseudo', 'dimensions', 'of', 'the', 'coordinate', 'projection', 'spaces', 'of', 'da', 'da', 'now', 'we', 'are', 'ready', 'to', 'state', 'our', 'assumptions', 'on', 'our', 'function', 'sets', 'assumption', 'capacity', 'of', 'the', 'function', 'and', 'policy', 'sets', 'assume', 'that', 'qmax', 'for', 'qmax', 'and', 'vf', 'also', 'da', 'and', 'besides', 'their', 'capacity', 'one', 'shall', 'also', 'control', 'the', 'approximation', 'power', 'of', 'the', 'function', 'sets', 'involved', 'let', 'us', 'first', 'consider', 'the', 'policy', 'set', 'introduce', 'sup', 'inf', 'eq', 'qf', 'note', 'that', 'inf', 'eq', 'measures', 'the', 'quality', 'of', 'approximating', 'eq', 'by', 'hence', 'measures', 'the', 'worst', 'case', 'approximation', 'error', 'of', 'eq', 'as', 'is', 'changed', 'within', 'this', 'can', 'be', 'made', 'small', 'by', 'choosing', 'large', 'another', 'related', 'quantity', 'is', 'the', 'one', 'step', 'bellman', 'error', 'of', 'wrt', 'this', 'is', 'defined', 'as', 'follows', 'for', 'fixed', 'policy', 'the', 'one', 'step', 'bellman', 'error', 'of', 'wrt', 'is', 'defined', 'as', 'sup', 'inf', 'qk', 'qf', 'taking', 'again', 'pessimistic', 'approach', 'the', 'one', 'step', 'bellman', 'error', 'of', 'is', 'defined', 'as', 'sup', 'typically', 'by', 'increasing', 'can', 'be', 'made', 'smaller', 'this', 'is', 'discussed', 'at', 'some', 'length', 'in', 'however', 'it', 'also', 'holds', 'for', 'both', 'and', 'that', 'making', 'them', 'bigger', 'will', 'increase', 'their', 'capacity', 'pseudo', 'dimensions', 'which', 'leads', 'to', 'an', 'increase', 'of', 'the', 'estimation', 'errors', 'hence', 'and', 'must', 'be', 'selected', 'to', 'balance', 'the', 'approximation', 'and', 'estimation', 'errors', 'just', 'like', 'in', 'supervised', 'learning', 'the', 'main', 'result', 'theorem', 'let', 'be', 'greedy', 'policy', 'wrt', 'qk', 'ie', 'argmaxaa', 'qk', 'then', 'under', 'assumptions', 'and', 'for', 'all', 'we', 'have', 'with', 'probability', 'at', 'least', 'given', 'assumption', 'respectively', 'kv', 'resp', 'kv', 'is', 'bounded', 'by', 'log', 'log', 'where', 'depends', 'on', 'da', 'vf', 'dk', 'resp', 'la', 'lp', 'lr', 'max', 'and', 'in', 'particular', 'scales', 'with', 'da', 'where', 'qmax', 'rmax', 'plays', 'the', 'role', 'of', 'the', 'combined', 'effective', 'dimension', 'of', 'and', 'readers', 'not', 'familiar', 'with', 'vc', 'dimension', 'are', 'suggested', 'to', 'consult', 'book', 'such', 'as', 'the', 'one', 'by', 'anthony', 'and', 'bartlett', 'discussion', 'we', 'have', 'presented', 'what', 'we', 'believe', 'is', 'the', 'first', 'finite', 'time', 'bounds', 'for', 'continuous', 'state', 'and', 'actionspace', 'rl', 'that', 'uses', 'value', 'functions', 'further', 'this', 'is', 'the', 'first', 'analysis', 'of', 'fitted', 'iteration', 'an', 'algorithm', 'that', 'has', 'proved', 'to', 'be', 'useful', 'in', 'number', 'of', 'cases', 'even', 'when', 'used', 'with', 'non', 'averagers', 'for', 'which', 'no', 'previous', 'theoretical', 'analysis', 'existed', 'eg', 'in', 'fact', 'our', 'main', 'motivation', 'was', 'to', 'show', 'that', 'there', 'is', 'systematic', 'way', 'of', 'making', 'these', 'algorithms', 'work', 'and', 'to', 'point', 'at', 'possible', 'problem', 'sources', 'the', 'same', 'time', 'we', 'discussed', 'why', 'it', 'can', 'be', 'difficult', 'to', 'make', 'these', 'algorithms', 'work', 'in', 'practice', 'we', 'suggested', 'that', 'either', 'the', 'set', 'of', 'action', 'value', 'candidates', 'has', 'to', 'be', 'carefully', 'controlled', 'eg', 'assuming', 'uniform', 'lipschitzness', 'wrt', 'the', 'state', 'variables', 'or', 'policy', 'search', 'step', 'is', 'needed', 'just', 'like', 'in', 'actorcritic', 'algorithms', 'the', 'bound', 'in', 'this', 'paper', 'is', 'similar', 'in', 'many', 'respects', 'to', 'previous', 'bound', 'of', 'bellman', 'residual', 'minimization', 'algorithm', 'it', 'looks', 'that', 'the', 'techniques', 'developed', 'here', 'can', 'be', 'used', 'to', 'obtain', 'results', 'for', 'that', 'algorithm', 'when', 'it', 'is', 'applied', 'to', 'continuous', 'action', 'spaces', 'finally', 'although', 'we', 'have', 'not', 'explored', 'them', 'here', 'consistency', 'results', 'for', 'fqi', 'can', 'be', 'obtained', 'from', 'our', 'results', 'using', 'standard', 'methods', 'like', 'the', 'methods', 'of', 'sieves', 'we', 'believe', 'that', 'the', 'methods', 'developed', 'here', 'will', 'eventually', 'lead', 'to', 'algorithms', 'where', 'the', 'function', 'approximation', 'methods', 'are', 'chosen', 'based', 'on', 'the', 'data', 'similar', 'to', 'adaptive', 'regression', 'methods', 'so', 'as', 'to', 'optimize', 'performance', 'which', 'in', 'our', 'opinion', 'is', 'one', 'of', 'the', 'biggest', 'open', 'questions', 'in', 'rl', 'currently', 'we', 'are', 'exploring', 'this', 'possibility', 'acknowledgments', 'andras', 'antos', 'would', 'like', 'to', 'acknowledge', 'support', 'for', 'this', 'project', 'from', 'the', 'hungarian', 'academy', 'of', 'sciences', 'bolyai', 'fellowship', 'csaba', 'szepesvari', 'greatly', 'acknowledges', 'the', 'support', 'received', 'from', 'the', 'alberta', 'ingenuity', 'fund', 'nserc', 'the', 'computer', 'and', 'automation', 'research', 'institute', 'of', 'the', 'hungarian', 'academy', 'of', 'sciences', 'references', 'antos', 'cs', 'szepesvari', 'and', 'munos', 'learning', 'near', 'optimal', 'policies', 'with', 'bellman', 'residual', 'minimization', 'based', 'fitted', 'policy', 'iteration', 'and', 'single', 'sample', 'path', 'in', 'colt', 'pages', 'antos', 'cs', 'szepesvari', 'and', 'munos', 'learning', 'near', 'optimal', 'policies', 'with', 'bellman', 'residual', 'minimization', 'based', 'fitted', 'policy', 'iteration', 'and', 'single', 'sample', 'path', 'machine', 'learning', 'accepted', 'antos', 'cs', 'szepesvari', 'and', 'munos', 'value', 'iteration', 'based', 'fitted', 'policy', 'iteration', 'learning', 'with', 'single', 'trajectory', 'in', 'ieee', 'adprl', 'pages', 'bertsekas', 'and', 'se', 'shreve', 'stochastic', 'optimal', 'control', 'the', 'discrete', 'time', 'case', 'academic', 'press', 'new', 'york', 'ernst', 'geurts', 'and', 'wehenkel', 'tree', 'based', 'batch', 'mode', 'reinforcement', 'learning', 'journal', 'of', 'machine', 'learning', 'research', 'rs', 'sutton', 'and', 'ag', 'barto', 'reinforcement', 'learning', 'an', 'introduction', 'bradford', 'book', 'mit', 'press', 'cristianini', 'and', 'shawe', 'taylor', 'an', 'introduction', 'to', 'support', 'vector', 'machines', 'and', 'other', 'kernel', 'based', 'learning', 'methods', 'cambridge', 'university', 'press', 'ja', 'boyan', 'and', 'aw', 'moore', 'generalization', 'in', 'reinforcement', 'learning', 'safely', 'approximating', 'the', 'value', 'function', 'in', 'nips', 'pages', 'pl', 'bartlett', 'pm', 'long', 'and', 'rc', 'williamson', 'fat', 'shattering', 'and', 'the', 'learnability', 'of', 'real', 'valued', 'functions', 'journal', 'of', 'computer', 'and', 'system', 'sciences', 'an', 'kolmogorov', 'and', 'vm', 'tihomirov', 'entropy', 'and', 'capacity', 'of', 'sets', 'in', 'functional', 'space', 'american', 'mathematical', 'society', 'translations', 'munos', 'and', 'cs', 'szepesvari', 'finite', 'time', 'bounds', 'for', 'sampling', 'based', 'fitted', 'value', 'iteration', 'technical', 'report', 'computer', 'and', 'automation', 'research', 'institute', 'of', 'the', 'hungarian', 'academy', 'of', 'sciences', 'kende', 'budapest', 'hungary', 'ay', 'ng', 'and', 'jordan', 'pegasus', 'policy', 'search', 'method', 'for', 'large', 'mdps', 'and', 'pomdps', 'in', 'proceedings', 'of', 'the', 'conference', 'in', 'uncertainty', 'in', 'artificial', 'intelligence', 'pages', 'pl', 'bartlett', 'and', 'tewari', 'sample', 'complexity', 'of', 'policy', 'search', 'with', 'known', 'dynamics', 'in', 'nips', 'mit', 'press', 'anthony', 'and', 'bartlett', 'neural', 'network', 'learning', 'theoretical', 'foundations', 'cambridge', 'university', 'press', 'riedmiller', 'neural', 'fitted', 'iteration', 'first', 'experiences', 'with', 'data', 'efficient', 'neural', 'reinforcement', 'learning', 'method', 'in', 'european', 'conference', 'on', 'machine', 'learning', 'pages', 'kalyanakrishnan', 'and', 'stone', 'batch', 'reinforcement', 'learning', 'in', 'complex', 'domain', 'in', 'aamas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stop words\n",
        "clean_words = remove_all_stop_words(text_as_words)"
      ],
      "metadata": {
        "id": "cbZjmZDno_As"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(clean_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDD-9HhP4dbW",
        "outputId": "1e100c10-40ca-4506-f185-f0e7339e212f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(clean_words[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxflO5_V4iAl",
        "outputId": "2c8c70b8-7243-4068-de4d-61008e9cbaf6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2329"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_words[:1][0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n87TWktK4wge",
        "outputId": "91ec35e0-5faf-4ba3-d5b8-6f21ce980d4f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fitted', 'iteration', 'continuous', 'action', 'space', 'mdps', 'andras', 'antos', 'computer', 'automation', 'research', 'inst', 'hungarian', 'academy', 'sciences', 'kende', 'budapest', 'hungary', 'antos', 'sztakihu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2. Creating Bigram (2 words compound words) and Trigram (3 words compound words)**\n",
        "- Bigram\n",
        "  - google search\n",
        "  - machine learning\n",
        "  - artificial intelligence\n",
        "- Trigram\n",
        "  - on the table\n",
        "  - natural language processing\n"
      ],
      "metadata": {
        "id": "ARy1rRaKFcnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note if you will use higher threshold, which will return the fewer phrases.\n",
        "bigram = gensim.models.Phrases(clean_words, min_count=5, threshold=100) \n",
        "trigram = gensim.models.Phrases(bigram[clean_words], threshold=100)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwo8W6SBFbp_",
        "outputId": "6a3bcb5b-c971-417a-b3a5-e4db3e148582"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "metadata": {
        "id": "gGIHeClxFbgH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
      ],
      "metadata": {
        "id": "it0YWyM0GQJg"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "metadata": {
        "id": "ZHQ1CEQ7GSbd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Using Spacy library for removing stop words ###"
      ],
      "metadata": {
        "id": "D40GYJ4En1gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing spacy and Loading model\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])"
      ],
      "metadata": {
        "id": "06WIabEa_rqI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Form Bigrams\n",
        "clean_words_bigrams = make_bigrams(clean_words)"
      ],
      "metadata": {
        "id": "Rv_NHPKkGtEb"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "clean_words_lemmatized = lemmatization(clean_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
      ],
      "metadata": {
        "id": "s3uCGYcJ_4wJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_words_lemmatized[:1][0][:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItekDLuDG-UV",
        "outputId": "babfbc43-8004-4800-9916-be041cea1478"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['continuous', 'action', 'space', 'andra', 'computer', 'hungarian', 'sztakihu', 'team', 'szepesva', 'consider', 'continuous', 'state', 'continuous', 'action', 'batch', 'reinforcement_learne', 'goal', 'learn', 'good', 'policy', 'sufficiently', 'rich', 'generate', 'policy', 'study', 'variant', 'greedy', 'action', 'selection', 'replace', 'search', 'policy', 'restrict', 'set', 'candidate', 'policy', 'maximize', 'average', 'action', 'value', 'provide', 'rigorous', 'analysis', 'algorithm', 'prove', 'believe', 'first', 'finite', 'time', 'bind', 'value', 'function', 'base', 'continuous', 'state', 'action', 'problem', 'preliminary', 'build', 'result', 'reason', 'notation', 'paper', 'unattributed', 'result', 'cite', 'section', 'find', 'book', 'discount', 'define', 'possible', 'infinite', 'state', 'space', 'set', 'action', 'transition', 'probability', 'kernel', 'define', 'next', 'state', 'distribution', 'take', 'action', 'state', 'give', 'correspond', 'distribution', 'immediate', 'reward', 'measurable', 'space', 'denote', 'set', 'probability', 'measure', 'lebesguemeasure', 'shall']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2 Tokenizing the clean and lemmatize words**"
      ],
      "metadata": {
        "id": "b6eIqifh5BCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean_words))\n",
        "print(len(clean_words[0]))\n",
        "print(len(clean_words[99]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZoYjycnnnRf",
        "outputId": "4d0877ba-51bc-44c8-c6e6-b17d65852fbb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "2329\n",
            "1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean_words_lemmatized))\n",
        "print(len(clean_words_lemmatized[0]))\n",
        "print(len(clean_words_lemmatized[99]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PHEmJnzHFSd",
        "outputId": "d03c08dd-2c8a-4eaf-f886-7854b8438f1a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "1700\n",
            "863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.corpora as corpora"
      ],
      "metadata": {
        "id": "bbwRsopi5JBg"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = corpora.Dictionary(clean_words_lemmatized)\n",
        "\n",
        "# note: If you do not lematized the clean words you can still use the clean words as below\n",
        "# id2word = corpora.Dictionary(clean_words)\n",
        "\n",
        "\n",
        "# Creating Corpus for the clean words\n",
        "texts = clean_words_lemmatized\n",
        "#texts = clean_words\n",
        "\n",
        "\n",
        "# Creating The Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "6PpZjT3E5A0_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus[:1][0][:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJknwLIi5X9Q",
        "outputId": "705888ee-6cf7-4e6c-de26-20551370d26f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (1, 2), (2, 1), (3, 2), (4, 1), (5, 1), (6, 35), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 10), (13, 1), (14, 9), (15, 1), (16, 1), (17, 1), (18, 8), (19, 2), (20, 1), (21, 2), (22, 4), (23, 4), (24, 3), (25, 8), (26, 4), (27, 6), (28, 1), (29, 2), (30, 3), (31, 1), (32, 2), (33, 16), (34, 29), (35, 1), (36, 1), (37, 3), (38, 1), (39, 1), (40, 2), (41, 13), (42, 1), (43, 3), (44, 6), (45, 1), (46, 1), (47, 3), (48, 5), (49, 3), (50, 3), (51, 5), (52, 2), (53, 11), (54, 1), (55, 2), (56, 7), (57, 3), (58, 7), (59, 1), (60, 2), (61, 14), (62, 1), (63, 1), (64, 1), (65, 4), (66, 7), (67, 1), (68, 2), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 2), (75, 2), (76, 2), (77, 1), (78, 1), (79, 1), (80, 5), (81, 2), (82, 1), (83, 3), (84, 2), (85, 2), (86, 2), (87, 2), (88, 7), (89, 1), (90, 6), (91, 1), (92, 1), (93, 1), (94, 9), (95, 11), (96, 1), (97, 1), (98, 2), (99, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(clean_words_lemmatized))\n",
        "print(len(clean_words_lemmatized[0]))\n",
        "print(len(clean_words_lemmatized[99]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ytv_ia46Ict",
        "outputId": "d333425e-1f1b-4d3c-a1ba-b1aee6b2ea84"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "1700\n",
            "863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now on the following objects will be used for modeling:\n",
        "- id2word\n",
        "- corpus"
      ],
      "metadata": {
        "id": "PzeDY1H3HvNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Training the LDA Model**"
      ],
      "metadata": {
        "id": "bG99Q7uG6Nrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Latent Dirichlet Allocation (LDA):\n",
        "- Unsupervised machine learning, clustering technique\n",
        "- A topic modeling in which words are represented as topics, \n",
        "- Documents are represented as a collection of these word topics"
      ],
      "metadata": {
        "id": "e6Q0_qqiI1O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiting the total number of topics we are interested from the given tech corpus\n",
        "num_topics = 10"
      ],
      "metadata": {
        "id": "Gx2j8Ico6J-e"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A LDA model with N (= num_topics) topics\n",
        "- Each Topic is a combination of keywords\n",
        "- Each keyword contribute certain weight to the topic"
      ],
      "metadata": {
        "id": "3B8xa-rs9pmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gensin to build the LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus, \n",
        "                                       id2word=id2word, \n",
        "                                       num_topics=num_topics,\n",
        "                                       )\n",
        "\n",
        "# Please perform the modelling by adding the following options also to check your modelling performance\n",
        "# random_state=100,\n",
        "# chunksize=100,\n",
        "# passes=10,\n",
        "# per_word_topics=True\n"
      ],
      "metadata": {
        "id": "3W-cpDVq6Zvc"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Keyword in the N (=num_topics) topics\n",
        "from pprint import pprint\n",
        "pprint(lda_model.print_topics())\n",
        "#pprint(lda_model.print_topics(N))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWfnkUK_6ULN",
        "outputId": "9abae53e-4f51-4c84-8e36-caef26289ed1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.020*\"model\" + 0.011*\"use\" + 0.008*\"network\" + 0.007*\"time\" + '\n",
            "  '0.007*\"learn\" + 0.007*\"function\" + 0.006*\"result\" + 0.006*\"set\" + '\n",
            "  '0.006*\"image\" + 0.006*\"method\"'),\n",
            " (1,\n",
            "  '0.012*\"model\" + 0.010*\"set\" + 0.010*\"use\" + 0.007*\"distribution\" + '\n",
            "  '0.007*\"result\" + 0.006*\"function\" + 0.006*\"method\" + 0.006*\"network\" + '\n",
            "  '0.006*\"policy\" + 0.005*\"problem\"'),\n",
            " (2,\n",
            "  '0.011*\"use\" + 0.009*\"model\" + 0.008*\"result\" + 0.007*\"image\" + '\n",
            "  '0.007*\"function\" + 0.007*\"network\" + 0.007*\"problem\" + 0.006*\"set\" + '\n",
            "  '0.005*\"time\" + 0.005*\"distribution\"'),\n",
            " (3,\n",
            "  '0.013*\"model\" + 0.011*\"use\" + 0.007*\"distribution\" + 0.006*\"result\" + '\n",
            "  '0.005*\"set\" + 0.005*\"time\" + 0.005*\"show\" + 0.005*\"network\" + '\n",
            "  '0.005*\"method\" + 0.005*\"learn\"'),\n",
            " (4,\n",
            "  '0.011*\"model\" + 0.008*\"use\" + 0.007*\"state\" + 0.006*\"set\" + 0.006*\"show\" + '\n",
            "  '0.006*\"learn\" + 0.006*\"distribution\" + 0.006*\"algorithm\" + 0.006*\"result\" + '\n",
            "  '0.005*\"function\"'),\n",
            " (5,\n",
            "  '0.012*\"model\" + 0.012*\"use\" + 0.009*\"function\" + 0.008*\"set\" + '\n",
            "  '0.007*\"datum\" + 0.007*\"distribution\" + 0.007*\"method\" + 0.006*\"give\" + '\n",
            "  '0.006*\"show\" + 0.005*\"result\"'),\n",
            " (6,\n",
            "  '0.012*\"model\" + 0.009*\"use\" + 0.009*\"result\" + 0.007*\"learn\" + '\n",
            "  '0.006*\"image\" + 0.006*\"set\" + 0.005*\"function\" + 0.005*\"show\" + '\n",
            "  '0.005*\"network\" + 0.005*\"give\"'),\n",
            " (7,\n",
            "  '0.013*\"model\" + 0.012*\"image\" + 0.010*\"use\" + 0.007*\"datum\" + 0.007*\"set\" + '\n",
            "  '0.006*\"method\" + 0.006*\"result\" + 0.006*\"show\" + 0.006*\"network\" + '\n",
            "  '0.005*\"learn\"'),\n",
            " (8,\n",
            "  '0.010*\"model\" + 0.010*\"use\" + 0.007*\"set\" + 0.007*\"show\" + '\n",
            "  '0.007*\"distribution\" + 0.007*\"problem\" + 0.006*\"function\" + 0.006*\"time\" + '\n",
            "  '0.006*\"method\" + 0.006*\"learn\"'),\n",
            " (9,\n",
            "  '0.013*\"model\" + 0.010*\"use\" + 0.007*\"problem\" + 0.006*\"function\" + '\n",
            "  '0.006*\"time\" + 0.006*\"set\" + 0.006*\"state\" + 0.006*\"learn\" + 0.005*\"show\" + '\n",
            "  '0.005*\"result\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the above result:\n",
        "- Above you are seeing N topics\n",
        "- Each topic is a collection of M keywords\n",
        "- Each keyword has the weight\n",
        "- For every topic each keywords provide the importance based on the weight as shown "
      ],
      "metadata": {
        "id": "YHvjGUF9BTBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "id": "N85cqnDH6kKk"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_lda\n",
        "# to Save the mode;\n",
        "# doc_lda.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bT3r7TCkE7t",
        "outputId": "742b20bc-a6ac-4761-bdf4-3f8d6c6d4235"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f5db42d9110>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Analyzing the LDA Model**"
      ],
      "metadata": {
        "id": "yqQexTrU6ofV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Understanding and interpreting individual topics\n",
        "- Understanding the relationships between the topics."
      ],
      "metadata": {
        "id": "qm0pV3O19_6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1CNkUD6xb3",
        "outputId": "b607ad22-d8c1-4d67-fe7b-88800e985aba"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pickle \n",
        "import pyLDAvis\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INDWA_ts6u7t",
        "outputId": "c5b4dcf0-6ae9-4453-aeac-26bb5d2ac43d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "QSSJrG-R613d"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDAvis_data_filepath = os.path.join('/content/results/ldavis_prepared_'+str(num_topics))"
      ],
      "metadata": {
        "id": "eBfj1LUa6nKY"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # this is a bit time consuming - make the if statement True\n",
        "# # if you want to execute visualization prep yourself\n",
        "if 1 == 1:\n",
        "    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "    with open(LDAvis_data_filepath, 'wb') as f:\n",
        "        pickle.dump(LDAvis_prepared, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dztaKyg-fdq",
        "outputId": "4e90172e-d1cd-478d-ecef-c5e16515d8e9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre-prepared pyLDAvis data from disk\n",
        "with open(LDAvis_data_filepath, 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)"
      ],
      "metadata": {
        "id": "4T5Voe8B-m-K"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')"
      ],
      "metadata": {
        "id": "PfyuHktL-3UO"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDAvis_prepared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "W89hHYYA-4YJ",
        "outputId": "fae06d18-cf91-4c11-c83f-a9c37268e1cc"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.001470  0.009057       1        1  29.665970\n",
              "8     -0.006502 -0.002360       2        1  13.915657\n",
              "0      0.011305 -0.000207       3        1  13.849841\n",
              "7      0.005493 -0.011711       4        1   8.558589\n",
              "2      0.003825 -0.002794       5        1   7.393522\n",
              "6      0.001923 -0.005090       6        1   7.150309\n",
              "9     -0.000333  0.002765       7        1   5.729087\n",
              "4     -0.020490 -0.000903       8        1   5.039800\n",
              "3      0.005569  0.008471       9        1   4.477995\n",
              "1     -0.002261  0.002772      10        1   4.219230, topic_info=           Term         Freq        Total Category  logprob  loglift\n",
              "834       model  2239.000000  2239.000000  Default  30.0000  30.0000\n",
              "534         use  1856.000000  1856.000000  Default  29.0000  29.0000\n",
              "1193      image   848.000000   848.000000  Default  28.0000  28.0000\n",
              "426      result  1040.000000  1040.000000  Default  27.0000  27.0000\n",
              "448         set  1231.000000  1231.000000  Default  26.0000  26.0000\n",
              "...         ...          ...          ...      ...      ...      ...\n",
              "109       datum    30.873891   905.234742  Topic10  -5.4734  -0.2128\n",
              "212        give    28.451700   806.814283  Topic10  -5.5551  -0.1794\n",
              "12    algorithm    23.944387   567.979847  Topic10  -5.7276  -0.0008\n",
              "14         also    23.458271   597.450527  Topic10  -5.7481  -0.0719\n",
              "732     feature    23.203286   584.068865  Topic10  -5.7590  -0.0602\n",
              "\n",
              "[864 rows x 6 columns], token_table=      Topic      Freq         Term\n",
              "term                              \n",
              "5621      1  0.475504  abstraction\n",
              "5621      2  0.103371  abstraction\n",
              "5621      3  0.062022  abstraction\n",
              "5621      4  0.041348  abstraction\n",
              "5621      5  0.062022  abstraction\n",
              "...     ...       ...          ...\n",
              "8048      5  0.122470         worm\n",
              "8048      6  0.244939         worm\n",
              "7033      2  0.236061       ystrom\n",
              "7033      3  0.236061       ystrom\n",
              "7033      6  0.236061       ystrom\n",
              "\n",
              "[3305 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 9, 1, 8, 3, 7, 10, 5, 4, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el19181400403553420322638357784\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el19181400403553420322638357784_data = {\"mdsDat\": {\"x\": [0.0014696418846688656, -0.00650196905929022, 0.011305203517501888, 0.0054931457315150894, 0.0038250903795395996, 0.0019231171361850437, -0.00033254843284811716, -0.020489829152829486, 0.005569126399753365, -0.0022609784041959986], \"y\": [0.00905666589379554, -0.0023595200385304995, -0.00020727483093887751, -0.011711414106384306, -0.00279414554948171, -0.005089586203339331, 0.00276549796717409, -0.0009033280417515442, 0.00847127596244169, 0.0027718289470149374], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [29.66596973318967, 13.9156571932444, 13.849841306038616, 8.55858889263016, 7.393521847232118, 7.150309343792855, 5.729086902359989, 5.039799931191282, 4.4779950878173835, 4.21922976250354]}, \"tinfo\": {\"Term\": [\"model\", \"use\", \"image\", \"result\", \"set\", \"distribution\", \"policy\", \"problem\", \"network\", \"state\", \"learn\", \"show\", \"time\", \"method\", \"algorithm\", \"number\", \"function\", \"variable\", \"give\", \"feature\", \"datum\", \"probability\", \"sample\", \"value\", \"large\", \"example\", \"also\", \"base\", \"action\", \"figure\", \"dene\", \"escort\", \"mmse\", \"infoset\", \"minimise\", \"exploitability\", \"regularization_constant\", \"poker\", \"blueprint\", \"gift\", \"imperfect_information\", \"cbv\", \"contour\", \"opper\", \"holdem\", \"exponential_family\", \"actuator\", \"stochastic_oscillator\", \"dss\", \"particle\", \"gibb\", \"deform\", \"student\", \"sensory_adaptation\", \"bucket\", \"head\", \"opponent\", \"blueprint_strategy\", \"finger\", \"coin\", \"subgame\", \"strategy\", \"control\", \"subgame_solve\", \"center\", \"classification\", \"rbm\", \"tail\", \"game\", \"function\", \"entropy\", \"point\", \"datum\", \"training\", \"probability\", \"distribution\", \"use\", \"give\", \"set\", \"graph\", \"example\", \"method\", \"section\", \"define\", \"process\", \"figure\", \"model\", \"base\", \"dataset\", \"sample\", \"consider\", \"show\", \"error\", \"value\", \"high\", \"problem\", \"also\", \"time\", \"follow\", \"number\", \"learn\", \"result\", \"image\", \"state\", \"first\", \"network\", \"parameter\", \"olpomdp\", \"objective_return\", \"drastic\", \"semibandit\", \"steepest_descent\", \"covariant\", \"contextual_semibandit\", \"composite_action\", \"approximator\", \"evening\", \"eel\", \"reward\", \"decod\", \"umichedu\", \"dashed_line\", \"fully_observable\", \"compatible\", \"recency\", \"seduce\", \"fmo\", \"pmin\", \"pricing\", \"ergodic\", \"sl\", \"ot\", \"unsealed\", \"vcee\", \"semibandit_feedback\", \"thwart\", \"infant\", \"pgrd\", \"evolution\", \"gbm\", \"hedge\", \"agent\", \"language\", \"price\", \"asset\", \"policy\", \"investor\", \"natural\", \"gradient\", \"item\", \"sequence\", \"environment\", \"column\", \"problem\", \"estimate\", \"test\", \"loss\", \"regression\", \"factor\", \"domain\", \"distribution\", \"show\", \"oracle\", \"action\", \"base\", \"time\", \"set\", \"learn\", \"optimal\", \"step\", \"method\", \"use\", \"value\", \"first\", \"figure\", \"function\", \"result\", \"number\", \"model\", \"parameter\", \"state\", \"case\", \"give\", \"network\", \"follow\", \"sample\", \"datum\", \"approach\", \"eager\", \"consequent\", \"prognosis\", \"consolidation\", \"parent\", \"patient\", \"greatest\", \"solar\", \"lbr\", \"pth\", \"pittsburgh\", \"outgoing\", \"hoete\", \"antecedent\", \"intent\", \"reversal\", \"effector\", \"cancer\", \"factored\", \"disorder\", \"declarative\", \"population_wide\", \"diagnosis\", \"reinstate\", \"acquire\", \"lung\", \"postoperative\", \"lazy\", \"tic\", \"nondescendant\", \"averaging\", \"entity\", \"instance\", \"network\", \"rois\", \"model\", \"grammar\", \"prediction\", \"node\", \"roi\", \"error\", \"interaction\", \"parameter\", \"time\", \"score\", \"learn\", \"estimate\", \"brain\", \"input\", \"structure\", \"mixture\", \"text\", \"use\", \"part\", \"represent\", \"test\", \"image\", \"follow\", \"gaussian\", \"result\", \"training\", \"function\", \"fix\", \"dataset\", \"step\", \"method\", \"show\", \"set\", \"system\", \"see\", \"datum\", \"weight\", \"value\", \"give\", \"problem\", \"figure\", \"approach\", \"feature\", \"algorithm\", \"state\", \"distribution\", \"number\", \"cvae_gan\", \"unconditional\", \"rail\", \"multimodal\", \"host\", \"untraine\", \"diversity\", \"inject\", \"gan\", \"painting\", \"untrained\", \"binarize\", \"lvae\", \"workstation\", \"facade\", \"stochasticity\", \"convolutional\", \"turker\", \"ofinter\", \"image\", \"chip\", \"shoe\", \"convolution\", \"colorization\", \"bundle\", \"disneyland\", \"detectable\", \"skl\", \"generative_adversarial\", \"fake\", \"realism\", \"night\", \"generator\", \"cvpr\", \"biosift\", \"brnn\", \"ddp\", \"merge\", \"paragraph\", \"layer\", \"gradient\", \"neural_net\", \"work\", \"segmentation\", \"architecture\", \"scene\", \"cell\", \"segment\", \"policy\", \"table\", \"sentence\", \"datum\", \"feature\", \"human\", \"model\", \"prediction\", \"network\", \"method\", \"scale\", \"different\", \"perform\", \"use\", \"show\", \"improve\", \"result\", \"domain\", \"value\", \"set\", \"number\", \"structure\", \"approach\", \"output\", \"input\", \"represent\", \"learn\", \"time\", \"vector\", \"sample\", \"find\", \"may\", \"follow\", \"performance\", \"experiment\", \"also\", \"function\", \"training\", \"distribution\", \"state\", \"base\", \"algorithm\", \"problem\", \"lma\", \"gesture\", \"fir\", \"iir\", \"pole\", \"tap\", \"convolve\", \"modal\", \"interference\", \"architectur\", \"unmixe\", \"compensation\", \"gaul\", \"nonminimum\", \"delay\", \"cri\", \"fingertip\", \"rubin\", \"visakan\", \"apparent\", \"mdlstm\", \"flanged\", \"patent\", \"protocol\", \"veuerle\", \"ordinate\", \"encouraging\", \"back_propagation\", \"brightness\", \"bass\", \"audio\", \"instruction\", \"signal\", \"realism\", \"keyword\", \"sense\", \"execution\", \"texture\", \"competition\", \"output\", \"controller\", \"schedule\", \"web\", \"scheme\", \"image\", \"feature\", \"optimization\", \"train\", \"problem\", \"network\", \"large\", \"result\", \"compare\", \"table\", \"use\", \"first\", \"base\", \"policy\", \"sample\", \"approach\", \"node\", \"require\", \"task\", \"give\", \"point\", \"function\", \"time\", \"datum\", \"distribution\", \"show\", \"vector\", \"model\", \"also\", \"set\", \"value\", \"state\", \"learn\", \"performance\", \"parameter\", \"probability\", \"step\", \"figure\", \"method\", \"passive\", \"prescribe\", \"worm\", \"pgrd\", \"udell\", \"ssft\", \"acrobot\", \"sequential_labelling\", \"orthonormal\", \"asynchronous\", \"randomize\", \"nystrm\", \"schatten_norm\", \"overestimation\", \"sketch\", \"polydecayme\", \"ofer\", \"recency\", \"expdecayme\", \"underestimation\", \"hurt\", \"streaming\", \"storage\", \"internal\", \"daniely\", \"sociability\", \"ketch\", \"ystrom\", \"mcallester\", \"forage\", \"rank_psd\", \"designer\", \"agent\", \"insect\", \"sleep\", \"psd\", \"objective_return\", \"matrix\", \"approximation\", \"gradient\", \"result\", \"ant\", \"random\", \"reward\", \"sense\", \"accuracy\", \"experiment\", \"learn\", \"inference\", \"image\", \"behavior\", \"train\", \"policy\", \"large\", \"model\", \"feature\", \"algorithm\", \"assumption\", \"space\", \"structure\", \"rate\", \"sample\", \"size\", \"use\", \"show\", \"network\", \"give\", \"linear\", \"set\", \"also\", \"test\", \"function\", \"number\", \"value\", \"method\", \"figure\", \"example\", \"base\", \"datum\", \"problem\", \"follow\", \"time\", \"first\", \"density_parity\", \"turbocode\", \"codeword_bit\", \"codeword\", \"revolution\", \"leap\", \"permute\", \"ukly\", \"cable\", \"thumbnail\", \"hamming_code\", \"stimulus_drive\", \"qlds\", \"stimulus_selectivity\", \"wire\", \"lfsr\", \"qld\", \"stimulus\", \"parity_check\", \"forwardbackward\", \"microstate\", \"telephone\", \"propagation\", \"qi\", \"radio\", \"constituent\", \"prompts\", \"nonconstructive\", \"paritycheck\", \"cryptography\", \"bit\", \"code\", \"decode\", \"send\", \"recording\", \"cell\", \"population\", \"cycle\", \"state\", \"problem\", \"channel\", \"algorithm\", \"neural\", \"number\", \"model\", \"quadratic\", \"filter\", \"time\", \"feature\", \"optimization\", \"probability\", \"use\", \"also\", \"work\", \"learn\", \"parameter\", \"function\", \"linear\", \"show\", \"performance\", \"set\", \"datum\", \"result\", \"follow\", \"method\", \"give\", \"define\", \"step\", \"estimate\", \"approach\", \"variable\", \"distribution\", \"sample\", \"experiment\", \"value\", \"example\", \"robot\", \"fuel\", \"cooperative\", \"planner\", \"repair\", \"consumption\", \"visitation\", \"undersupply\", \"dar\", \"maxa\", \"centralized\", \"propositional\", \"knowledge_compilation\", \"enemy\", \"slave\", \"towing\", \"burgard\", \"smoke\", \"auction\", \"ihmm\", \"pomdp\", \"pickup\", \"coordinating\", \"basque\", \"occupy\", \"root_binding\", \"chunk\", \"dislike\", \"maxfa\", \"arena\", \"evolve\", \"tow\", \"logic\", \"plan\", \"mvu\", \"fun\", \"wfomc\", \"clause\", \"abstraction\", \"environment\", \"teammate\", \"resource\", \"subgame\", \"action\", \"planning\", \"state\", \"logical_variable\", \"algorithm\", \"inference\", \"solve\", \"node\", \"variable\", \"game\", \"atom\", \"mdp\", \"agent\", \"policy\", \"language\", \"must\", \"model\", \"show\", \"large\", \"first\", \"reward\", \"space\", \"learn\", \"distribution\", \"give\", \"find\", \"problem\", \"use\", \"result\", \"set\", \"figure\", \"time\", \"method\", \"order\", \"also\", \"value\", \"function\", \"number\", \"datum\", \"sample\", \"base\", \"example\", \"chaos\", \"etude\", \"consolidation\", \"investigator\", \"declarative\", \"lock\", \"resonance\", \"twice_continuously\", \"variate\", \"onset\", \"earn\", \"tightness\", \"emission\", \"stdp\", \"deletion\", \"ediss\", \"warp\", \"anatomical\", \"closure\", \"homomorphism\", \"housing\", \"trigonometric\", \"perirhinal\", \"definite\", \"outputting_summary\", \"samuelide\", \"conditional_densitie\", \"independencie\", \"networksfor\", \"instantaneous_effect\", \"dax\", \"supx\", \"graph_cover\", \"discrete\", \"variable\", \"watch\", \"independence\", \"expert\", \"edge\", \"identify\", \"bifurcation\", \"mechanism\", \"negative\", \"timino\", \"tight\", \"independent\", \"query\", \"probability\", \"markov\", \"test\", \"binary\", \"cluster\", \"classifier\", \"region\", \"distribution\", \"program\", \"theorem\", \"matrix\", \"use\", \"training\", \"model\", \"information\", \"case\", \"scale\", \"result\", \"mean\", \"compute\", \"constant\", \"graph\", \"network\", \"time\", \"give\", \"small\", \"large\", \"approach\", \"show\", \"method\", \"learn\", \"let\", \"image\", \"base\", \"number\", \"set\", \"figure\", \"datum\", \"feature\", \"function\", \"value\", \"example\", \"problem\", \"also\", \"follow\", \"lsh\", \"robot\", \"tow\", \"fuel\", \"hub\", \"centralized\", \"coordination\", \"measuremoot\", \"pursuit\", \"revolution\", \"teammate\", \"planner\", \"cooditioo\", \"experimoot\", \"density_parity\", \"hash\", \"hard_thresholde\", \"turbocode\", \"amari\", \"meinshausen\", \"residnal\", \"microstate\", \"corouary\", \"request\", \"codeword_bit\", \"ern\", \"hamming_code\", \"consumption\", \"cv\", \"repair\", \"resource\", \"replacement\", \"propagation\", \"star\", \"rip\", \"recovery\", \"ompr\", \"policy\", \"sentence\", \"slave\", \"stability\", \"bit\", \"set\", \"support\", \"cost\", \"instruction\", \"program\", \"distribution\", \"example\", \"matrix\", \"performance\", \"number\", \"update\", \"compute\", \"obtain\", \"result\", \"increase\", \"network\", \"note\", \"model\", \"sample\", \"size\", \"use\", \"method\", \"problem\", \"graph\", \"value\", \"probability\", \"function\", \"state\", \"learn\", \"vector\", \"show\", \"figure\", \"base\", \"follow\", \"parameter\", \"time\", \"estimate\", \"datum\", \"give\", \"algorithm\", \"also\", \"feature\"], \"Freq\": [2239.0, 1856.0, 848.0, 1040.0, 1231.0, 951.0, 572.0, 858.0, 868.0, 645.0, 945.0, 998.0, 923.0, 991.0, 567.0, 675.0, 1217.0, 426.0, 806.0, 584.0, 905.0, 576.0, 613.0, 708.0, 493.0, 576.0, 597.0, 693.0, 393.0, 685.0, 15.363512528277328, 6.889160556656194, 5.392339323700283, 12.295550596289912, 7.299094032596276, 14.51311906381798, 6.366088259327534, 11.782142493978677, 12.771552844708934, 15.313767514485141, 4.459248499494083, 5.59960093165538, 34.641854978744284, 3.693564639748806, 2.4363774337352955, 19.671058003882223, 2.405601789649041, 2.4691284422937643, 2.4168290778909554, 35.26829050829592, 6.537235583378729, 2.9930154974967516, 11.959689712907846, 2.902598636180782, 2.926678400600076, 25.18583605501745, 6.35715866355754, 4.0035418132748175, 6.777744581248526, 5.670843134387614, 36.32081768657846, 71.24085697049723, 125.30637408730928, 18.923493380799872, 46.143011755254484, 146.30337620617186, 16.518612642461324, 17.06104644700402, 68.712492808253, 481.9236482281787, 32.22304545590476, 207.46207527267697, 346.97528569741553, 215.9591968103158, 224.47862126281106, 346.56598144788, 618.6889275926603, 293.7927568760149, 426.1428057407847, 124.77658351858456, 212.30183188173996, 337.68580855184337, 160.5360078155355, 167.5853426199844, 124.35052799768549, 236.82424804468502, 639.5301585432359, 231.50054708550337, 134.9982791517566, 201.89010385308504, 136.54308115604982, 290.72726217387697, 162.02523317184688, 218.25955220450717, 126.27881489435863, 243.56495482432823, 186.15337426330223, 245.78684056776126, 186.18025337019182, 197.03570342951593, 243.1438969868338, 250.47088622159018, 218.11918353519488, 185.0258005463283, 171.73768293000103, 196.68852700813605, 170.5540147327889, 6.7912118961107915, 7.869039515073698, 1.3769610634465612, 5.464453094812045, 1.6798976467530902, 1.3837422449700432, 2.465856603702968, 2.347134027542687, 3.10098979009736, 0.989287867457548, 2.8071990813194105, 120.90559337915474, 2.105244936458338, 0.9392964690919423, 1.2070065320102705, 1.5303271732719395, 2.4656971980978315, 2.11697139884814, 0.599214143094841, 6.021396860978102, 2.2442256171969426, 1.7844101752980297, 0.5770452013373393, 0.5798293270310342, 1.1643826559405277, 0.5811363029435785, 2.715628769762915, 2.0556196590507083, 0.5682447056198887, 0.8884478463425696, 15.47973108967159, 7.814035225269493, 2.954449435345073, 5.265018147251106, 59.81995325966606, 50.35682874248865, 27.68095880164703, 9.151303145599217, 130.69560989395873, 11.185308781518941, 36.14513870217468, 76.73502678888859, 25.524676533035233, 75.56769901288905, 14.722869745906452, 34.00506037520924, 159.51641445099887, 91.65922140085941, 109.31284669537007, 55.827773158355036, 32.95947540847992, 42.04541837233727, 41.61476126956791, 162.65812063403607, 166.62273962978927, 20.7541931805147, 72.14630889927727, 115.50847476540665, 143.51543868343973, 180.1349458707995, 142.4255124791461, 61.39761330592891, 86.65826755322644, 143.16370271322793, 232.78659959441447, 109.01626682982452, 89.13801009746719, 103.92506010588546, 156.7164456407483, 139.44273315484304, 102.11717811721454, 241.71463533051806, 92.97896282495397, 92.76085217795806, 76.10457285429413, 103.35293697186287, 106.82765858733391, 84.24610309994452, 81.13565241947987, 83.16647488610633, 77.57780122225253, 2.6381909582593517, 1.7065828710835174, 1.2346398158321068, 5.138567196862496, 9.640964716513201, 1.864763687043799, 0.691413051647529, 0.6797835587729522, 1.6446849988082295, 0.6643302179068129, 0.6606091509012739, 1.3424414334054648, 0.6457643261805923, 2.254364765582866, 0.6435135543571705, 0.6440648821078406, 1.312880831202109, 0.6240649760090994, 0.6130007785576523, 0.6282116177896736, 1.4725354562243718, 0.61314972314039, 1.2578190365083464, 0.8749970228500102, 3.6088670645397185, 0.5946725568807368, 0.5958566026244283, 5.233707953897679, 0.5836988857592875, 0.5881179410763225, 5.962177064886579, 18.057529238812144, 39.29779592549816, 203.3321369741659, 3.171906967356883, 483.77240390852324, 8.41024094409559, 42.39966915883652, 83.21925617585944, 6.051017786713499, 99.80330736017368, 22.882264797256195, 123.42776824010771, 173.16215561645777, 44.74750593990713, 168.51572697228335, 88.65314248646459, 8.065786545437883, 87.16505653059585, 60.69862583869229, 19.30834818739631, 26.568380996727292, 277.31949183845427, 40.43842100709752, 53.15491048017645, 96.96724086637576, 135.09308476851055, 102.27458252421269, 40.148003052989246, 155.10280337677216, 87.8648977109443, 162.7305313861817, 43.515674592556365, 62.59541256710117, 81.96078118582747, 133.8966564635661, 133.37499429226023, 154.6954519340998, 64.97548427649268, 67.57908372290031, 112.28089798015915, 68.19577807235356, 92.92007772752889, 100.59102364816242, 101.11691371972071, 88.33645476649265, 78.27861177621968, 78.19431239272906, 75.95855151269845, 79.67326788315906, 91.39143878692506, 80.20015870770264, 2.3737512182671976, 2.3895407149499706, 0.67713630551549, 3.687173948758445, 1.0952881683979638, 1.9587911289079316, 5.279052699226278, 2.382990402676952, 0.8500288513418537, 2.0370031516154143, 2.2782640117930733, 0.8279702415637313, 1.016418313328514, 1.2008880138703932, 0.969509730506684, 0.772137221983136, 8.476833679152065, 1.1837448525748115, 0.37546854199011837, 174.5494521580952, 3.8222811422261116, 0.37517124714523353, 3.329278835377075, 1.152265418918116, 1.1349107610981717, 0.7381901841140631, 0.3642866946900052, 0.5484536989742239, 0.5416668645357416, 0.9511147443004759, 4.1205225100572545, 1.8629725634028247, 5.350484238905275, 5.490016790860117, 6.271365728761906, 1.6279686563560753, 1.7160611930263971, 8.924563569823084, 2.1800227905155714, 37.42307574955756, 47.493218277852456, 2.1853162836068543, 45.99356460625557, 8.875742181166439, 22.96055603192404, 9.028275037960688, 19.364279554490384, 7.524473081352073, 69.42735865996963, 31.316532693078475, 14.313536701886783, 99.95249654738132, 66.97811251962057, 18.11235215273532, 197.0440522497908, 22.93429745728532, 83.20785724065844, 92.04100132925471, 24.951597340806146, 48.55638828874731, 30.951108390286688, 145.38889853155936, 88.00790244925248, 27.585053045314968, 88.14600490253233, 23.98119396148425, 64.34850283815025, 97.50910803561665, 61.63716429854271, 33.8747668575631, 52.276388930079705, 41.56034383350166, 44.087180969802894, 30.798938595287854, 70.26565965989381, 68.98814769295754, 41.62214424705994, 51.204224019775005, 35.400039837096735, 40.436940307323475, 49.48023290136724, 43.09737376151074, 38.86511898391454, 46.805054621727905, 64.52411357031335, 44.746782606596284, 55.712113922739995, 47.65708595864232, 48.02515071085531, 44.19727728784025, 43.361693171399466, 4.961073577956627, 1.2556120271870288, 1.2177695021231576, 1.328247634307394, 0.479985452618139, 0.47255261700868567, 1.582638692243668, 0.8331638606570487, 0.4569206692428508, 0.3075261931225548, 0.7729042294143167, 0.4485253921662857, 0.30026199462832504, 0.2974593405027229, 5.798964061206386, 0.29359147287496656, 0.4560180198563592, 0.2976485648519796, 0.30078994697626366, 0.8490471696402359, 0.9428682129744358, 0.28772122708692804, 0.6909892196519499, 3.3349859737956455, 0.2862168114427754, 0.4394731994306404, 0.2839169735433766, 0.413568831527014, 1.140585288675207, 1.7910381507244122, 5.897382107281662, 9.01992395799317, 9.79663086994343, 3.293916552208266, 4.148442270888792, 22.55992587090036, 4.636366658045053, 6.4572760881238045, 4.5841529305450655, 53.07057362035275, 5.99803839368936, 6.0242913845948145, 3.7881654877259052, 9.55817161119533, 93.67560573384006, 65.60368102244244, 31.639351155866752, 33.06613144946122, 83.95690959691967, 84.36725715941311, 50.869105558198754, 97.71543519787696, 27.63425906173593, 25.434516763163757, 146.81099003034208, 52.980029558202524, 63.27794597708547, 53.82600786999509, 54.75493688417786, 50.74348797741, 35.32516498204882, 32.338540519381574, 29.600092865092062, 65.41800686900632, 45.3007087638476, 89.3478528751401, 69.71173067120073, 66.84210697672502, 69.23085190145025, 67.40275504121921, 37.051129652843706, 111.02578449862729, 45.590961189014116, 72.99920524809086, 49.55161261991707, 46.27595126991051, 56.265043046158574, 39.43370084593798, 43.94646756592102, 42.382106398255814, 40.45115102722028, 45.113365872061046, 49.044178100302325, 3.0162764925791987, 0.6060635078781933, 1.8195550169205572, 11.208456349944191, 0.5409863485333571, 2.458868785274318, 0.784158499502632, 0.5277449221804431, 2.0881643595838444, 2.8253914739794745, 1.7374865917832707, 1.5360680442123331, 1.1669305680342743, 1.1517284819311082, 5.820369789232303, 0.47619863265561896, 0.4789443998735819, 1.2587551700547048, 0.48481608397124626, 1.4557813608563703, 0.5098564360637062, 2.2554459936266036, 7.0969245079798995, 6.516035506656039, 0.46928854404171, 2.8107446004937033, 0.6211695814743324, 0.7800356308376367, 0.4619600277519244, 7.626249577424077, 1.9909552564371635, 3.3963603016202804, 39.07778154118528, 1.304396259542945, 1.581125076513283, 1.8066754629311614, 3.351398692236092, 31.70562323573511, 36.43123601541568, 41.460579576324335, 109.91661143127882, 5.170098893978357, 38.99848546018099, 38.85402314634872, 19.03841462494149, 22.122671963568358, 42.105635591036005, 85.69955520294772, 31.22364970249151, 77.07190705974371, 11.164188824361391, 30.620266290546358, 52.57505777777494, 45.86704587558526, 152.4039386893621, 51.25154845313451, 49.579042327892594, 20.48492735471091, 38.466984893364554, 30.21189684318097, 26.502187638277693, 50.36532135681353, 37.66194637209284, 110.61297957747385, 67.97450241923984, 61.44427175594734, 57.588117762621735, 29.184069394881018, 72.03866240681596, 45.04273990727279, 43.35467585552613, 68.25902670798997, 47.20259808027572, 48.09641256836599, 57.56977334181764, 46.99316400769679, 42.71138462053738, 44.39767228216821, 48.03692672027119, 46.97579485989747, 41.61161337254592, 42.57780124486552, 39.93064907606616, 2.2440288327599047, 1.2230277942481964, 1.432744658172145, 2.1626006949842926, 1.0895396764444791, 0.6502616873571982, 0.645655849491246, 0.8648302557406632, 0.633818423195088, 0.6134496514012409, 0.7799352027676588, 1.0537684490863426, 1.2746878322531316, 1.6753968894244158, 0.5733441077832869, 0.3816332107985134, 5.656299144083867, 20.48400626119083, 0.7371935884387516, 0.5569306412278456, 0.7245757555562239, 0.36724238398063613, 7.972260416821962, 0.3654874866405563, 0.3612438713883558, 0.7104512539325868, 0.35285479129323877, 0.34755506891589094, 0.5091686025762951, 0.33503916565129793, 13.590425019953395, 16.34945664498266, 7.33619692565709, 3.7382984263487455, 2.8936327924577023, 18.24790315574234, 14.69772036344103, 8.450047742611902, 55.4930021194839, 68.11792189035681, 4.88448357110224, 46.53506827055445, 22.65617911027063, 52.47171899643147, 131.77527985812765, 11.049181631046725, 17.221756143235986, 61.72595210624333, 42.542419217929364, 24.018064042304673, 41.12666951570524, 96.45747962823536, 41.391586227952224, 26.27790522941329, 54.9452471061516, 40.778819523160415, 63.97739763598023, 24.611018391099357, 54.34100164474205, 33.540572127312196, 60.94942589503278, 48.913653356301516, 52.90812573174638, 37.75533166792284, 49.81911453833967, 42.731021497767664, 30.496248622658232, 32.592002384320566, 30.58773338000754, 32.87463602672204, 29.070149702898345, 38.643045686137306, 32.09644928937204, 27.652076659479114, 31.497352854394894, 29.22393674981296, 18.623664271562717, 2.409421524244455, 0.7873071050415245, 1.886543297601038, 1.669873812901114, 1.248667929564667, 0.7177241013314954, 0.3681211863699657, 0.34585173924495066, 0.34880771570525887, 0.8553025872261906, 1.7193978866018373, 2.7769178929321936, 1.529402420498379, 1.368529992344233, 0.5040022817955849, 0.5076822360962221, 2.3942343564579422, 2.1134533222649794, 0.5495668219749225, 2.6537744025093284, 0.49401629126385904, 0.32578277174704295, 0.4850510238167121, 0.3247159529345518, 0.9509413130213972, 0.7919685275350096, 0.6419505884088761, 0.31955176094827725, 0.3160096463000376, 6.790181771140616, 2.367801876918415, 3.273862573545967, 8.39414738802194, 1.8288640521097208, 0.9624267573042848, 3.9656779988036552, 4.660272721542338, 7.248033949966367, 8.319150853436792, 1.2147268970862841, 8.852240466574145, 9.617030096229302, 43.097159510715734, 10.706638483160873, 62.34133442289906, 1.8602595263321395, 48.85347842143353, 27.488532793861147, 25.172662964979214, 33.360810910484545, 35.0123560134658, 15.40433556539181, 8.612142716280037, 6.493981492195369, 19.910881016271627, 39.10531499385398, 17.07637606930394, 14.51611218927395, 96.20193401172338, 53.83823898279365, 32.48687375763484, 34.75169739479922, 25.518682944041085, 28.171014505513632, 49.173385074733595, 48.919735564031605, 43.77987445012886, 24.664302143507044, 44.477646901106304, 70.60951631574079, 48.841362853025394, 53.852948698574544, 37.22619483463911, 44.487712520249836, 44.97162329814795, 24.81268409985711, 32.224654149658, 34.5871940809591, 44.97861603925213, 31.4484946666715, 34.439540449896654, 28.956218724726465, 27.521935510071817, 25.87058067184267, 2.6568929489932422, 0.29003986847822294, 1.3807087454507272, 0.1915219998291267, 0.4826564243472965, 0.6531776695358625, 0.5563533214868158, 0.7273912758596283, 0.30086130733332217, 0.46062828699686503, 0.4678140155166367, 1.2886340772953933, 0.2779734649703154, 0.36622837070622344, 0.5680358571063608, 0.4567312397439775, 2.316496117871623, 1.5229635101495067, 0.6194519429232052, 0.35515033825116366, 0.45883145012275567, 0.28017112638312774, 0.18102946886505505, 0.26752325462434656, 0.38941788238793523, 0.5052978982261259, 0.820388363071008, 0.1774648372859707, 0.17623820683382374, 1.2493277097130384, 0.6427577652969513, 0.3532529544051858, 0.7208584493857159, 7.355665626818026, 36.830757983330685, 1.0338347579300156, 5.865691748557181, 5.824053259289464, 15.25078291318276, 5.247888889585017, 2.0427468186499604, 6.885367106987758, 9.208559312348632, 1.74431056794323, 3.4074837060224707, 10.786251050541969, 13.628500581182687, 36.896078749651565, 4.947811735019872, 36.0135194671767, 10.692720780348692, 24.7650959099298, 11.70645421038523, 10.228870445756131, 51.26493497418925, 9.726191938162676, 19.36240649302956, 14.573737551160864, 85.92201330404079, 30.790035883943123, 98.40854296087821, 21.930377517900634, 26.698489886998704, 12.808691698145594, 48.55840408701387, 16.734749876758144, 22.291455895430232, 14.170724383230631, 18.208237232779684, 39.068231452507085, 40.87205458016913, 35.60693250766783, 18.714626775728068, 24.593890206851945, 26.780559847422126, 39.211361259892115, 39.005073866236344, 37.711681247280225, 22.16562243945454, 33.480719205003254, 29.349816055734756, 28.534242642879878, 41.1369914201592, 28.71625152161992, 33.753468942350906, 25.74033745966232, 37.609128334919816, 28.40548434934059, 24.790137900157344, 28.32622106958727, 24.757984682739753, 24.759000832023812, 0.7580203428117575, 8.768078094589395, 1.5331101100518107, 1.164928565182273, 0.9328923179385349, 0.4750830477301759, 0.6503460127333737, 0.5068969921018845, 1.3485447974056328, 0.4142862093671058, 0.7453511468202022, 0.9079376901462434, 0.7053742116158295, 0.2899421423213665, 0.696469116110124, 2.1788088294244803, 0.2896771202305937, 0.38856705051461066, 0.47122410343036075, 0.38110642308418136, 0.38763124394386017, 0.3233113218524378, 0.2833248059241939, 0.34587893102547496, 0.45190138909002975, 0.18128501195402585, 0.3057713982443102, 0.5898533757341139, 0.7386829630058359, 0.7603717414771779, 6.129871307549039, 1.0652751207863962, 3.2742902062981174, 3.619270342320199, 2.0197880816572336, 5.967596325081402, 2.5753396827053483, 41.1822990273209, 7.775961274236408, 0.6809075584578054, 2.695016732944872, 5.160512292471193, 72.3301687814975, 12.588756876215758, 15.377834694042763, 4.418303569557152, 9.658020509125643, 50.51174117150321, 32.65503258780531, 14.635245739495309, 27.436105069707, 35.72558800517526, 13.35082585095526, 23.178786778023067, 18.71624103133655, 49.02276437158437, 16.011807570821812, 41.944396262519646, 18.95564651446876, 88.11149432328659, 30.77867511466218, 22.328790950811666, 71.94423709909245, 43.86643976534605, 39.01740397809009, 17.544783336645036, 31.896367713837925, 27.206577045268027, 47.17679117401226, 28.978617455957476, 36.919107698380316, 21.92045985713728, 36.59455773344504, 28.74011973303116, 28.873389207787685, 26.476763531052264, 26.28596775056836, 32.57440977948068, 22.0080330256799, 30.8738905964854, 28.45170033704575, 23.944386597412493, 23.458270730623248, 23.20328602705169], \"Total\": [2239.0, 1856.0, 848.0, 1040.0, 1231.0, 951.0, 572.0, 858.0, 868.0, 645.0, 945.0, 998.0, 923.0, 991.0, 567.0, 675.0, 1217.0, 426.0, 806.0, 584.0, 905.0, 576.0, 613.0, 708.0, 493.0, 576.0, 597.0, 693.0, 393.0, 685.0, 23.7304670383137, 11.478199923032983, 9.029225577177666, 20.82215687523241, 12.515546601137542, 24.92639834458976, 11.083227979071694, 20.54283081155025, 22.525288476755073, 27.02808012408152, 7.897297285891346, 10.01770970588273, 62.050911826590536, 6.631291160992507, 4.409204109137385, 35.68349050189556, 4.372854543241474, 4.501799080323587, 4.427539719949783, 64.82674307330922, 12.020548455063466, 5.5111032869869385, 22.178367980391226, 5.440844158693195, 5.5023235347324375, 47.53653285159343, 12.053769845555276, 7.638159453448944, 12.943330370057865, 10.962117596803976, 70.61492320388231, 143.14667887913356, 257.9144648258589, 37.43679083581923, 95.7752938980441, 325.52773800409335, 32.79072423916325, 34.05952101732984, 149.1462847307697, 1217.2435515927168, 68.49637232543705, 514.3168702571161, 905.234742153093, 551.6099888182378, 576.0221289917465, 951.9854253170032, 1856.5411335120139, 806.8142834651755, 1231.7897140314715, 314.07390188832574, 576.2323058202988, 991.0633719680822, 425.4406959480293, 450.03556037230123, 320.6636177463914, 685.4351987541309, 2239.988224374073, 693.6642006287484, 365.65013298586126, 613.4213066231706, 385.0615175821285, 998.0953156265108, 479.771478258988, 708.5788237868262, 350.89140141937685, 858.431874462405, 597.4505267696616, 923.4022434628255, 617.7746282636356, 675.401920758962, 945.0648154738091, 1040.1251313282637, 848.4374957036864, 645.5676300438499, 555.0564525974575, 868.3732689588726, 624.4475945616518, 16.68295765314627, 19.53494015905207, 3.7322069123153265, 15.300534743931914, 4.7193750857689025, 3.959663559926967, 7.056615829617749, 6.731523766138102, 8.896689068484516, 2.855162223901303, 8.130006062236578, 358.0434086651602, 6.388889599313037, 2.86909425984507, 3.709393941522461, 4.703232469065899, 7.592370352060152, 6.5709976239753125, 1.8783592975008532, 18.909812744672006, 7.05571774401533, 5.7076603660343235, 1.8480957432951437, 1.858051204113548, 3.7326415122828314, 1.8656966414118774, 8.758110449248615, 6.741994584489092, 1.8644977948144366, 2.920424001811511, 51.53471182710753, 25.9787737147475, 9.79437898805584, 17.89897507821346, 220.21328998790202, 188.7766928940107, 101.62299528372607, 32.149715062387955, 572.1814504764349, 40.75199509848608, 145.2298254811496, 330.02539591896823, 99.8402540013667, 341.2870280921357, 57.02482781920549, 146.85638312364748, 858.431874462405, 459.6805590036915, 564.4222383309408, 264.180674882214, 145.39438386274233, 194.37538982560895, 192.4782680679459, 951.9854253170032, 998.0953156265108, 87.46490362206086, 393.05205244798344, 693.6642006287484, 923.4022434628255, 1231.7897140314715, 945.0648154738091, 335.26724078545055, 516.8450856617023, 991.0633719680822, 1856.5411335120139, 708.5788237868262, 555.0564525974575, 685.4351987541309, 1217.2435515927168, 1040.1251313282637, 675.401920758962, 2239.988224374073, 624.4475945616518, 645.5676300438499, 471.76820581731903, 806.8142834651755, 868.3732689588726, 617.7746282636356, 613.4213066231706, 905.234742153093, 568.0543007547005, 5.758389196633115, 3.8583857349917077, 2.7996438582627263, 12.194140878252512, 24.3720377045445, 4.774293218845011, 1.8601551264563008, 1.860155957855365, 4.543450778063774, 1.8480043934678712, 1.8588467641413593, 3.8043595375332653, 1.848201823200907, 6.477911852550058, 1.8583179270442705, 1.8621806684297744, 3.8128835468417726, 1.848121486410936, 1.8256647467587828, 1.8724229333564382, 4.427389859004942, 1.8496218494365968, 3.795908245170708, 2.6581342621353974, 10.976383394496407, 1.8137246324940397, 1.8383927492365881, 16.270559141820982, 1.8262257423302506, 1.8420917764883635, 18.97107791610233, 61.851001965641046, 142.95972323458398, 868.3732689588726, 10.586143933647708, 2239.988224374073, 30.03800128636601, 173.56456758416397, 366.39852900723304, 21.353105904211503, 479.771478258988, 95.92525133575516, 624.4475945616518, 923.4022434628255, 209.1218207175375, 945.0648154738091, 459.6805590036915, 30.54485646410113, 458.127757721432, 307.571701612979, 82.77073439552858, 120.28876687842536, 1856.5411335120139, 197.3515516981792, 274.5199609072807, 564.4222383309408, 848.4374957036864, 617.7746282636356, 200.05463325579302, 1040.1251313282637, 551.6099888182378, 1217.2435515927168, 229.86174707804406, 365.65013298586126, 516.8450856617023, 991.0633719680822, 998.0953156265108, 1231.7897140314715, 387.6554644676564, 413.85554791507997, 905.234742153093, 438.6370328292319, 708.5788237868262, 806.8142834651755, 858.431874462405, 685.4351987541309, 568.0543007547005, 584.0688649225812, 567.9798472937256, 645.5676300438499, 951.9854253170032, 675.401920758962, 8.628286903076052, 9.709211733824775, 2.7609157761562244, 15.365165587469546, 4.569358992747446, 8.247710886518691, 23.109157226648247, 10.661626191727034, 3.8090408327826815, 9.151294413106028, 10.296584792567106, 3.795004876945635, 4.658924488233987, 5.630531749689141, 4.550614120993042, 3.656610111767326, 40.155675139525094, 5.657163527506958, 1.8228760182011627, 848.4374957036864, 18.668266471230883, 1.8366352957039087, 16.37099482784317, 5.697521967966041, 5.616169601691365, 3.687960008472553, 1.8213979687135462, 2.7445107349910085, 2.7132638187138967, 4.777529345611833, 20.978098842646435, 9.48711408265042, 27.92720767885405, 28.71739724587907, 33.216337979027664, 8.357909448143493, 8.838681145188213, 50.82388305259856, 11.373756074090172, 247.69173930490945, 330.02539591896823, 11.456168062593317, 329.85619082081865, 53.61733504684368, 159.67262577872165, 55.923423549962585, 133.48034563671914, 45.73061683262384, 572.1814504764349, 232.07151053390578, 95.21446187048292, 905.234742153093, 584.0688649225812, 127.70684723641666, 2239.988224374073, 173.56456758416397, 868.3732689588726, 991.0633719680822, 196.7939184011623, 452.9844628822401, 261.47036613793586, 1856.5411335120139, 998.0953156265108, 227.7338043467585, 1040.1251313282637, 192.4782680679459, 708.5788237868262, 1231.7897140314715, 675.401920758962, 307.571701612979, 568.0543007547005, 417.4457184844881, 458.127757721432, 274.5199609072807, 945.0648154738091, 923.4022434628255, 438.92340048640676, 613.4213066231706, 342.9716276547541, 429.0393832114925, 617.7746282636356, 485.90404725058494, 405.0075013152895, 597.4505267696616, 1217.2435515927168, 551.6099888182378, 951.9854253170032, 645.5676300438499, 693.6642006287484, 567.9798472937256, 858.431874462405, 22.721331730471437, 6.094860596756648, 5.961188681037065, 6.846971303989947, 2.5307531368145573, 2.5768301615457334, 8.745909995555255, 4.628561665573481, 2.539403004738796, 1.7143256149756385, 4.33192040234295, 2.5333545701111166, 1.706056582221183, 1.712529927040577, 33.61868551818231, 1.7024018578086544, 2.6511695168364113, 1.733099628372852, 1.7797677911213436, 5.066090319509237, 5.639295278842535, 1.7211248875451546, 4.17079319740543, 20.141412442709093, 1.750172685232168, 2.6921474099220197, 1.739598423724102, 2.544664672603569, 7.044534144872916, 11.070027193903893, 36.51087036061255, 56.41477074437505, 63.66410420289557, 20.978098842646435, 26.918631351171577, 156.6279269075028, 30.850642643626877, 44.33802522912564, 30.801168718242394, 417.4457184844881, 41.32077324127264, 41.77351823892299, 25.78795047919045, 70.85739188254517, 848.4374957036864, 584.0688649225812, 275.29803093271795, 292.8780556900463, 858.431874462405, 868.3732689588726, 493.25969235369666, 1040.1251313282637, 249.7199907917348, 232.07151053390578, 1856.5411335120139, 555.0564525974575, 693.6642006287484, 572.1814504764349, 613.4213066231706, 568.0543007547005, 366.39852900723304, 332.9259547514261, 298.7263658030657, 806.8142834651755, 514.3168702571161, 1217.2435515927168, 923.4022434628255, 905.234742153093, 951.9854253170032, 998.0953156265108, 438.92340048640676, 2239.988224374073, 597.4505267696616, 1231.7897140314715, 708.5788237868262, 645.5676300438499, 945.0648154738091, 485.90404725058494, 624.4475945616518, 576.0221289917465, 516.8450856617023, 685.4351987541309, 991.0633719680822, 12.43179581331003, 2.5381900680324567, 8.16529371730733, 51.53471182710753, 2.5289736918684858, 11.572711276664132, 3.6930705343365853, 2.5201672283583596, 10.055893416625427, 13.635281382918945, 8.592691969849145, 7.6235083381891995, 5.939237997811217, 5.877837119722132, 29.912027566166334, 2.4650524496700683, 2.489998142199994, 6.5709976239753125, 2.5369532958010526, 7.677087197937837, 2.699984734697971, 12.024367552658077, 37.868406271668945, 35.16917402156688, 2.53431926456625, 15.19604030806952, 3.363871471119259, 4.236186979165574, 2.512620472788938, 41.51066792368724, 10.874955921265714, 18.660941700162574, 220.21328998790202, 7.112901097968258, 8.692426089175619, 10.121401874616355, 19.53494015905207, 226.86262727535154, 271.28765413942995, 330.02539591896823, 1040.1251313282637, 32.911514156621394, 349.9179775036546, 358.0434086651602, 156.6279269075028, 188.00626499919247, 405.0075013152895, 945.0648154738091, 287.4920547184154, 848.4374957036864, 85.4845455004718, 292.8780556900463, 572.1814504764349, 493.25969235369666, 2239.988224374073, 584.0688649225812, 567.9798472937256, 184.57532341933955, 415.20296135614603, 307.571701612979, 263.5062193858428, 613.4213066231706, 418.84126529407746, 1856.5411335120139, 998.0953156265108, 868.3732689588726, 806.8142834651755, 305.1017864735014, 1231.7897140314715, 597.4505267696616, 564.4222383309408, 1217.2435515927168, 675.401920758962, 708.5788237868262, 991.0633719680822, 685.4351987541309, 576.2323058202988, 693.6642006287484, 905.234742153093, 858.431874462405, 617.7746282636356, 923.4022434628255, 555.0564525974575, 6.5173880382828315, 3.6698529771492985, 4.387337262680893, 6.671348544766914, 3.7590244094513263, 2.275898160699471, 2.2675386284113865, 3.1022874478530023, 2.2912192136727265, 2.3043116007352555, 3.001477344087929, 4.167214840276182, 5.046965689599062, 6.75518203387527, 2.3721276515339924, 1.5884132848915624, 23.693192757329722, 86.28678014894292, 3.110723200497824, 2.365250966477273, 3.095068179963626, 1.5771790508317458, 34.50518569033066, 1.584432169918823, 1.610445874908126, 3.1968551034339736, 1.6046029757459026, 1.5933824241462395, 2.336137473084232, 1.5798956070775274, 64.5168816093299, 96.12028385364788, 41.13753992712995, 20.57659706669567, 16.257058407656963, 133.48034563671914, 106.97974637918526, 59.16778710767263, 645.5676300438499, 858.431874462405, 33.709890372147434, 567.9798472937256, 231.7854324594646, 675.401920758962, 2239.988224374073, 94.0381608672271, 170.56455340410537, 923.4022434628255, 584.0688649225812, 275.29803093271795, 576.0221289917465, 1856.5411335120139, 597.4505267696616, 329.85619082081865, 945.0648154738091, 624.4475945616518, 1217.2435515927168, 305.1017864735014, 998.0953156265108, 485.90404725058494, 1231.7897140314715, 905.234742153093, 1040.1251313282637, 617.7746282636356, 991.0633719680822, 806.8142834651755, 450.03556037230123, 516.8450856617023, 459.6805590036915, 568.0543007547005, 426.2821689192774, 951.9854253170032, 613.4213066231706, 405.0075013152895, 708.5788237868262, 576.2323058202988, 73.01124568966127, 10.18252077426265, 3.410059950886166, 8.414750809669561, 7.63275072020346, 5.810427452250762, 3.3990419283934137, 1.7495065067202022, 1.6709845812091462, 1.7018350178397748, 4.247363544151764, 8.54299833081615, 13.812254862886856, 7.653940764234123, 6.857081174425484, 2.530362912897878, 2.558831081745376, 12.086794511039878, 10.67248199843532, 2.799955373533864, 13.59849058335967, 2.549134086284719, 1.684553139300283, 2.517575659296201, 1.69262266959548, 5.055913263854821, 4.224797489808147, 3.424832097871026, 1.707245965500007, 1.6996070944115491, 38.32214910161389, 13.154212268455618, 18.371191924678065, 50.364455612286704, 10.37513858468335, 5.258393375630935, 24.129707042445077, 28.867136569610906, 48.36968347466641, 57.02482781920549, 6.792462442606129, 63.573836094716555, 70.61492320388231, 393.05205244798344, 83.02048281389031, 645.5676300438499, 11.1859303368818, 567.9798472937256, 287.4920547184154, 259.77589361347157, 366.39852900723304, 426.2821689192774, 149.1462847307697, 72.5925827681601, 50.280020722187786, 220.21328998790202, 572.1814504764349, 188.7766928940107, 151.5949440149293, 2239.988224374073, 998.0953156265108, 493.25969235369666, 555.0564525974575, 358.0434086651602, 415.20296135614603, 945.0648154738091, 951.9854253170032, 806.8142834651755, 342.9716276547541, 858.431874462405, 1856.5411335120139, 1040.1251313282637, 1231.7897140314715, 685.4351987541309, 923.4022434628255, 991.0633719680822, 367.8169486172595, 597.4505267696616, 708.5788237868262, 1217.2435515927168, 675.401920758962, 905.234742153093, 613.4213066231706, 693.6642006287484, 576.2323058202988, 22.445336011463144, 2.4931295634899593, 12.194140878252512, 1.7264029943084116, 4.427389859004942, 6.0087548087915925, 5.137248295439671, 6.7165771464157045, 2.799906662327176, 4.308022013041662, 4.382166953387052, 12.079624327400609, 2.6104727792012046, 3.442991420871335, 5.378662656930869, 4.3460285674954555, 22.11946480480162, 14.598500460643885, 5.951915672504626, 3.416364682808376, 4.430678487715327, 2.709951722133967, 1.7516654883969953, 2.588697365328967, 3.77058726683825, 4.915088096296034, 7.9989678419679455, 1.730801169966512, 1.7201394363684896, 12.235152543228704, 6.33373581311061, 3.4687211504670823, 7.173034628978935, 79.30671969437039, 426.2821689192774, 10.490946340311174, 64.03554746438462, 64.20290735597713, 181.56775682612508, 59.704789068810314, 21.89000179894163, 81.34376151925258, 113.51078728840845, 18.710909393387077, 38.89659468039868, 139.80241373651475, 181.87583884817272, 576.0221289917465, 60.61200213177305, 564.4222383309408, 145.6847809825016, 378.8653260241636, 163.39743797438902, 142.59950550641972, 951.9854253170032, 139.66820561105644, 313.36365696949133, 226.86262727535154, 1856.5411335120139, 551.6099888182378, 2239.988224374073, 370.4961798872831, 471.76820581731903, 196.7939184011623, 1040.1251313282637, 279.1686265697467, 404.557713800251, 226.34622245317343, 314.07390188832574, 868.3732689588726, 923.4022434628255, 806.8142834651755, 332.5739671043607, 493.25969235369666, 568.0543007547005, 998.0953156265108, 991.0633719680822, 945.0648154738091, 437.4116713379054, 848.4374957036864, 693.6642006287484, 675.401920758962, 1231.7897140314715, 685.4351987541309, 905.234742153093, 584.0688649225812, 1217.2435515927168, 708.5788237868262, 576.2323058202988, 858.431874462405, 597.4505267696616, 617.7746282636356, 5.381578606715841, 73.01124568966127, 13.154212268455618, 10.18252077426265, 8.24487157372726, 4.247363544151764, 5.877989367502315, 4.586614265940933, 12.211904212489884, 3.7590244094513263, 6.792462442606129, 8.414750809669561, 6.55825146514579, 2.7107933048886808, 6.5173880382828315, 20.485315510935546, 2.7274094001412257, 3.6698529771492985, 4.458378077715498, 3.633069557734109, 3.6965296945742994, 3.095068179963626, 2.7322234927626665, 3.352950421258276, 4.387337262680893, 1.7708571912596192, 3.001477344087929, 5.810427452250762, 7.387939061082608, 7.63275072020346, 63.573836094716555, 10.782051864641064, 34.50518569033066, 38.315214091762435, 21.149692171212454, 67.49991789827762, 27.822339815872578, 572.1814504764349, 95.21446187048292, 6.857081174425484, 31.301079411946677, 64.5168816093299, 1231.7897140314715, 180.37344960293677, 228.60814576439788, 56.41477074437505, 139.66820561105644, 951.9854253170032, 576.2323058202988, 226.86262727535154, 485.90404725058494, 675.401920758962, 209.28191158625893, 404.557713800251, 318.66792693087064, 1040.1251313282637, 267.2717789856171, 868.3732689588726, 332.2483234006182, 2239.988224374073, 613.4213066231706, 418.84126529407746, 1856.5411335120139, 991.0633719680822, 858.431874462405, 314.07390188832574, 708.5788237868262, 576.0221289917465, 1217.2435515927168, 645.5676300438499, 945.0648154738091, 438.92340048640676, 998.0953156265108, 685.4351987541309, 693.6642006287484, 617.7746282636356, 624.4475945616518, 923.4022434628255, 459.6805590036915, 905.234742153093, 806.8142834651755, 567.9798472937256, 597.4505267696616, 584.0688649225812], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.1217, -8.9237, -9.1687, -8.3444, -8.8659, -8.1786, -9.0027, -8.3871, -8.3064, -8.1249, -9.3587, -9.131, -7.3086, -9.5471, -9.9631, -7.8745, -9.9759, -9.9498, -9.9712, -7.2907, -8.9761, -9.7574, -8.3721, -9.788, -9.7798, -7.6274, -9.0041, -9.4665, -8.94, -9.1183, -7.2613, -6.5876, -6.0229, -7.9132, -7.0219, -5.868, -8.0492, -8.0169, -6.6237, -4.6759, -7.381, -5.5187, -5.0044, -5.4786, -5.4399, -5.0056, -4.426, -5.1708, -4.7989, -6.0271, -5.4956, -5.0315, -5.7751, -5.7322, -6.0305, -5.3863, -4.3929, -5.4091, -5.9484, -5.5459, -5.937, -5.1813, -5.7659, -5.468, -6.0152, -5.3583, -5.6271, -5.3492, -5.6269, -5.5703, -5.36, -5.3303, -5.4686, -5.6332, -5.7077, -5.572, -5.7146, -8.181, -8.0337, -9.7768, -8.3984, -9.5779, -9.7719, -9.1941, -9.2435, -8.9649, -10.1074, -9.0645, -5.3017, -9.3522, -10.1593, -9.9085, -9.6712, -9.1942, -9.3467, -10.6088, -8.3013, -9.2883, -9.5176, -10.6465, -10.6417, -9.9445, -10.6394, -9.0976, -9.3761, -10.6619, -10.2149, -7.3571, -8.0407, -9.0134, -8.4356, -6.0053, -6.1775, -6.7759, -7.8828, -5.2238, -7.6821, -6.5091, -5.7563, -6.857, -5.7716, -7.4073, -6.5702, -5.0245, -5.5786, -5.4025, -6.0744, -6.6014, -6.3579, -6.3682, -5.005, -4.9809, -7.0639, -5.818, -5.3473, -5.1302, -4.903, -5.1378, -5.9793, -5.6347, -5.1327, -4.6465, -5.4052, -5.6065, -5.453, -5.0422, -5.159, -5.4705, -4.6089, -5.5643, -5.5666, -5.7646, -5.4585, -5.4254, -5.6629, -5.7005, -5.6758, -5.7454, -9.1218, -9.5574, -9.8811, -8.4551, -7.8259, -9.4688, -10.4609, -10.4779, -9.5944, -10.5009, -10.5065, -9.7974, -10.5292, -9.2791, -10.5327, -10.5319, -9.8197, -10.5634, -10.5813, -10.5568, -9.7049, -10.5811, -9.8625, -10.2255, -8.8085, -10.6117, -10.6097, -8.4368, -10.6303, -10.6228, -8.3065, -7.1984, -6.4208, -4.7771, -8.9376, -3.9103, -7.9625, -6.3448, -5.6704, -8.2917, -5.4887, -6.9616, -5.2763, -4.9377, -6.2909, -4.9649, -5.6072, -8.0043, -5.6241, -5.986, -7.1314, -6.8122, -4.4668, -6.3921, -6.1187, -5.5176, -5.186, -5.4643, -6.3994, -5.0478, -5.6161, -4.9998, -6.3188, -5.9552, -5.6857, -5.1949, -5.1988, -5.0505, -5.9179, -5.8786, -5.3709, -5.8695, -5.5602, -5.4809, -5.4756, -5.6108, -5.7316, -5.7327, -5.7617, -5.714, -5.5768, -5.7074, -8.7461, -8.7395, -10.0005, -8.3057, -9.5196, -8.9383, -7.9468, -8.7422, -9.7731, -8.8991, -8.7872, -9.7994, -9.5943, -9.4275, -9.6415, -9.8692, -7.4732, -9.4419, -10.5902, -4.4484, -8.2697, -10.591, -8.4078, -9.4689, -9.484, -9.9141, -10.6204, -10.2112, -10.2237, -9.6607, -8.1946, -8.9884, -7.9334, -7.9077, -7.7746, -9.1233, -9.0706, -7.4218, -8.8312, -5.9883, -5.75, -8.8288, -5.7821, -7.4273, -6.4768, -7.4102, -6.6472, -7.5924, -5.3703, -6.1664, -6.9494, -5.0059, -5.4062, -6.714, -4.3272, -6.478, -5.1892, -5.0884, -6.3936, -5.7279, -6.1782, -4.6312, -5.1332, -6.2933, -5.1316, -6.4333, -5.4463, -5.0306, -5.4893, -6.0879, -5.654, -5.8834, -5.8244, -6.1831, -5.3583, -5.3767, -5.882, -5.6748, -6.0439, -5.9108, -5.709, -5.8471, -5.9505, -5.7646, -5.4435, -5.8096, -5.5904, -5.7466, -5.7389, -5.8219, -5.841, -7.8626, -9.2366, -9.2672, -9.1804, -10.1983, -10.2139, -9.0052, -9.6468, -10.2475, -10.6434, -9.7219, -10.266, -10.6674, -10.6767, -7.7066, -10.6898, -10.2495, -10.6761, -10.6656, -9.6279, -9.5231, -10.71, -9.8339, -8.2598, -10.7153, -10.2864, -10.7233, -10.3472, -9.3327, -8.8815, -7.6897, -7.2648, -7.1822, -8.2722, -8.0415, -6.3481, -7.9303, -7.599, -7.9416, -5.4926, -7.6728, -7.6685, -8.1324, -7.2069, -4.9244, -5.2806, -6.0099, -5.9657, -5.034, -5.0291, -5.535, -4.8822, -6.1452, -6.2281, -4.4751, -5.4943, -5.3167, -5.4785, -5.4614, -5.5375, -5.8997, -5.988, -6.0765, -5.2835, -5.6509, -4.9717, -5.2199, -5.2619, -5.2268, -5.2536, -5.852, -4.7545, -5.6445, -5.1738, -5.5612, -5.6296, -5.4342, -5.7896, -5.6813, -5.7175, -5.7642, -5.6551, -5.5715, -8.3268, -9.9316, -8.8322, -7.0141, -10.0452, -8.5311, -9.6739, -10.0699, -8.6945, -8.3922, -8.8784, -9.0016, -9.2764, -9.2895, -7.6694, -10.1727, -10.167, -9.2007, -10.1548, -9.0553, -10.1044, -8.6175, -7.4711, -7.5565, -10.1873, -8.3974, -9.907, -9.6792, -10.2031, -7.3992, -8.7422, -8.2081, -5.7653, -9.1651, -8.9727, -8.8393, -8.2214, -5.9743, -5.8354, -5.7061, -4.7311, -7.7879, -5.7673, -5.771, -6.4843, -6.3342, -5.6906, -4.98, -5.9896, -5.0861, -7.0181, -6.0091, -5.4686, -5.6051, -4.4043, -5.4941, -5.5272, -6.4111, -5.781, -6.0226, -6.1536, -5.5115, -5.8022, -4.7248, -5.2117, -5.3127, -5.3775, -6.0572, -5.1536, -5.6232, -5.6614, -5.2075, -5.5764, -5.5576, -5.3778, -5.5808, -5.6763, -5.6376, -5.5588, -5.5812, -5.7024, -5.6795, -5.7437, -8.4009, -9.0079, -8.8496, -8.4379, -9.1235, -9.6396, -9.6467, -9.3544, -9.6652, -9.6979, -9.4578, -9.1568, -8.9665, -8.6932, -9.7655, -10.1725, -7.4764, -6.1896, -9.5141, -9.7945, -9.5314, -10.2109, -7.1332, -10.2157, -10.2274, -9.5511, -10.2509, -10.266, -9.8842, -10.3027, -6.5998, -6.415, -7.2164, -7.8906, -8.1467, -6.3052, -6.5215, -7.075, -5.1929, -4.988, -7.6231, -5.369, -6.0888, -5.2489, -4.3281, -6.8068, -6.363, -5.0865, -5.4587, -6.0304, -5.4925, -4.6401, -5.4861, -5.9405, -5.2029, -5.501, -5.0507, -6.006, -5.2139, -5.6965, -5.0992, -5.3191, -5.2406, -5.5781, -5.3008, -5.4543, -5.7916, -5.7251, -5.7886, -5.7165, -5.8395, -5.5548, -5.7405, -5.8895, -5.7593, -5.8342, -6.1566, -8.2016, -9.3202, -8.4463, -8.5683, -8.8589, -9.4127, -10.0804, -10.1428, -10.1343, -9.2373, -8.539, -8.0597, -8.6561, -8.7673, -9.7662, -9.7589, -8.208, -8.3327, -9.6796, -8.105, -9.7862, -10.2025, -9.8045, -10.2058, -9.1313, -9.3142, -9.5243, -10.2219, -10.233, -7.1655, -8.2191, -7.895, -6.9535, -8.4773, -9.1193, -7.7033, -7.5419, -7.1003, -6.9625, -8.8865, -6.9003, -6.8175, -5.3176, -6.7102, -4.9484, -8.4603, -5.1922, -5.7672, -5.8553, -5.5736, -5.5253, -6.3464, -6.9278, -7.2101, -6.0897, -5.4148, -6.2433, -6.4058, -4.5146, -5.095, -5.6002, -5.5328, -5.8416, -5.7427, -5.1857, -5.1908, -5.3018, -5.8757, -5.286, -4.8239, -5.1924, -5.0948, -5.464, -5.2858, -5.275, -5.8697, -5.6083, -5.5375, -5.2748, -5.6327, -5.5418, -5.7152, -5.766, -5.8279, -7.9857, -10.2006, -8.6402, -10.6156, -9.6913, -9.3887, -9.5492, -9.2811, -10.1639, -9.738, -9.7225, -8.7092, -10.2431, -9.9673, -9.5284, -9.7465, -8.1228, -8.5422, -9.4417, -9.998, -9.7419, -10.2352, -10.6719, -10.2814, -9.9059, -9.6454, -9.1608, -10.6918, -10.6987, -8.7402, -9.4048, -10.0034, -9.2901, -6.9674, -5.3565, -8.9296, -7.1937, -7.2008, -6.2382, -7.305, -8.2485, -7.0334, -6.7427, -8.4065, -7.7369, -6.5846, -6.3507, -5.3547, -7.3639, -5.3789, -6.5933, -5.7534, -6.5027, -6.6376, -5.0258, -6.688, -5.9995, -6.2836, -4.5094, -5.5356, -4.3737, -5.875, -5.6782, -6.4127, -5.0801, -6.1453, -5.8586, -6.3116, -6.061, -5.2975, -5.2524, -5.3903, -6.0335, -5.7603, -5.6751, -5.2939, -5.2991, -5.3329, -5.8643, -5.4519, -5.5835, -5.6117, -5.2459, -5.6054, -5.4437, -5.7148, -5.3356, -5.6162, -5.7524, -5.619, -5.7537, -5.7536, -9.1803, -6.7322, -8.476, -8.7506, -8.9728, -9.6476, -9.3336, -9.5827, -8.6043, -9.7845, -9.1972, -8.9999, -9.2523, -10.1414, -9.265, -8.1245, -10.1423, -9.8486, -9.6557, -9.868, -9.851, -10.0324, -10.1645, -9.965, -9.6976, -10.611, -10.0882, -9.4312, -9.2062, -9.1773, -7.0901, -8.8401, -7.7172, -7.617, -8.2003, -7.117, -7.9573, -5.1853, -6.8523, -9.2876, -7.9119, -7.2623, -4.6221, -6.3705, -6.1704, -7.4175, -6.6355, -4.9811, -5.4173, -6.2199, -5.5914, -5.3274, -6.3117, -5.7601, -5.9739, -5.011, -6.13, -5.167, -5.9612, -4.4247, -5.4765, -5.7974, -4.6274, -5.1222, -5.2393, -6.0385, -5.4408, -5.5998, -5.0494, -5.5367, -5.2946, -5.8159, -5.3034, -5.545, -5.5404, -5.627, -5.6343, -5.4198, -5.8119, -5.4734, -5.5551, -5.7276, -5.7481, -5.759], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7804, 0.7047, 0.6997, 0.6884, 0.6759, 0.6743, 0.6607, 0.6592, 0.6478, 0.647, 0.6436, 0.6335, 0.6323, 0.63, 0.622, 0.6196, 0.6176, 0.6146, 0.6098, 0.6064, 0.6061, 0.6047, 0.5976, 0.5868, 0.5839, 0.58, 0.5754, 0.5692, 0.5682, 0.5561, 0.5503, 0.5174, 0.4933, 0.5329, 0.4849, 0.4154, 0.5295, 0.5239, 0.4402, 0.2886, 0.4611, 0.3073, 0.2562, 0.2774, 0.2728, 0.2047, 0.1163, 0.205, 0.1537, 0.2921, 0.2167, 0.1385, 0.2406, 0.2273, 0.2679, 0.1524, -0.0383, 0.1178, 0.2188, 0.1038, 0.1784, -0.0183, 0.1296, 0.0376, 0.1932, -0.0446, 0.0491, -0.1084, 0.0158, -0.0168, -0.1424, -0.2086, -0.1432, -0.0345, 0.0421, -0.2698, -0.0826, 1.0734, 1.0629, 0.975, 0.9425, 0.9392, 0.9208, 0.9207, 0.9185, 0.9182, 0.9123, 0.9088, 0.8865, 0.862, 0.8555, 0.8494, 0.8494, 0.8475, 0.8395, 0.8296, 0.8278, 0.8267, 0.8094, 0.8082, 0.8076, 0.8072, 0.8058, 0.8012, 0.7844, 0.784, 0.7821, 0.7694, 0.7708, 0.7737, 0.7485, 0.6689, 0.6507, 0.6716, 0.7156, 0.4956, 0.6793, 0.5814, 0.5133, 0.6082, 0.4645, 0.6181, 0.5092, 0.2892, 0.3597, 0.3306, 0.4178, 0.488, 0.4411, 0.4406, 0.2053, 0.182, 0.5337, 0.2769, 0.1795, 0.1105, 0.0496, 0.0797, 0.2746, 0.1864, 0.0374, -0.1042, 0.1004, 0.1433, 0.0858, -0.0778, -0.0373, 0.083, -0.2543, 0.0677, 0.0321, 0.1478, -0.0828, -0.1232, -0.0202, -0.0508, -0.4152, -0.0188, 1.1963, 1.1611, 1.1582, 1.1127, 1.0495, 1.0368, 0.9872, 0.9703, 0.9608, 0.9538, 0.9423, 0.9352, 0.9254, 0.9214, 0.9164, 0.9152, 0.9107, 0.8912, 0.8856, 0.8848, 0.8761, 0.8728, 0.8724, 0.8657, 0.8645, 0.8618, 0.8502, 0.8427, 0.8363, 0.8352, 0.8194, 0.7457, 0.6855, 0.5251, 0.7717, 0.4443, 0.7039, 0.5675, 0.4947, 0.7159, 0.4068, 0.5437, 0.3557, 0.3031, 0.435, 0.2527, 0.3311, 0.6453, 0.3176, 0.3541, 0.5214, 0.4667, 0.0756, 0.3917, 0.3351, 0.2155, 0.1395, 0.1784, 0.3709, 0.0739, 0.1399, -0.0354, 0.3125, 0.2119, 0.1354, -0.0248, -0.0358, -0.0979, 0.1908, 0.1647, -0.1103, 0.1156, -0.0546, -0.1051, -0.1619, -0.072, -0.005, -0.0339, -0.035, -0.1153, -0.3665, -0.1539, 1.1677, 1.0563, 1.0528, 1.031, 1.0299, 1.0206, 0.9818, 0.9599, 0.9584, 0.9558, 0.9498, 0.9358, 0.9357, 0.9131, 0.912, 0.9031, 0.9028, 0.894, 0.8782, 0.877, 0.8723, 0.8699, 0.8655, 0.8599, 0.8591, 0.8496, 0.8488, 0.848, 0.847, 0.8442, 0.8307, 0.8305, 0.8058, 0.8037, 0.7912, 0.8224, 0.8191, 0.7187, 0.8063, 0.5683, 0.5197, 0.8015, 0.4881, 0.6597, 0.5189, 0.6346, 0.5277, 0.6536, 0.3491, 0.4553, 0.5633, 0.2547, 0.2926, 0.5051, 0.0274, 0.4343, 0.113, 0.0817, 0.393, 0.2251, 0.3243, -0.0888, 0.0298, 0.3473, -0.0099, 0.3755, 0.0593, -0.078, 0.0642, 0.2522, 0.0726, 0.1512, 0.1173, 0.2707, -0.1407, -0.1359, 0.1025, -0.025, 0.1873, 0.0964, -0.0663, 0.0357, 0.1144, -0.0884, -0.4791, -0.0536, -0.3801, -0.1479, -0.212, -0.0952, -0.5273, 1.0829, 1.0247, 1.0163, 0.9646, 0.942, 0.9084, 0.8951, 0.8898, 0.8894, 0.8864, 0.881, 0.8732, 0.8673, 0.8541, 0.8472, 0.847, 0.8443, 0.8428, 0.8267, 0.8184, 0.816, 0.8158, 0.8068, 0.8063, 0.7938, 0.792, 0.7918, 0.7876, 0.7839, 0.7831, 0.7815, 0.7713, 0.733, 0.7532, 0.7345, 0.6669, 0.7093, 0.6779, 0.6996, 0.542, 0.6746, 0.6681, 0.6865, 0.6013, 0.401, 0.4182, 0.4411, 0.4233, 0.2798, 0.2731, 0.3328, 0.2395, 0.4033, 0.3936, 0.0672, 0.2554, 0.2101, 0.2409, 0.1884, 0.1891, 0.2654, 0.2729, 0.2928, 0.0923, 0.175, -0.0072, 0.0209, -0.0013, -0.0165, -0.0906, 0.1325, -0.3999, 0.0316, -0.2212, -0.0557, -0.0309, -0.2166, 0.0932, -0.0493, -0.0049, 0.0569, -0.1163, -0.4015, 1.2218, 1.2058, 1.1367, 1.1124, 1.0958, 1.0891, 1.0884, 1.0745, 1.0661, 1.064, 1.0395, 1.036, 1.0108, 1.0081, 1.0011, 0.9939, 0.9896, 0.9855, 0.9831, 0.9753, 0.9711, 0.9644, 0.9636, 0.9521, 0.9516, 0.9504, 0.9488, 0.9459, 0.9444, 0.9437, 0.9402, 0.9343, 0.909, 0.9418, 0.9337, 0.9149, 0.8752, 0.6702, 0.6303, 0.5636, 0.3906, 0.7871, 0.4438, 0.4172, 0.5306, 0.4981, 0.3743, 0.2376, 0.418, 0.2394, 0.6024, 0.3799, 0.2508, 0.2627, -0.0497, 0.2047, 0.1995, 0.4396, 0.259, 0.3175, 0.3412, 0.1383, 0.2292, -0.1824, -0.0487, -0.0105, -0.0018, 0.291, -0.201, 0.053, 0.0716, -0.243, -0.0228, -0.052, -0.2078, -0.042, 0.036, -0.1108, -0.2982, -0.2675, -0.0597, -0.4387, 0.0061, 1.7934, 1.7608, 1.7405, 1.7331, 1.6212, 1.6069, 1.6034, 1.5823, 1.5745, 1.5362, 1.512, 1.4847, 1.4835, 1.4654, 1.4396, 1.4336, 1.4272, 1.4216, 1.4199, 1.4134, 1.4076, 1.4022, 1.3945, 1.3929, 1.3649, 1.3556, 1.345, 1.3369, 1.3361, 1.3087, 1.3021, 1.0882, 1.1355, 1.1541, 1.1336, 0.8697, 0.8747, 0.9134, 0.4057, 0.3257, 0.9279, 0.3577, 0.5342, 0.3046, 0.0265, 0.7183, 0.5667, 0.1543, 0.2401, 0.4206, 0.2201, -0.0978, 0.19, 0.3297, 0.0147, 0.1309, -0.0862, 0.3422, -0.051, 0.1864, -0.1466, -0.0585, -0.1189, 0.0646, -0.1308, -0.0786, 0.1679, 0.0959, 0.1497, 0.0101, 0.1742, -0.3446, -0.0907, 0.1754, -0.2537, -0.1219, 1.6216, 1.5465, 1.5219, 1.4926, 1.4681, 1.4502, 1.4326, 1.4291, 1.4126, 1.4029, 1.3852, 1.3847, 1.3836, 1.3775, 1.3763, 1.3743, 1.3704, 1.3688, 1.3685, 1.3596, 1.3538, 1.3469, 1.3448, 1.341, 1.3367, 1.3169, 1.3136, 1.3135, 1.3121, 1.3054, 1.2573, 1.273, 1.263, 1.1961, 1.2521, 1.2897, 1.182, 1.1642, 1.0897, 1.0629, 1.2665, 1.0163, 0.9941, 0.7773, 0.9396, 0.6503, 1.1939, 0.5345, 0.6404, 0.6537, 0.5915, 0.4884, 0.7175, 0.8561, 0.9411, 0.5845, 0.3046, 0.5849, 0.6419, -0.16, 0.0679, 0.2676, 0.217, 0.3466, 0.2973, 0.0319, 0.0194, 0.0739, 0.3555, 0.0277, -0.2815, -0.0707, -0.1422, 0.0748, -0.045, -0.1049, 0.2916, 0.0679, -0.032, -0.3104, -0.0792, -0.2812, -0.0655, -0.2392, -0.1156, 0.9721, 0.9547, 0.9276, 0.9072, 0.8897, 0.8869, 0.8831, 0.8831, 0.8753, 0.8704, 0.8688, 0.8681, 0.8662, 0.8652, 0.858, 0.8531, 0.8496, 0.8457, 0.8434, 0.8422, 0.8384, 0.8367, 0.8363, 0.8363, 0.8357, 0.8311, 0.8287, 0.8284, 0.8277, 0.8243, 0.8181, 0.8216, 0.8084, 0.7281, 0.6572, 0.7888, 0.7157, 0.7059, 0.629, 0.6744, 0.7343, 0.6367, 0.5942, 0.7332, 0.6711, 0.544, 0.5148, 0.358, 0.6004, 0.3541, 0.4941, 0.3782, 0.4699, 0.4712, 0.1845, 0.4415, 0.322, 0.3609, 0.033, 0.2203, -0.0191, 0.279, 0.2341, 0.374, 0.0417, 0.2917, 0.2074, 0.3351, 0.2582, 0.0047, -0.0116, -0.0146, 0.2284, 0.1075, 0.0515, -0.1309, -0.1291, -0.1153, 0.1237, -0.1264, -0.0567, -0.0582, -0.2933, -0.0666, -0.1831, -0.016, -0.3711, -0.1107, -0.0401, -0.3053, -0.0775, -0.1109, 1.2055, 1.046, 1.0161, 0.9975, 0.9865, 0.975, 0.9641, 0.9629, 0.9621, 0.9602, 0.9558, 0.939, 0.9358, 0.9302, 0.9293, 0.9246, 0.9232, 0.9201, 0.9183, 0.9108, 0.9104, 0.9066, 0.8992, 0.894, 0.8925, 0.8864, 0.8815, 0.878, 0.8628, 0.8591, 0.8265, 0.8509, 0.8105, 0.8059, 0.8169, 0.7397, 0.7857, 0.5341, 0.6604, 0.8559, 0.7133, 0.6396, 0.3305, 0.5033, 0.4664, 0.6185, 0.494, 0.2292, 0.295, 0.4246, 0.2914, 0.2261, 0.4134, 0.306, 0.3308, 0.1107, 0.3506, 0.1352, 0.3017, -0.0701, 0.1733, 0.2339, -0.0851, 0.0479, 0.0744, 0.2806, 0.0647, 0.1128, -0.0849, 0.0619, -0.077, 0.1686, -0.1404, -0.0062, -0.0136, 0.0157, -0.0023, -0.179, 0.1264, -0.2128, -0.1794, -0.0008, -0.0719, -0.0602]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 8, 1, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 10, 1, 2, 8, 1, 2, 3, 4, 8, 7, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 1, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 7, 10, 1, 7, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 9, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 2, 3, 5, 8, 10, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 10, 2, 8, 1, 2, 3, 8, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 1, 2, 4, 7, 10, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 6, 9, 1, 2, 3, 4, 5, 6, 8, 1, 3, 1, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 9, 1, 2, 4, 5, 7, 8, 9, 1, 3, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 8, 1, 3, 4, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 1, 2, 1, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 6, 8, 1, 3, 1, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 10, 2, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 6, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 7, 9, 3, 1, 7, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 1, 1, 3, 4, 1, 3, 1, 2, 3, 4, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 8, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 10, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 1, 2, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 6, 8, 9, 2, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 1, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 5, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 3, 1, 2, 3, 4, 5, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 3, 1, 2, 3, 5, 8, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 3, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 6, 9, 1, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 2, 1, 2, 3, 4, 5, 8, 10, 1, 2, 3, 4, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 1, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 7, 1, 2, 3, 4, 7, 1, 2, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 7, 1, 2, 3, 4, 1, 2, 4, 7, 9, 3, 6, 1, 7, 2, 1, 2, 3, 4, 5, 6, 9, 1, 3, 4, 6, 7, 8, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6], \"Freq\": [0.4755044554311842, 0.10337053378938786, 0.06202232027363272, 0.04134821351575515, 0.06202232027363272, 0.04134821351575515, 0.020674106757877574, 0.144718747305143, 0.020674106757877574, 0.020674106757877574, 0.3191383010574553, 0.09042251863294566, 0.16488812221301855, 0.0744656035800729, 0.04787074515861829, 0.11701737705440027, 0.06382766021149106, 0.03723280179003645, 0.06382766021149106, 0.021275886737163685, 0.1822093788198767, 0.09110468940993835, 0.3644187576397534, 0.09110468940993835, 0.09110468940993835, 0.09110468940993835, 0.09110468940993835, 0.09110468940993835, 0.2707773898988468, 0.2707773898988468, 0.2707773898988468, 0.3282008049482756, 0.18318184462229334, 0.08395834545188445, 0.08395834545188445, 0.058516422587677044, 0.04070707658273186, 0.0559722303012563, 0.10940026831609186, 0.017809346004945187, 0.04070707658273186, 0.45736714547048624, 0.1725599758401849, 0.27246311974766035, 0.06811577993691509, 0.09536209191168112, 0.04541051995794339, 0.17710102783597922, 0.040869467962149054, 0.09082103991588678, 0.013623155987383017, 0.027246311974766034, 0.26761512881881283, 0.11972255762946889, 0.13380756440940642, 0.07746753728965634, 0.06690378220470321, 0.08803129237460948, 0.08274941483213291, 0.08627066652711729, 0.03873376864482817, 0.04225502033981255, 0.3113228487816023, 0.12720718552366547, 0.12720718552366547, 0.07866760157384575, 0.07699382281695541, 0.07532004406006508, 0.06862492903250374, 0.05356092022049072, 0.04184446892225838, 0.038496911408477705, 0.22429681435012047, 0.22429681435012047, 0.22429681435012047, 0.20550055864214983, 0.13700037242809987, 0.06850018621404994, 0.06850018621404994, 0.06850018621404994, 0.06850018621404994, 0.06850018621404994, 0.06850018621404994, 0.13700037242809987, 0.06850018621404994, 0.21269152086676893, 0.18230701788580195, 0.12153801192386796, 0.09115350894290097, 0.03038450298096699, 0.15192251490483494, 0.06076900596193398, 0.03038450298096699, 0.06076900596193398, 0.03038450298096699, 0.15437073284755268, 0.30874146569510535, 0.15437073284755268, 0.15437073284755268, 0.19739087480320963, 0.19739087480320963, 0.19739087480320963, 0.28870479421089557, 0.13731081675884058, 0.13731081675884058, 0.09154054450589372, 0.08978014941924192, 0.06865540837942029, 0.05809303785950948, 0.04400987716629506, 0.04753066733959866, 0.03872869190633965, 0.21379520636125426, 0.15850334264713678, 0.15481721839952894, 0.07740860919976447, 0.055291863714117484, 0.13270047291388196, 0.06266411220933314, 0.07003636070454881, 0.04423349097129398, 0.029488993980862657, 0.22480273106146498, 0.33720409659219747, 0.11240136553073249, 0.11240136553073249, 0.11240136553073249, 0.11240136553073249, 0.3131407137331809, 0.08767939984529066, 0.15657035686659046, 0.14404472831726323, 0.10646784266928151, 0.05010251419730895, 0.05010251419730895, 0.03131407137331809, 0.018788442823990854, 0.04383969992264533, 0.18662684842950342, 0.27994027264425514, 0.15552237369125285, 0.062208949476501144, 0.09331342421475171, 0.062208949476501144, 0.031104474738250572, 0.031104474738250572, 0.031104474738250572, 0.062208949476501144, 0.31423485504738297, 0.16253526985209465, 0.09752116191125679, 0.0595962656124347, 0.05417842328403155, 0.1083568465680631, 0.0595962656124347, 0.048760580955628394, 0.03250705397041893, 0.05417842328403155, 0.22001746174142986, 0.14667830782761992, 0.14667830782761992, 0.07333915391380996, 0.07333915391380996, 0.22001746174142986, 0.07333915391380996, 0.07333915391380996, 0.07333915391380996, 0.26173472929983155, 0.08265307241047312, 0.1102040965472975, 0.1102040965472975, 0.08265307241047312, 0.08265307241047312, 0.05510204827364875, 0.12397960861570968, 0.04132653620523656, 0.05510204827364875, 0.18739783307137156, 0.18739783307137156, 0.09369891653568578, 0.09369891653568578, 0.09369891653568578, 0.09369891653568578, 0.18739783307137156, 0.09369891653568578, 0.13694551651647108, 0.2191128264263537, 0.10955641321317686, 0.13694551651647108, 0.16433461981976527, 0.10955641321317686, 0.05477820660658843, 0.05477820660658843, 0.027389103303294214, 0.027389103303294214, 0.21084727065534148, 0.10542363532767074, 0.3162709059830122, 0.10542363532767074, 0.05271181766383537, 0.05271181766383537, 0.05271181766383537, 0.05271181766383537, 0.05271181766383537, 0.05271181766383537, 0.3344557781556428, 0.1672278890778214, 0.11100471947407112, 0.06919774720461576, 0.09082204320605819, 0.06343126827089778, 0.04180697226945535, 0.04036535253602586, 0.04180697226945535, 0.04180697226945535, 0.18066802953305947, 0.09033401476652973, 0.09033401476652973, 0.09033401476652973, 0.18066802953305947, 0.18066802953305947, 0.09033401476652973, 0.09033401476652973, 0.187168334420304, 0.128678229913959, 0.16377229261776602, 0.10528218811142101, 0.058490104506345, 0.128678229913959, 0.058490104506345, 0.058490104506345, 0.058490104506345, 0.046792083605076, 0.22841478250777245, 0.04568295650155449, 0.22841478250777245, 0.04568295650155449, 0.09136591300310898, 0.09136591300310898, 0.04568295650155449, 0.09136591300310898, 0.09136591300310898, 0.26350427270197296, 0.26350427270197296, 0.26350427270197296, 0.3020219387588941, 0.12355442949227487, 0.15101096937944705, 0.09609788960510268, 0.04804894480255134, 0.061777214746137434, 0.061777214746137434, 0.027456539887172192, 0.07550548468972353, 0.054913079774344384, 0.1806340001654703, 0.12042266677698019, 0.06021133338849009, 0.1806340001654703, 0.09031700008273515, 0.09031700008273515, 0.06021133338849009, 0.09031700008273515, 0.06021133338849009, 0.030105666694245047, 0.26349692632294863, 0.0929989151728054, 0.15499819195467565, 0.0464994575864027, 0.0464994575864027, 0.0464994575864027, 0.21699746873654593, 0.030999638390935134, 0.0464994575864027, 0.07749909597733783, 0.5771291237142345, 0.08878909595603608, 0.04439454797801804, 0.04439454797801804, 0.04439454797801804, 0.04439454797801804, 0.08878909595603608, 0.04439454797801804, 0.5236863703066365, 0.1309215925766591, 0.1309215925766591, 0.1309215925766591, 0.1964324175840113, 0.06547747252800376, 0.26190989011201504, 0.13095494505600752, 0.03273873626400188, 0.09821620879200565, 0.03273873626400188, 0.06547747252800376, 0.06547747252800376, 0.03273873626400188, 0.14195402839062257, 0.14195402839062257, 0.14195402839062257, 0.14195402839062257, 0.14195402839062257, 0.14195402839062257, 0.2392942891292333, 0.11964714456461666, 0.2392942891292333, 0.2392942891292333, 0.11964714456461666, 0.11964714456461666, 0.5452242095658378, 0.1817414031886126, 0.1817414031886126, 0.17805730078002632, 0.17805730078002632, 0.17805730078002632, 0.17805730078002632, 0.3908034442499819, 0.4364488539693427, 0.5410899701956318, 0.30311495822881573, 0.16109606171601396, 0.13354015642248526, 0.07418897579026959, 0.07842834583542785, 0.057231495609636536, 0.044513385474161754, 0.04875275551932001, 0.057231495609636536, 0.04027401542900349, 0.5989392961224063, 0.09982321602040105, 0.09982321602040105, 0.09982321602040105, 0.09982321602040105, 0.2622108883000363, 0.0973926156542992, 0.10488435532001453, 0.14234305364859115, 0.08240913632286856, 0.052442177660007264, 0.1348513139828758, 0.037458698328576616, 0.029966958662861292, 0.052442177660007264, 0.48029087803132703, 0.08352884835327427, 0.1252932725299114, 0.0626466362649557, 0.03132331813247785, 0.04176442417663714, 0.0626466362649557, 0.04176442417663714, 0.04176442417663714, 0.03132331813247785, 0.23544017120383062, 0.23544017120383062, 0.23544017120383062, 0.2669839593259606, 0.1186595374782047, 0.05932976873910235, 0.08899465310865352, 0.08899465310865352, 0.08899465310865352, 0.14832442184775588, 0.05932976873910235, 0.029664884369551173, 0.05932976873910235, 0.1782107426664116, 0.0891053713332058, 0.22276342833301452, 0.0445526856666029, 0.0891053713332058, 0.0891053713332058, 0.0445526856666029, 0.0445526856666029, 0.1336580569998087, 0.0445526856666029, 0.2142673507561231, 0.10713367537806155, 0.16070051306709232, 0.2142673507561231, 0.16070051306709232, 0.053566837689030776, 0.053566837689030776, 0.053566837689030776, 0.23669773578790193, 0.23669773578790193, 0.23669773578790193, 0.44850248674711746, 0.07372643617760835, 0.12902126331081462, 0.06143869681467362, 0.05529482713320626, 0.06143869681467362, 0.06143869681467362, 0.03071934840733681, 0.05529482713320626, 0.02457547872586945, 0.2815221619766771, 0.10404079899138068, 0.1591212219868175, 0.09180070499239472, 0.07956061099340875, 0.06120046999492981, 0.07344056399391577, 0.030600234997464906, 0.07344056399391577, 0.04284032899645087, 0.31177321582614137, 0.06928293685025365, 0.10392440527538047, 0.06928293685025365, 0.06928293685025365, 0.06928293685025365, 0.034641468425126824, 0.1732073421256341, 0.06928293685025365, 0.06928293685025365, 0.33602626617160725, 0.16801313308580362, 0.16801313308580362, 0.3457693037648026, 0.13461247703820559, 0.12669409603595821, 0.058068127349814175, 0.03959190501123694, 0.07390488935430896, 0.06334704801797911, 0.055428667015731715, 0.06598650835206156, 0.042231365345319405, 0.2913016782454848, 0.10403631365910171, 0.09363268229319154, 0.09363268229319154, 0.06242178819546103, 0.08322905092728136, 0.16645810185456272, 0.02080726273182034, 0.04161452546364068, 0.052018156829550855, 0.14989473167076722, 0.14989473167076722, 0.29978946334153445, 0.14989473167076722, 0.2279286820518894, 0.2279286820518894, 0.5473395032497471, 0.09122325054162451, 0.09122325054162451, 0.09122325054162451, 0.09122325054162451, 0.17551490027110683, 0.17551490027110683, 0.17551490027110683, 0.17551490027110683, 0.17551490027110683, 0.23832808118753226, 0.23151870743931707, 0.10214060622322811, 0.0885218587267977, 0.0953312324750129, 0.06809373748215208, 0.054474989985721665, 0.027237494992860833, 0.054474989985721665, 0.04085624248929125, 0.2723049916204412, 0.13214801063933176, 0.13214801063933176, 0.08409418858866567, 0.11212558478488756, 0.07208073307599915, 0.05606279239244378, 0.05205830722155494, 0.04004485170888841, 0.04805382205066609, 0.13171117235194604, 0.2634223447038921, 0.13171117235194604, 0.13171117235194604, 0.13171117235194604, 0.13171117235194604, 0.2597304041668359, 0.16233150260427243, 0.16233150260427243, 0.09739890156256346, 0.16233150260427243, 0.06493260104170898, 0.03246630052085449, 0.03246630052085449, 0.03246630052085449, 0.03246630052085449, 0.14855477522494187, 0.29710955044988374, 0.14855477522494187, 0.14855477522494187, 0.14855477522494187, 0.14855477522494187, 0.304035730389585, 0.16066928841726036, 0.12359176032096951, 0.07168322098616231, 0.06426771536690415, 0.0766268913990011, 0.03707752809629085, 0.049436704128387805, 0.05438037454122658, 0.056852209747645974, 0.2500322591005629, 0.12501612955028146, 0.2500322591005629, 0.12501612955028146, 0.12501612955028146, 0.12501612955028146, 0.12501612955028146, 0.25917574568322654, 0.5183514913664531, 0.3557873060394297, 0.14802829521348537, 0.12725239413089093, 0.04934276507116179, 0.06492469088310761, 0.06752167851843192, 0.059730715612459004, 0.041551802165188875, 0.04674577743583748, 0.041551802165188875, 0.16401319453073362, 0.41003298632683405, 0.08200659726536681, 0.08200659726536681, 0.08200659726536681, 0.08200659726536681, 0.08200659726536681, 0.31809675999737697, 0.1281223061100546, 0.13695832722109286, 0.06627015833278686, 0.06185214777726774, 0.057434137221748616, 0.07952418999934424, 0.03976209499967212, 0.06185214777726774, 0.04859811611071037, 0.31280742093247443, 0.31280742093247443, 0.17210437755532668, 0.17210437755532668, 0.17210437755532668, 0.17210437755532668, 0.17210437755532668, 0.17210437755532668, 0.14171098783680977, 0.28342197567361954, 0.14171098783680977, 0.14171098783680977, 0.5640529521598671, 0.08057899316569529, 0.06446319453255624, 0.03223159726627812, 0.048347395899417174, 0.06446319453255624, 0.03223159726627812, 0.03223159726627812, 0.03223159726627812, 0.06446319453255624, 0.48465680311648546, 0.166721940272071, 0.06203607079891014, 0.03101803539945507, 0.06203607079891014, 0.06591332522384202, 0.038772544249318835, 0.03101803539945507, 0.019386272124659418, 0.03101803539945507, 0.2662099263189202, 0.16940631674840378, 0.12100451196314556, 0.07260270717788733, 0.14520541435577466, 0.048401804785258226, 0.09680360957051645, 0.048401804785258226, 0.024200902392629113, 0.024200902392629113, 0.2443345711157975, 0.12216728555789876, 0.1832509283368481, 0.1832509283368481, 0.06108364277894938, 0.06108364277894938, 0.06108364277894938, 0.06108364277894938, 0.06108364277894938, 0.19922464190187722, 0.09961232095093861, 0.19922464190187722, 0.19922464190187722, 0.09961232095093861, 0.07470924071320395, 0.024903080237734652, 0.024903080237734652, 0.024903080237734652, 0.049806160475469305, 0.114339159733888, 0.114339159733888, 0.114339159733888, 0.114339159733888, 0.228678319467776, 0.114339159733888, 0.3049593341501339, 0.15247966707506694, 0.15247966707506694, 0.15247966707506694, 0.15247966707506694, 0.2932499763648237, 0.2932499763648237, 0.1701262008959573, 0.1701262008959573, 0.1701262008959573, 0.1701262008959573, 0.1701262008959573, 0.36600226981756084, 0.26683213669414135, 0.15747470362277194, 0.1443518116542076, 0.08748594645709552, 0.06998875716567642, 0.06124016251996686, 0.05249156787425731, 0.05249156787425731, 0.03499437858283821, 0.06561445984282163, 0.2525467087962504, 0.2525467087962504, 0.2525467087962504, 0.4060672367755546, 0.13535574559185154, 0.13535574559185154, 0.13535574559185154, 0.13535574559185154, 0.23179572288990347, 0.11589786144495173, 0.11589786144495173, 0.23179572288990347, 0.11589786144495173, 0.11589786144495173, 0.2785767780939129, 0.06964419452347823, 0.10446629178521735, 0.17411048630869558, 0.06964419452347823, 0.10446629178521735, 0.03482209726173911, 0.03482209726173911, 0.03482209726173911, 0.03482209726173911, 0.10140653036560743, 0.10140653036560743, 0.21971414912548276, 0.06760435357707162, 0.10140653036560743, 0.08450544197133952, 0.13520870715414324, 0.06760435357707162, 0.050703265182803714, 0.050703265182803714, 0.26958581799741826, 0.36920539012964093, 0.1121290444097428, 0.17229584872716577, 0.06563651380082505, 0.05469709483402088, 0.08204564225103132, 0.04102282112551566, 0.030083402158711484, 0.043757675867216704, 0.030083402158711484, 0.383325985892525, 0.09168892457948004, 0.1237248138903827, 0.11046858383069884, 0.07401395116656823, 0.053024920238735444, 0.05412960607704243, 0.03755931850243761, 0.03755931850243761, 0.034245260987516644, 0.3157694067157128, 0.1578847033578564, 0.1578847033578564, 0.1578847033578564, 0.1578847033578564, 0.11313905135546168, 0.11313905135546168, 0.11313905135546168, 0.22627810271092336, 0.11313905135546168, 0.11313905135546168, 0.11313905135546168, 0.22586671421448992, 0.22586671421448992, 0.31304344345143315, 0.31304344345143315, 0.15652172172571657, 0.2673956687610668, 0.07292609148029094, 0.1458521829605819, 0.04861739432019396, 0.07292609148029094, 0.09723478864038793, 0.17016088012067887, 0.02430869716009698, 0.04861739432019396, 0.04861739432019396, 0.3733038337259805, 0.11999051798335088, 0.1266566578713148, 0.0688834455089607, 0.06221730562099675, 0.07332753876760331, 0.06666139887963937, 0.035552746069141, 0.031108652810498374, 0.042218885957104935, 0.38629467213635527, 0.5443556115313123, 0.18145187051043743, 0.08923608861439516, 0.14872681435732527, 0.17847217722879033, 0.11898145148586022, 0.17847217722879033, 0.08923608861439516, 0.08923608861439516, 0.029745362871465054, 0.05949072574293011, 0.029745362871465054, 0.18591982129822068, 0.18591982129822068, 0.18591982129822068, 0.6320988110255881, 0.1264197622051176, 0.04213992073503921, 0.04213992073503921, 0.04213992073503921, 0.04213992073503921, 0.04213992073503921, 0.15343570064050918, 0.15343570064050918, 0.30687140128101836, 0.15343570064050918, 0.21435145472670075, 0.21435145472670075, 0.05358786368167519, 0.10717572736335038, 0.10717572736335038, 0.16076359104502555, 0.05358786368167519, 0.05358786368167519, 0.2634415627069585, 0.2634415627069585, 0.30464621042835877, 0.13245487409928644, 0.13466245533427454, 0.10817148051441725, 0.07285018075460753, 0.07285018075460753, 0.05298194963971457, 0.044151624699762144, 0.04194404346477404, 0.035321299759809716, 0.2647947119856817, 0.10087417599454543, 0.15131126399181813, 0.050437087997272714, 0.050437087997272714, 0.06304635999659089, 0.07565563199590906, 0.06304635999659089, 0.08826490399522724, 0.06304635999659089, 0.29198511676576167, 0.29198511676576167, 0.2711526149151957, 0.2711526149151957, 0.2711526149151957, 0.5340673745153484, 0.36450137866811555, 0.17122110871153554, 0.09558969872852598, 0.058824429986785214, 0.0724801012337175, 0.0388661412412688, 0.040967013740796844, 0.05147137623843706, 0.05357224873796511, 0.05357224873796511, 0.25963733515478965, 0.12981866757739483, 0.08654577838492988, 0.2163644459623247, 0.12981866757739483, 0.08654577838492988, 0.04327288919246494, 0.04327288919246494, 0.20262027703944627, 0.21820645219632676, 0.09871244266024305, 0.12468940125504385, 0.05714930890856177, 0.07793087578440241, 0.062344700627521926, 0.08312626750336256, 0.031172350313760963, 0.046758525470641445, 0.2679379850833715, 0.2679379850833715, 0.2679379850833715, 0.45171813840276154, 0.22585906920138077, 0.1736596756232962, 0.5209790268698886, 0.22819760420745333, 0.22819760420745333, 0.22819760420745333, 0.35799307727443047, 0.060583443846442084, 0.1431972309097722, 0.07710620125910811, 0.04956827223799807, 0.0715986154548861, 0.04956827223799807, 0.04956827223799807, 0.08261378706333011, 0.04956827223799807, 0.23009512810825436, 0.23009512810825436, 0.23009512810825436, 0.24600227658991397, 0.36900341488487093, 0.12300113829495699, 0.12300113829495699, 0.12300113829495699, 0.26226869709364825, 0.26226869709364825, 0.3830723721647067, 0.13065165132618622, 0.13065165132618622, 0.13065165132618622, 0.13065165132618622, 0.13065165132618622, 0.13065165132618622, 0.26130330265237245, 0.13065165132618622, 0.22635041559677826, 0.16167886828341305, 0.2910219629101435, 0.08083943414170652, 0.06467154731336522, 0.03233577365668261, 0.048503660485023914, 0.03233577365668261, 0.03233577365668261, 0.03233577365668261, 0.4671780258370905, 0.10219519315186354, 0.05839725322963631, 0.0729965665370454, 0.0729965665370454, 0.04379793992222723, 0.04379793992222723, 0.04379793992222723, 0.05839725322963631, 0.04379793992222723, 0.17536221295931878, 0.2630433194389782, 0.07014488518372752, 0.08768110647965939, 0.052608663887795636, 0.12275354907152315, 0.052608663887795636, 0.14028977036745505, 0.01753622129593188, 0.03507244259186376, 0.5410975073277351, 0.33766075588292876, 0.10213195702631796, 0.20843256535983257, 0.07920437483673637, 0.04793949003276149, 0.06878274656874474, 0.05419246699355647, 0.03543353611117153, 0.03543353611117153, 0.029180559150376557, 0.6098517229999885, 0.17424334942856815, 0.08712167471428407, 0.08712167471428407, 0.22841949250056667, 0.20013898390525842, 0.1936127126909565, 0.06308728840491841, 0.06743813588111969, 0.052210169714415236, 0.06743813588111969, 0.04568389850011333, 0.03698220354771079, 0.047859322238213965, 0.3502427958834496, 0.26945074763195137, 0.30794371157937295, 0.07698592789484324, 0.07698592789484324, 0.03849296394742162, 0.03849296394742162, 0.03849296394742162, 0.07698592789484324, 0.03849296394742162, 0.03849296394742162, 0.2609456994043913, 0.208756559523513, 0.05218913988087825, 0.07828370982131738, 0.026094569940439124, 0.13047284970219564, 0.026094569940439124, 0.18266198958307386, 0.026094569940439124, 0.026094569940439124, 0.36790717538511863, 0.10412467227880716, 0.12842042914386217, 0.059003980957990726, 0.07115185939051823, 0.0746226817998118, 0.050326924934756795, 0.04512069132081643, 0.04338528011616965, 0.057268569753343934, 0.22689964941284813, 0.06482847126081374, 0.16207117815203437, 0.06482847126081374, 0.16207117815203437, 0.06482847126081374, 0.09724270689122062, 0.06482847126081374, 0.03241423563040687, 0.06482847126081374, 0.25678536733826635, 0.13826904395137418, 0.12839268366913317, 0.09629451275184987, 0.0839490623990486, 0.10370178296353064, 0.06913452197568709, 0.05678907162288582, 0.029629080846723038, 0.0370363510584038, 0.36889570230108903, 0.21805866083877018, 0.07787809315670363, 0.2336342794701109, 0.07787809315670363, 0.07787809315670363, 0.06230247452536291, 0.06230247452536291, 0.04672685589402218, 0.09345371178804436, 0.031151237262681455, 0.6017716556012485, 0.08023622074683313, 0.04011811037341657, 0.04011811037341657, 0.04011811037341657, 0.04011811037341657, 0.04011811037341657, 0.08023622074683313, 0.04011811037341657, 0.5604832856510371, 0.14012082141275928, 0.028024164282551854, 0.028024164282551854, 0.08407249284765557, 0.028024164282551854, 0.028024164282551854, 0.028024164282551854, 0.05604832856510371, 0.028024164282551854, 0.21975055968528892, 0.21975055968528892, 0.21975055968528892, 0.21975055968528892, 0.277812947659928, 0.21607673706883287, 0.10289368431849186, 0.11318305275034103, 0.046302157943321334, 0.056591526375170516, 0.046302157943321334, 0.07202557902294429, 0.025723421079622964, 0.04115747372739674, 0.5477456919597986, 0.20931320933036263, 0.20931320933036263, 0.20931320933036263, 0.20931320933036263, 0.20931320933036263, 0.2551069042513507, 0.11471250056939931, 0.13354589618527085, 0.11471250056939931, 0.11300037369522917, 0.08731847058267708, 0.07362145558931597, 0.025681903112552085, 0.044515298728423615, 0.039378918105913194, 0.3457657272792218, 0.15172842040944753, 0.12838558650030177, 0.05981601189218605, 0.06565172036947249, 0.06856957460811572, 0.040849959341005104, 0.05398030341489961, 0.04230888646032672, 0.04230888646032672, 0.2579668466973569, 0.12312054046919309, 0.16416072062559078, 0.09966900895125154, 0.09380612607176617, 0.05862882879485385, 0.09966900895125154, 0.041040180156397696, 0.017588648638456154, 0.041040180156397696, 0.253665297607582, 0.13995326764556248, 0.14578465379746092, 0.10204925765822263, 0.06997663382278124, 0.0641452476708828, 0.06122955459493359, 0.07289232689873046, 0.05248247536708593, 0.03790400998733984, 0.5408190782330086, 0.15451973663800245, 0.07725986831900122, 0.07725986831900122, 0.07725986831900122, 0.07725986831900122, 0.37719202550023295, 0.1677517779601686, 0.1677517779601686, 0.1677517779601686, 0.1677517779601686, 0.1677517779601686, 0.30987839019815744, 0.16034405074206984, 0.1189068241458046, 0.06305664916822971, 0.09548578302617643, 0.07206474190654824, 0.037833989500937824, 0.06305664916822971, 0.039635608048601535, 0.04143722659626524, 0.30888132063093404, 0.10006014611988005, 0.19141940996846618, 0.06090617589905742, 0.05655573476341046, 0.09570970498423309, 0.05655573476341046, 0.03480352908517567, 0.05655573476341046, 0.03915397022082263, 0.15864778993357692, 0.31729557986715384, 0.10576519328905128, 0.10576519328905128, 0.05288259664452564, 0.05288259664452564, 0.05288259664452564, 0.05288259664452564, 0.05288259664452564, 0.3010806716403776, 0.13597191622468666, 0.16510875541569095, 0.07931695113106722, 0.0663672448239542, 0.06798595811234333, 0.061511104958786825, 0.03884911892133905, 0.040467832209728175, 0.0420865454981173, 0.16863135068962812, 0.21681173660095046, 0.09636077182264464, 0.09636077182264464, 0.04818038591132232, 0.1927215436452893, 0.09636077182264464, 0.02409019295566116, 0.04818038591132232, 0.04818038591132232, 0.42278811600672006, 0.42278811600672006, 0.09820750894293297, 0.19641501788586593, 0.09820750894293297, 0.09820750894293297, 0.09820750894293297, 0.09820750894293297, 0.19641501788586593, 0.09820750894293297, 0.2126197262366256, 0.4252394524732512, 0.2126197262366256, 0.19017215498450868, 0.19017215498450868, 0.3959766304527318, 0.1289799397947695, 0.13390910946845494, 0.053399338131592464, 0.0731160168263343, 0.05586392296843519, 0.05257780985264489, 0.03696877255264094, 0.031218074600007903, 0.03861182911053609, 0.4626330459692967, 0.13409653506356425, 0.06704826753178213, 0.053638614025425704, 0.053638614025425704, 0.033524133765891063, 0.026819307012712852, 0.1005724012976732, 0.033524133765891063, 0.026819307012712852, 0.2625332843359029, 0.2625332843359029, 0.2625332843359029, 0.2649276307049253, 0.11496859445685437, 0.19994538166409456, 0.0699808835824331, 0.09997269083204728, 0.0699808835824331, 0.03998907633281891, 0.03998907633281891, 0.04998634541602364, 0.04998634541602364, 0.20419875547382663, 0.30629813321073995, 0.20419875547382663, 0.10209937773691331, 0.10209937773691331, 0.3685598109195316, 0.28645900055584317, 0.10742212520844119, 0.10742212520844119, 0.17903687534740198, 0.14322950027792158, 0.07161475013896079, 0.035807375069480396, 0.035807375069480396, 0.1640726615686904, 0.1640726615686904, 0.1640726615686904, 0.1640726615686904, 0.1640726615686904, 0.5823361576360819, 0.08319087966229742, 0.08319087966229742, 0.08319087966229742, 0.08319087966229742, 0.08319087966229742, 0.554978375494576, 0.07399711673261014, 0.07399711673261014, 0.03699855836630507, 0.07399711673261014, 0.03699855836630507, 0.03699855836630507, 0.1109956750989152, 0.3643961268723497, 0.1276625886661633, 0.12518370344934462, 0.04461993390273669, 0.08056376954660792, 0.07188767128774246, 0.05329603216160216, 0.05453547477001151, 0.04461993390273669, 0.03470439303546188, 0.17271398112039632, 0.23331537800474592, 0.07878181594965446, 0.14241328267822154, 0.07878181594965446, 0.12423286361291665, 0.04848111750747967, 0.04848111750747967, 0.027270628597957314, 0.04545104766326219, 0.2663293047940287, 0.03329116309925359, 0.2663293047940287, 0.09987348929776077, 0.06658232619850718, 0.03329116309925359, 0.06658232619850718, 0.03329116309925359, 0.03329116309925359, 0.39799550121310573, 0.08915099227173569, 0.10188684831055507, 0.08596702826203084, 0.04775946014557269, 0.06367928019409692, 0.07323117222321146, 0.028655676087343613, 0.057311352174687226, 0.057311352174687226, 0.2788220193333565, 0.13941100966667824, 0.13941100966667824, 0.13941100966667824, 0.13941100966667824, 0.5375895729218325, 0.33316926478546316, 0.33316926478546316, 0.36664829267957344, 0.3417081858594384, 0.14644636536833075, 0.14644636536833075, 0.048815455122776914, 0.048815455122776914, 0.048815455122776914, 0.048815455122776914, 0.048815455122776914, 0.048815455122776914, 0.09763091024555383, 0.5259113044287158, 0.08414580870859452, 0.08414580870859452, 0.06310935653144589, 0.04207290435429726, 0.04207290435429726, 0.04207290435429726, 0.08414580870859452, 0.02103645217714863, 0.02103645217714863, 0.22347648301207923, 0.27934560376509904, 0.11173824150603962, 0.05586912075301981, 0.05586912075301981, 0.05586912075301981, 0.05586912075301981, 0.05586912075301981, 0.05586912075301981, 0.05586912075301981, 0.35908545917717677, 0.12539492225234744, 0.1282448068489917, 0.08264665330268355, 0.0569976919328852, 0.07694688410939503, 0.0427482689496639, 0.0427482689496639, 0.0427482689496639, 0.03989838435301964, 0.5410664503447447, 0.45359660167587007, 0.29270879804844596, 0.21884907742797505, 0.21884907742797505, 0.21884907742797505, 0.22569906680718071, 0.22569906680718071, 0.36386255057746036, 0.12128751685915345, 0.12128751685915345, 0.12128751685915345, 0.12128751685915345, 0.12128751685915345, 0.12128751685915345, 0.3367086489919876, 0.11745650546232125, 0.1331173728572974, 0.1409478065547855, 0.07047390327739275, 0.07047390327739275, 0.039152168487440416, 0.039152168487440416, 0.03132173478995234, 0.01566086739497617, 0.37037246438797483, 0.37037246438797483, 0.28473427785512057, 0.15074167651153442, 0.15074167651153442, 0.08374537583974134, 0.050247225503844806, 0.06699630067179307, 0.050247225503844806, 0.03349815033589654, 0.08374537583974134, 0.03349815033589654, 0.35714854938487306, 0.35714854938487306, 0.14604997678568746, 0.14604997678568746, 0.14604997678568746, 0.14604997678568746, 0.14604997678568746, 0.25694291106169553, 0.07189686960900656, 0.15911602290517843, 0.20626151117337946, 0.1107918974302724, 0.09075506491628696, 0.023572744134100508, 0.02003683251398543, 0.03889502782126584, 0.02121546972069046, 0.5065023963509727, 0.12662559908774318, 0.12662559908774318, 0.23711894751372525, 0.10099510727436446, 0.16686148158373257, 0.12295056537748716, 0.07464855755061721, 0.10099510727436446, 0.07903964917124175, 0.03951982458562087, 0.04391091620624542, 0.03073764134437179, 0.35918494786225114, 0.14591888506903952, 0.10102076658625814, 0.0710886875977372, 0.06734717772417209, 0.0710886875977372, 0.04115660860921628, 0.04115660860921628, 0.04115660860921628, 0.05986415797704186, 0.24986121979981357, 0.18739591484986018, 0.14054693613739513, 0.07808163118744174, 0.09369795742493009, 0.046848978712465045, 0.015616326237488348, 0.046848978712465045, 0.09369795742493009, 0.031232652474976696, 0.2503533312805629, 0.10014133251222518, 0.15021199876833777, 0.08583542786762158, 0.08583542786762158, 0.07868247554531978, 0.06437657090071619, 0.05722361857841438, 0.07868247554531978, 0.05722361857841438, 0.34241603252805397, 0.34241603252805397, 0.34087898566792146, 0.06608878293561742, 0.0973939959051204, 0.07652385392545175, 0.06608878293561742, 0.10782906689495474, 0.06608878293561742, 0.09391563890850897, 0.03130521296950299, 0.04521864095594876, 0.31579272972691697, 0.13495415800295596, 0.13765324116301508, 0.0836715779618327, 0.0836715779618327, 0.056680746361241506, 0.07287524532159621, 0.02699083160059119, 0.05937982952130062, 0.03238899792070943, 0.5763091725753824, 0.09605152876256373, 0.048025764381281866, 0.048025764381281866, 0.048025764381281866, 0.048025764381281866, 0.09605152876256373, 0.2813829659801684, 0.09379432199338945, 0.09379432199338945, 0.1875886439867789, 0.1875886439867789, 0.09379432199338945, 0.29686042311956096, 0.15279580601742107, 0.1899033589073662, 0.09604307806809324, 0.08294629469517144, 0.06766671409342934, 0.02182797228820301, 0.02182797228820301, 0.03710755288994512, 0.03274195843230451, 0.1405896112186407, 0.2811792224372814, 0.1405896112186407, 0.1405896112186407, 0.1405896112186407, 0.1405896112186407, 0.25881415522389023, 0.08393972601855898, 0.2728041095603167, 0.07694474885034573, 0.04196986300927949, 0.05595981734570599, 0.08393972601855898, 0.03497488584106624, 0.04896484017749274, 0.04196986300927949, 0.16346342989461618, 0.08173171494730809, 0.16346342989461618, 0.16346342989461618, 0.08173171494730809, 0.08173171494730809, 0.08173171494730809, 0.08173171494730809, 0.08173171494730809, 0.08173171494730809, 0.15953268764984505, 0.05317756254994834, 0.21271025019979337, 0.08862927091658057, 0.15953268764984505, 0.08862927091658057, 0.10635512509989668, 0.03545170836663223, 0.017725854183316115, 0.07090341673326446, 0.5381210531561412, 0.21892045845672403, 0.13552218856844822, 0.23977002592879298, 0.11467262109637925, 0.031274351208103436, 0.07297348615224135, 0.07297348615224135, 0.04169913494413791, 0.031274351208103436, 0.04169913494413791, 0.1421699581836593, 0.22747193309385486, 0.11373596654692743, 0.08530197491019557, 0.056867983273463714, 0.199037941457123, 0.056867983273463714, 0.056867983273463714, 0.028433991636731857, 0.028433991636731857, 0.2699254348999626, 0.2699254348999626, 0.12269337949998302, 0.0736160276999898, 0.0736160276999898, 0.04907735179999321, 0.024538675899996604, 0.024538675899996604, 0.024538675899996604, 0.0736160276999898, 0.2804480044653804, 0.26041600414642463, 0.0701120011163451, 0.09014400143530084, 0.04006400063791148, 0.0701120011163451, 0.050080000797389355, 0.050080000797389355, 0.050080000797389355, 0.03004800047843361, 0.29727651861421167, 0.29727651861421167, 0.2600429386130488, 0.07429798246087108, 0.18574495615217768, 0.07429798246087108, 0.14859596492174215, 0.11144697369130661, 0.03714899123043554, 0.07429798246087108, 0.21719842486116558, 0.07239947495372187, 0.07239947495372187, 0.07239947495372187, 0.07239947495372187, 0.07239947495372187, 0.07239947495372187, 0.21719842486116558, 0.07239947495372187, 0.07239947495372187, 0.33372763890599333, 0.2648632054809471, 0.1006480180827599, 0.05826990520580836, 0.042378112876951535, 0.042378112876951535, 0.03178358465771365, 0.09005348986352202, 0.010594528219237884, 0.015891792328856826, 0.2899081401069773, 0.14799506453013525, 0.09325716395049619, 0.07298386743951875, 0.1033938122059849, 0.09325716395049619, 0.04460125232415035, 0.06487454883512778, 0.05068324127744358, 0.03851926337085712, 0.28260934416480377, 0.09285735593986409, 0.1534165011180363, 0.14937922477282484, 0.07670825055901816, 0.07670825055901816, 0.06055914517817223, 0.03633548710690334, 0.024223658071268892, 0.048447316142537784, 0.2458428112478699, 0.06146070281196748, 0.3073035140598374, 0.06146070281196748, 0.06146070281196748, 0.06146070281196748, 0.06146070281196748, 0.06146070281196748, 0.06146070281196748, 0.06146070281196748, 0.22009702511318005, 0.4401940502263601, 0.4393869713804161, 0.2571252214888264, 0.150254244656022, 0.17882371371033606, 0.07406899384451789, 0.05925519507561431, 0.09099904958040769, 0.0581970665921212, 0.051848295691162526, 0.040208882372738286, 0.039150753889245174, 0.32920932255773855, 0.16003230957667844, 0.13717055106572437, 0.05029586872409894, 0.06629909968176678, 0.06401292383067138, 0.054868220426289756, 0.04115116531971732, 0.05029586872409894, 0.04800969287300354, 0.22943162938863884, 0.1376589776331833, 0.13438138292763133, 0.0786622729332476, 0.08849505704990356, 0.09505024646100751, 0.08193986763879958, 0.058996704699935704, 0.05244151528883174, 0.0393311364666238, 0.17604601910880183, 0.17604601910880183, 0.08802300955440091, 0.08802300955440091, 0.22005752388600228, 0.04401150477720046, 0.13203451433160138, 0.08802300955440091, 0.04401150477720046, 0.16642383186228027, 0.16642383186228027, 0.16642383186228027, 0.16642383186228027, 0.16642383186228027, 0.16642383186228027, 0.2177321981284617, 0.10886609906423085, 0.10886609906423085, 0.10886609906423085, 0.10886609906423085, 0.054433049532115425, 0.054433049532115425, 0.16329914859634628, 0.054433049532115425, 0.054433049532115425, 0.2681940535700031, 0.08939801785666769, 0.08939801785666769, 0.08939801785666769, 0.08939801785666769, 0.08939801785666769, 0.08939801785666769, 0.17879603571333538, 0.08939801785666769, 0.08939801785666769, 0.24982902337359217, 0.21197614104426002, 0.14384095285146214, 0.0757057646586643, 0.06434989995986465, 0.06813518819279786, 0.07949105289159751, 0.03406759409639893, 0.026497017630532502, 0.045423458795198574, 0.3716381653338924, 0.1858190826669462, 0.1858190826669462, 0.1858190826669462, 0.5513516120828702, 0.21464181326086704, 0.21464181326086704, 0.21464181326086704, 0.21464181326086704, 0.24747573867283523, 0.0989902954691341, 0.2144789735164572, 0.08249191289094508, 0.03299676515637803, 0.0989902954691341, 0.03299676515637803, 0.06599353031275607, 0.08249191289094508, 0.04949514773456705, 0.18954201719531932, 0.1542783860892134, 0.09256703165352805, 0.08375112387700157, 0.07934316998873832, 0.14105452442442368, 0.07052726221221184, 0.06171135443568536, 0.0661193083239486, 0.0661193083239486, 0.3239795819198275, 0.11187784123850159, 0.15616282006207513, 0.09323153436541798, 0.06759286241492804, 0.06759286241492804, 0.04428497882357354, 0.05127734390097989, 0.041954190464438094, 0.041954190464438094, 0.17732712166213258, 0.17732712166213258, 0.17732712166213258, 0.17732712166213258, 0.17732712166213258, 0.27844061714600726, 0.15910892408343272, 0.07955446204171636, 0.07955446204171636, 0.07955446204171636, 0.059665846531287266, 0.03977723102085818, 0.11933169306257453, 0.01988861551042909, 0.07955446204171636, 0.2829830879304156, 0.15761083378402896, 0.15402876937984647, 0.05373096606273715, 0.07164128808364953, 0.07164128808364953, 0.06447715927528458, 0.04656683725437219, 0.0608950948711021, 0.03940270844600724, 0.2180257466658475, 0.2180257466658475, 0.2180257466658475, 0.2180257466658475, 0.3442181610125432, 0.0860545402531358, 0.18440258625671957, 0.061467528752239854, 0.03688051725134391, 0.061467528752239854, 0.0860545402531358, 0.02458701150089594, 0.0860545402531358, 0.02458701150089594, 0.27524934056690203, 0.2361094682116473, 0.09837894508818637, 0.19675789017637274, 0.1770821011587355, 0.03935157803527455, 0.09837894508818637, 0.03935157803527455, 0.019675789017637276, 0.0787031560705491, 0.019675789017637276, 0.3410478174859695, 0.14428946124406403, 0.13520830634059147, 0.09282958345771951, 0.04944184336335061, 0.058522998266823174, 0.05045086057484756, 0.04540577451736281, 0.0393516712483811, 0.044396757305865855, 0.3230946595857388, 0.3230946595857388, 0.5593043774343638, 0.1598012506955325, 0.07990062534776625, 0.07990062534776625, 0.27787599286110115, 0.0845709543490308, 0.22954973323308359, 0.07248938944202639, 0.12081564907004398, 0.036244694721013195, 0.04832625962801759, 0.036244694721013195, 0.04832625962801759, 0.04832625962801759, 0.5537573468801172, 0.11075146937602345, 0.11075146937602345, 0.11075146937602345, 0.21604983842774395, 0.21604983842774395, 0.21604983842774395, 0.21604983842774395, 0.2857157877152846, 0.108036282229842, 0.216072564459684, 0.08794689090611105, 0.04955383193186968, 0.0678574995823801, 0.05892888121627746, 0.04285736815729269, 0.043750229993902955, 0.03928592081085164, 0.2603291176544197, 0.13016455882720984, 0.13016455882720984, 0.2603291176544197, 0.06508227941360492, 0.06508227941360492, 0.06508227941360492, 0.06508227941360492, 0.3298263034094061, 0.13193052136376243, 0.09235136495463371, 0.059368734613693096, 0.07256178675006934, 0.07915831281825746, 0.059368734613693096, 0.09894789102282182, 0.03957915640912873, 0.03957915640912873, 0.3855370188408987, 0.09638425471022467, 0.09638425471022467, 0.09638425471022467, 0.09638425471022467, 0.09638425471022467, 0.19276850942044935, 0.09638425471022467, 0.20656913895344392, 0.2478829667441327, 0.12394148337206636, 0.11705584540695156, 0.08951329354649236, 0.04131382779068878, 0.04819946575580358, 0.04131382779068878, 0.02754255186045919, 0.05508510372091838, 0.281911532502143, 0.12333629546968757, 0.14976550164176347, 0.06166814773484378, 0.06166814773484378, 0.07928761851622772, 0.07047788312553575, 0.03523894156276788, 0.07928761851622772, 0.05285841234415181, 0.22686096756086374, 0.1232189011624996, 0.23377043865408803, 0.09558101678960249, 0.09673259530513988, 0.07024628944778015, 0.033395776950584, 0.026486305857359727, 0.0449115621059578, 0.04836629765256994, 0.2718031039807372, 0.1812020693204915, 0.15531605941756413, 0.08197236469260329, 0.06471502475731838, 0.060400689773497156, 0.09922970462788819, 0.025886009902927352, 0.0345146798705698, 0.030200344886748578, 0.261867666710966, 0.08728922223698866, 0.17457844447397733, 0.17457844447397733, 0.08728922223698866, 0.08728922223698866, 0.21081226414864182, 0.10540613207432091, 0.10540613207432091, 0.21081226414864182, 0.10540613207432091, 0.10540613207432091, 0.2756561285157511, 0.060043909181648765, 0.22652929373076577, 0.05731464058248291, 0.09552440097080485, 0.06550244637998047, 0.05731464058248291, 0.09006586377247314, 0.03820976038832194, 0.030021954590824382, 0.5428611173251807, 0.3190384797583685, 0.16553883383688933, 0.11437228519639626, 0.0632057365559032, 0.07223512749246079, 0.0632057365559032, 0.05718614259819813, 0.04213715770393547, 0.045146954682787996, 0.05718614259819813, 0.2916781755352833, 0.1510211873329893, 0.11844799006508966, 0.09179719230044449, 0.05774339515673121, 0.06958819416324018, 0.07699119354230828, 0.045898596150222244, 0.042937396398595, 0.05330159552929035, 0.13117320210572872, 0.26234640421145744, 0.13117320210572872, 0.26234640421145744, 0.13117320210572872, 0.1023806565935777, 0.4095226263743108, 0.05119032829678885, 0.1023806565935777, 0.05119032829678885, 0.15357098489036655, 0.05119032829678885, 0.05119032829678885, 0.3232204790485364, 0.13179864194212162, 0.09414188710151546, 0.0847276983913639, 0.08158963548798007, 0.07845157258459622, 0.05334706935752542, 0.04393288064737388, 0.05334706935752542, 0.059623195164293125, 0.11988281943656533, 0.41958986802797865, 0.059941409718282664, 0.059941409718282664, 0.059941409718282664, 0.11988281943656533, 0.059941409718282664, 0.3234810608871049, 0.17971170049283605, 0.10782702029570163, 0.07188468019713443, 0.03594234009856721, 0.03594234009856721, 0.03594234009856721, 0.03594234009856721, 0.03594234009856721, 0.10782702029570163, 0.23212509058048056, 0.23212509058048056, 0.6032007798917577, 0.15080019497293942, 0.49776958386279857, 0.08296159731046643, 0.08296159731046643, 0.08296159731046643, 0.08296159731046643, 0.34599264672635444, 0.18194440905437603, 0.083515466451189, 0.06561929506879136, 0.07456738075999018, 0.056671209377592534, 0.06860199029919097, 0.05070581891679332, 0.03280964753439568, 0.03877503799519489, 0.2179456198677419, 0.16709164189860212, 0.13803222591623654, 0.07628096695370967, 0.11623766392946235, 0.07264853995591397, 0.08717824794709676, 0.05085397796913978, 0.03995669697575269, 0.036324269977956986, 0.28582893211688587, 0.24009630297818416, 0.08003210099272805, 0.08003210099272805, 0.06859894370805261, 0.04573262913870174, 0.05716578642337718, 0.05716578642337718, 0.034299471854026306, 0.04573262913870174, 0.31265552180866446, 0.11418723405186006, 0.12234346505556436, 0.07068733536543718, 0.0815623100370429, 0.08428105370494433, 0.06524984802963432, 0.06796859169753575, 0.03806241135062002, 0.04621864235432431, 0.3714506851721637, 0.09944417254330662, 0.19888834508661324, 0.19888834508661324, 0.09944417254330662, 0.19888834508661324, 0.09944417254330662, 0.09944417254330662, 0.2679067884524528, 0.2628563336703967, 0.2628563336703967, 0.2730893980991594, 0.15091782526532493, 0.1485223042293674, 0.10061188351021662, 0.12696261490574956, 0.05988802589893846, 0.040723857611278155, 0.028746252431490465, 0.038328336575320615, 0.03353729450340554, 0.2652106765423122, 0.2652106765423122, 0.17013060750606063, 0.17013060750606063, 0.17013060750606063, 0.17013060750606063, 0.17013060750606063, 0.17013060750606063, 0.21854831783531078, 0.10927415891765539, 0.10927415891765539, 0.21854831783531078, 0.10927415891765539, 0.21854831783531078, 0.17584340537740847, 0.17584340537740847, 0.17584340537740847, 0.17584340537740847, 0.08792170268870424, 0.08792170268870424, 0.08792170268870424, 0.27384203492694714, 0.14893163303044493, 0.1969740952983304, 0.06565803176611014, 0.07046227799289868, 0.06405661635718062, 0.06565803176611014, 0.03683255440537886, 0.03523113899644934, 0.0416368006321674, 0.16412250992267854, 0.08206125496133927, 0.41030627480669635, 0.08206125496133927, 0.041030627480669636, 0.041030627480669636, 0.041030627480669636, 0.041030627480669636, 0.041030627480669636, 0.041030627480669636, 0.3214686539258669, 0.3214686539258669, 0.42805700072084063, 0.2685562872140771, 0.09120779565761108, 0.20268399035024687, 0.09120779565761108, 0.09120779565761108, 0.05067099758756172, 0.0709393966225864, 0.03040259855253703, 0.05067099758756172, 0.05067099758756172, 0.5399006388523994, 0.12340586030911985, 0.0771286626931999, 0.030851465077279962, 0.0771286626931999, 0.030851465077279962, 0.015425732538639981, 0.030851465077279962, 0.030851465077279962, 0.046277197615919946, 0.2413167047666651, 0.16087780317777675, 0.08043890158888838, 0.08043890158888838, 0.08043890158888838, 0.2413167047666651, 0.08043890158888838, 0.08043890158888838, 0.23976254699515684, 0.23976254699515684, 0.23976254699515684, 0.20945508668232118, 0.41891017336464237, 0.27536581320277487, 0.13768290660138743, 0.12620933105127183, 0.11856028068452808, 0.0726659784840656, 0.06884145330069372, 0.08031502885080934, 0.04971882738383435, 0.038245251833718734, 0.03442072665034686, 0.26342649484866154, 0.15435146182538761, 0.14406136437036177, 0.08849483811322223, 0.08026276014920156, 0.055566526257139544, 0.06997266269417572, 0.0452764288021137, 0.041160389820103366, 0.055566526257139544, 0.4410068201133973, 0.11642638111821106, 0.29106595279552766, 0.0776175874121407, 0.09702198426517589, 0.05821319055910553, 0.21344836538338693, 0.03880879370607035, 0.05821319055910553, 0.019404396853035175, 0.019404396853035175, 0.5379679591081953, 0.15884218150961912, 0.2184079995757263, 0.09927636344351196, 0.07942109075480956, 0.05956581806610717, 0.07942109075480956, 0.05956581806610717, 0.15884218150961912, 0.01985527268870239, 0.05956581806610717, 0.11883893208707734, 0.11883893208707734, 0.11883893208707734, 0.11883893208707734, 0.11883893208707734, 0.23767786417415468, 0.11883893208707734, 0.1686330833727413, 0.21681396433638164, 0.07227132144546056, 0.10840698216819082, 0.08431654168637065, 0.08431654168637065, 0.04818088096364037, 0.13249742265001102, 0.012045220240910093, 0.06022610120455046, 0.28345805098232607, 0.28345805098232607, 0.14172902549116304, 0.14172902549116304, 0.40247561760227124, 0.13999151916600738, 0.10888229268467241, 0.04083085975675215, 0.08749469947875461, 0.06999575958300369, 0.0486081663770859, 0.02916489982625154, 0.038886533101668716, 0.03305355313641841, 0.5841453940833206, 0.09735756568055343, 0.04867878284027671, 0.04867878284027671, 0.04867878284027671, 0.04867878284027671, 0.09735756568055343, 0.18875131290969377, 0.2289483517700915, 0.0734032883537698, 0.12059111658119323, 0.09437565645484688, 0.09262795911309045, 0.04718782822742344, 0.06816019632850052, 0.013981578734051389, 0.07165559101201337, 0.22061272033170126, 0.14707514688780085, 0.07353757344390043, 0.14707514688780085, 0.07353757344390043, 0.07353757344390043, 0.22061272033170126, 0.23368909392800896, 0.16825614762816646, 0.1776037113852868, 0.0654329462998425, 0.028042691271361074, 0.09347563757120358, 0.14021345635680538, 0.028042691271361074, 0.03739025502848144, 0.03739025502848144, 0.5406510527028022, 0.5439534073528415, 0.25350796313114865, 0.06913853539940418, 0.24198487389791465, 0.13251552618219134, 0.06913853539940418, 0.06337699078278716, 0.06337699078278716, 0.0403308123163191, 0.0403308123163191, 0.017284633849851044, 0.3939815274650317, 0.3939815274650317, 0.18696555781447888, 0.27552819046344257, 0.11808351019861824, 0.06888204761586064, 0.0984029251655152, 0.05904175509930912, 0.02952087754965456, 0.06888204761586064, 0.039361170066206076, 0.06888204761586064, 0.17520313681432292, 0.35040627362864585, 0.17520313681432292, 0.17520313681432292, 0.3888739489784594, 0.12152310905576856, 0.11457893139543894, 0.03472088830164816, 0.07291386543346114, 0.05381737686755465, 0.07117782101837873, 0.029512755056400938, 0.0642336433580491, 0.04687319920722502, 0.2842392125208603, 0.1863863688661379, 0.11765639534674956, 0.05009133663277456, 0.0978528436547224, 0.05475099585442801, 0.07921420676810861, 0.051256251438187926, 0.03261761455157414, 0.04543167741112111, 0.3866980634456321, 0.09979304863113088, 0.12162277801919075, 0.08108185201279383, 0.07484478647334815, 0.06548918816417963, 0.040540926006396916, 0.053015057085288274, 0.03430386046695124, 0.040540926006396916, 0.35718828916351303, 0.35799128213359027, 0.08591790771206166, 0.11455721028274889, 0.06443843078404625, 0.07159825642671805, 0.05727860514137444, 0.06443843078404625, 0.05727860514137444, 0.07159825642671805, 0.07159825642671805, 0.2318492087478268, 0.0579623021869567, 0.0579623021869567, 0.0579623021869567, 0.08694345328043505, 0.02898115109347835, 0.2318492087478268, 0.0579623021869567, 0.0579623021869567, 0.08694345328043505, 0.2341098432368453, 0.11705492161842265, 0.11705492161842265, 0.11705492161842265, 0.11705492161842265, 0.11705492161842265, 0.2341098432368453, 0.11705492161842265, 0.1489468530835809, 0.09929790205572062, 0.19859580411144123, 0.04964895102786031, 0.1489468530835809, 0.04964895102786031, 0.04964895102786031, 0.09929790205572062, 0.04964895102786031, 0.04964895102786031, 0.09880054288802798, 0.09880054288802798, 0.19760108577605595, 0.09880054288802798, 0.19760108577605595, 0.09880054288802798, 0.09880054288802798, 0.09880054288802798, 0.5411242546471715, 0.32754924460584517, 0.16377462230292258, 0.08188731115146129, 0.08188731115146129, 0.08188731115146129, 0.08188731115146129, 0.08188731115146129, 0.1266186465761108, 0.1266186465761108, 0.2110310776268513, 0.08441243105074053, 0.042206215525370266, 0.08441243105074053, 0.2532372931522216, 0.042206215525370266, 0.042206215525370266, 0.042206215525370266, 0.19813885441322296, 0.19813885441322296, 0.19813885441322296, 0.19813885441322296, 0.20204563577999132, 0.17014369328841375, 0.14887573162736203, 0.06380388498315515, 0.08507184664420687, 0.09570582747473273, 0.11697378913578445, 0.03190194249157757, 0.053169904152629295, 0.04253592332210344, 0.4068709756537487, 0.060480820705286965, 0.12096164141057393, 0.09347035927180712, 0.060480820705286965, 0.07697558998854705, 0.054982564277533605, 0.01649476928326008, 0.07697558998854705, 0.03298953856652016, 0.362198661993308, 0.362198661993308, 0.30292813406219726, 0.13431719151814406, 0.10573906566321979, 0.0743031272228031, 0.08573437756477281, 0.11145469083420464, 0.04572500136787883, 0.06572968946632582, 0.04000937619689398, 0.0314359384404167, 0.1163779643805335, 0.1163779643805335, 0.1163779643805335, 0.1163779643805335, 0.232755928761067, 0.1163779643805335, 0.1163779643805335, 0.1163779643805335, 0.09195439569962063, 0.09195439569962063, 0.18390879139924127, 0.09195439569962063, 0.18390879139924127, 0.09195439569962063, 0.09195439569962063, 0.09195439569962063, 0.3149830777939478, 0.08348949049960061, 0.15938902731741936, 0.06830958313603687, 0.07589953681781875, 0.1024643747040553, 0.0721045599769278, 0.034154791568018435, 0.034154791568018435, 0.05692465261336405, 0.518439296308565, 0.09148928758386442, 0.1219857167784859, 0.06099285838924295, 0.06099285838924295, 0.06099285838924295, 0.030496429194621474, 0.030496429194621474, 0.06099285838924295, 0.030496429194621474, 0.2383438097753399, 0.09533752391013596, 0.09533752391013596, 0.19067504782027192, 0.14300628586520395, 0.09533752391013596, 0.04766876195506798, 0.15218389310495922, 0.30436778620991845, 0.15218389310495922, 0.15218389310495922, 0.15218389310495922, 0.12302348615897288, 0.12302348615897288, 0.1845352292384593, 0.12302348615897288, 0.06151174307948644, 0.06151174307948644, 0.1845352292384593, 0.06151174307948644, 0.06151174307948644, 0.3111114895228021, 0.16296316117861065, 0.11851866267535319, 0.07407416417209574, 0.029629665668838297, 0.05925933133767659, 0.04444449850325745, 0.04444449850325745, 0.05925933133767659, 0.0888889970065149, 0.2945311756225494, 0.11220235261811404, 0.1262276466953783, 0.10518970557948192, 0.06311382334768915, 0.0771391174249534, 0.07012647038632128, 0.04207588223179277, 0.07012647038632128, 0.04908852927042489, 0.26823594532246475, 0.2269688768113163, 0.08941198177415491, 0.0687784475185807, 0.08253413702229684, 0.0687784475185807, 0.07565629227043877, 0.03438922375929035, 0.04126706851114842, 0.04814491326300649, 0.5413585294220887, 0.18045284314069623, 0.09022642157034812, 0.376203720874752, 0.13101436646595263, 0.13101436646595263, 0.13101436646595263, 0.13101436646595263, 0.26202873293190526, 0.13101436646595263, 0.2782401752154686, 0.18549345014364577, 0.09274672507182288, 0.09274672507182288, 0.09274672507182288, 0.09274672507182288, 0.09274672507182288, 0.09274672507182288, 0.24770512051386692, 0.1274952826174315, 0.19306428510639628, 0.11292439317543934, 0.07285444720996086, 0.050998113046972604, 0.05828355776796869, 0.054640835407470646, 0.04371266832597652, 0.04371266832597652, 0.29824479170936435, 0.27934139310176936, 0.1441762028912358, 0.15318721557193804, 0.09011012680702238, 0.09611746859415721, 0.07509177233918532, 0.04505506340351119, 0.048058734297078604, 0.027033038042106713, 0.03904772161637636, 0.27052400024481943, 0.27052400024481943, 0.19465673887861304, 0.19465673887861304, 0.19465673887861304, 0.20448663787775415, 0.17302715512733044, 0.09437844825127115, 0.06291896550084743, 0.09437844825127115, 0.03145948275042371, 0.06291896550084743, 0.1415676723769067, 0.015729741375211857, 0.09437844825127115, 0.24035569612739213, 0.13363776704683003, 0.14902053159898312, 0.08460520503684203, 0.09421943288193772, 0.10575650629605254, 0.050955407579007135, 0.04710971644096886, 0.04710971644096886, 0.04710971644096886, 0.5370048228688888, 0.2660264715189657, 0.2660264715189657, 0.19829997782866246, 0.33794784953898815, 0.06703097842095633, 0.09496055276302146, 0.033515489210478165, 0.10892533993405402, 0.04748027638151073, 0.07261689328936935, 0.011171829736826054, 0.027929574342065135, 0.2836920722736002, 0.18912804818240014, 0.1418460361368001, 0.09456402409120007, 0.047282012045600036, 0.047282012045600036, 0.047282012045600036, 0.047282012045600036, 0.09456402409120007, 0.08217912108366654, 0.15066172198672198, 0.09587564126427763, 0.08217912108366654, 0.10957216144488872, 0.02739304036122218, 0.05478608072244436, 0.2602338834316107, 0.01369652018061109, 0.12326868162549981, 0.23415797319741868, 0.04683159463948374, 0.28098956783690243, 0.14049478391845122, 0.04683159463948374, 0.09366318927896748, 0.04683159463948374, 0.04683159463948374, 0.04683159463948374, 0.2833893076462525, 0.09446310254875083, 0.2833893076462525, 0.09446310254875083, 0.09446310254875083, 0.09446310254875083, 0.19778820320140578, 0.19778820320140578, 0.3293005929513468, 0.13204627737157965, 0.09944225826748591, 0.08314024871543904, 0.0896610525362578, 0.08151004776023435, 0.05216643056654999, 0.04727582770093593, 0.035864421014503114, 0.0505362296113453, 0.2034551528697097, 0.2034551528697097, 0.2034551528697097, 0.2034551528697097, 0.25407289212096246, 0.10162915684838499, 0.15752519311499674, 0.12703644606048123, 0.07622186763628874, 0.08130332547870799, 0.06097749410903099, 0.04065166273935399, 0.06605895195145024, 0.03557020489693474, 0.23246073245829918, 0.08940797402242276, 0.21457913765381462, 0.16093435324036096, 0.08940797402242276, 0.08940797402242276, 0.035763189608969105, 0.035763189608969105, 0.035763189608969105, 0.017881594804484553, 0.16837176761876343, 0.16837176761876343, 0.16837176761876343, 0.16837176761876343, 0.2154474983056165, 0.07181583276853883, 0.2154474983056165, 0.07181583276853883, 0.14363166553707765, 0.047877221845692555, 0.11969305461423138, 0.023938610922846278, 0.023938610922846278, 0.07181583276853883, 0.2681442189051332, 0.14112853626585958, 0.16935424351903147, 0.056451414506343826, 0.14112853626585958, 0.07056426813292979, 0.04233856087975787, 0.04233856087975787, 0.028225707253171913, 0.04233856087975787, 0.23909508739183843, 0.1530208559307766, 0.21518557865265459, 0.10520183845240891, 0.057382820974041224, 0.057382820974041224, 0.052600919226204454, 0.03347331223485738, 0.04303711573053092, 0.04303711573053092, 0.37843112220667136, 0.11987569709652322, 0.1386797280136249, 0.06581410820985589, 0.05876259661594276, 0.07756662753304444, 0.03525755796956566, 0.03525755796956566, 0.04701007729275421, 0.03995856569884108, 0.5323795087183237, 0.32378447184063314, 0.12564770549039495, 0.164308537948978, 0.07490536288850468, 0.07973796694582756, 0.07007275883118179, 0.04590973854456738, 0.03382822840126018, 0.048326040573228826, 0.03382822840126018, 0.26240625714541643, 0.10933594047725685, 0.19680469285906232, 0.17493750476361095, 0.043734376190902736, 0.08746875238180547, 0.043734376190902736, 0.021867188095451368, 0.043734376190902736, 0.043734376190902736, 0.2611095830810813, 0.11190410703474912, 0.16785616055212368, 0.16785616055212368, 0.11190410703474912, 0.05595205351737456, 0.03730136901158304, 0.01865068450579152, 0.03730136901158304, 0.03730136901158304, 0.26142877140855303, 0.3267859642606913, 0.06535719285213826, 0.06535719285213826, 0.06535719285213826, 0.06535719285213826, 0.06535719285213826, 0.06535719285213826, 0.14832405862511977, 0.29664811725023954, 0.14832405862511977, 0.14832405862511977, 0.14832405862511977, 0.1943956032688328, 0.0971978016344164, 0.1457967024516246, 0.0971978016344164, 0.0485989008172082, 0.0971978016344164, 0.1943956032688328, 0.0971978016344164, 0.0485989008172082, 0.0485989008172082, 0.21069039635242234, 0.08938380451314887, 0.17876760902629774, 0.08938380451314887, 0.14684482170017316, 0.12130659183927346, 0.051076459721799354, 0.031922787326124594, 0.06384557465224919, 0.019153672395674757, 0.551385026385419, 0.18379500879513966, 0.17854430583375597, 0.15753909338272587, 0.22055473073581622, 0.1470364871572108, 0.0735182435786054, 0.04201042490206023, 0.031507818676545174, 0.04201042490206023, 0.04201042490206023, 0.08402084980412046, 0.2959385844947306, 0.2226864596197973, 0.09962288982990931, 0.09376271983991465, 0.05860169989994665, 0.06446186988994132, 0.04688135991995732, 0.04102118992996266, 0.04395127492495999, 0.035161019939967994, 0.3967990650570444, 0.3458382507560994, 0.14612883834764764, 0.12583316635491879, 0.07955903421149704, 0.059263362218768205, 0.05845153533905905, 0.04952143966225837, 0.04383865150429429, 0.033284902068075294, 0.05845153533905905, 0.29155532086365665, 0.16731868929288887, 0.13325380644283963, 0.08816793208248036, 0.06712785738097936, 0.06812976570009846, 0.05410304923243113, 0.05410304923243113, 0.039074424445644705, 0.037070607807406515, 0.15707438477623595, 0.12565950782098878, 0.15707438477623595, 0.12565950782098878, 0.15707438477623595, 0.07853719238811797, 0.07853719238811797, 0.031414876955247195, 0.031414876955247195, 0.047122315432870786, 0.2650168672422105, 0.13370220329336746, 0.1504149787050384, 0.09072649509192793, 0.062076022957634897, 0.09072649509192793, 0.057300944268586056, 0.0501383262350128, 0.04775078689048838, 0.05252586557953722, 0.16715683980097454, 0.13372547184077963, 0.20058820776116945, 0.06686273592038981, 0.033431367960194906, 0.20058820776116945, 0.033431367960194906, 0.06686273592038981, 0.06686273592038981, 0.033431367960194906, 0.3643636686315516, 0.3643636686315516, 0.5381983003407524, 0.14583464517375855, 0.14583464517375855, 0.14583464517375855, 0.14583464517375855, 0.14583464517375855, 0.14583464517375855, 0.14583464517375855, 0.23008536161044058, 0.11504268080522029, 0.11504268080522029, 0.11504268080522029, 0.23008536161044058, 0.11504268080522029, 0.11504268080522029, 0.28865759047783646, 0.12929454573486424, 0.12328084593324265, 0.09922604672675628, 0.06314384791702672, 0.08719864712351309, 0.06013699801621593, 0.051116448313783536, 0.05713014811540513, 0.04209589861135115, 0.24820476572674827, 0.0827349219089161, 0.0827349219089161, 0.0827349219089161, 0.0827349219089161, 0.0827349219089161, 0.0827349219089161, 0.1654698438178322, 0.0827349219089161, 0.0827349219089161, 0.13161323341172926, 0.1974198501175939, 0.13161323341172926, 0.13161323341172926, 0.1974198501175939, 0.06580661670586463, 0.06580661670586463, 0.06580661670586463, 0.06580661670586463, 0.5375893326454911, 0.3272051105961128, 0.15782834746400737, 0.09238732534478479, 0.0692904940085886, 0.06544102211922256, 0.06159155022985653, 0.06544102211922256, 0.09623679723415082, 0.02694630322556223, 0.030795775114928266, 0.3203252683111704, 0.11801457253569436, 0.12042303319968813, 0.0770707412478004, 0.0578030559358503, 0.09152150523176297, 0.06502843792783158, 0.06743689859182535, 0.045760752615881486, 0.0385353706239002, 0.08641017442614822, 0.08641017442614822, 0.17282034885229644, 0.08641017442614822, 0.17282034885229644, 0.08641017442614822, 0.17282034885229644, 0.08641017442614822, 0.22363446026491698, 0.09584334011353585, 0.12779112015138114, 0.06389556007569057, 0.06389556007569057, 0.1597389001892264, 0.06389556007569057, 0.031947780037845284, 0.06389556007569057, 0.09584334011353585, 0.3392908093601108, 0.13049646513850416, 0.0782978790831025, 0.10439717211080334, 0.05219858605540167, 0.0782978790831025, 0.0782978790831025, 0.026099293027700834, 0.05219858605540167, 0.10439717211080334, 0.28656951090846045, 0.1440592676458747, 0.12392195066311802, 0.07435317039787082, 0.07125512163129287, 0.04956878026524721, 0.08519634108089365, 0.09603951176391647, 0.024784390132623606, 0.04492170711538029, 0.2904451036206547, 0.2904451036206547, 0.21189246072334073, 0.42378492144668145, 0.21189246072334073, 0.2747438331897872, 0.16832896822191185, 0.15865488958846863, 0.06384891898072519, 0.07739262906754568, 0.07158818188747976, 0.06384891898072519, 0.044500761713838766, 0.036761498807084195, 0.04256594598715012, 0.13907112977545738, 0.18542817303394316, 0.16224965140470027, 0.09271408651697158, 0.034767782443864345, 0.06953556488772869, 0.23178521629242896, 0.023178521629242894, 0.034767782443864345, 0.023178521629242894, 0.23996842935357873, 0.23996842935357873, 0.23996842935357873, 0.23996842935357873, 0.14803450077071073, 0.14803450077071073, 0.14803450077071073, 0.14803450077071073, 0.29606900154142146, 0.44426682850897936, 0.22213341425448968, 0.27347733814494, 0.27347733814494, 0.27347733814494, 0.10562895019409833, 0.1320361877426229, 0.21125790038819667, 0.07922171264557375, 0.05281447509704917, 0.18485066283967208, 0.05281447509704917, 0.07922171264557375, 0.07922171264557375, 0.026407237548524583, 0.4959947415891438, 0.08383009716999613, 0.10478762146249516, 0.05588673144666409, 0.06985841430833012, 0.04191504858499807, 0.04191504858499807, 0.05588673144666409, 0.027943365723332045, 0.027943365723332045, 0.16632891428521618, 0.16632891428521618, 0.16632891428521618, 0.08316445714260809, 0.16632891428521618, 0.16632891428521618, 0.08316445714260809, 0.2373430312904948, 0.11379460404338791, 0.19832773847561894, 0.11054332964214826, 0.04551784161735516, 0.09753823203718964, 0.05527166482107413, 0.0715280368272724, 0.04226656721611551, 0.032512744012396545, 0.5410677652480866, 0.18035592174936219, 0.045088980437340546, 0.09017796087468109, 0.045088980437340546, 0.045088980437340546, 0.045088980437340546, 0.5098072527255934, 0.0991291880299765, 0.05664525030284371, 0.028322625151421855, 0.05664525030284371, 0.028322625151421855, 0.042483937727132784, 0.14161312575710927, 0.028322625151421855, 0.014161312575710927, 0.5075221346649443, 0.1335584564907748, 0.053423382596309923, 0.053423382596309923, 0.053423382596309923, 0.026711691298154962, 0.026711691298154962, 0.10684676519261985, 0.026711691298154962, 0.026711691298154962, 0.2716586066733527, 0.13305727673796866, 0.13860132993538402, 0.09424890435606113, 0.07761674476381504, 0.07207269156639969, 0.055440531974153606, 0.033264319184492165, 0.049896478776738244, 0.07207269156639969, 0.2882906859968679, 0.3069736168002054, 0.13156012148580232, 0.16767466463876768, 0.07738830675635432, 0.08770674765720156, 0.06964947608071888, 0.056751424954659825, 0.028375712477329913, 0.04127376360338897, 0.030955322702541723, 0.28870411471817115, 0.14219754904029325, 0.11203443257720075, 0.13357951576512397, 0.1077254159396161, 0.04739918301343109, 0.06894426620135431, 0.03016311646309251, 0.03016311646309251, 0.034472133100677156, 0.49912622057574507, 0.11744146366488119, 0.058720731832440594, 0.058720731832440594, 0.058720731832440594, 0.029360365916220297, 0.058720731832440594, 0.058720731832440594, 0.029360365916220297, 0.029360365916220297, 0.27115115795771094, 0.15733462251867178, 0.13055426123889785, 0.09373126447920872, 0.1004263547991522, 0.07699353867935002, 0.05356072255954784, 0.05356072255954784, 0.0334754515997174, 0.03682299675968914, 0.14722201387930242, 0.14722201387930242, 0.14722201387930242, 0.14722201387930242, 0.14722201387930242, 0.14722201387930242, 0.2622150403528614, 0.19311783377339117, 0.17185715482586186, 0.06023859035133303, 0.07264065307072512, 0.07618409956198001, 0.038977911403803724, 0.030119295175666513, 0.06378203684258792, 0.02657584868441163, 0.22445986188626096, 0.10807326683412564, 0.22445986188626096, 0.11638659505213532, 0.08313328218009665, 0.08313328218009665, 0.04987996930805799, 0.024939984654028996, 0.04987996930805799, 0.041566641090048324, 0.27064804844121026, 0.09021601614707009, 0.13532402422060513, 0.11277002018383761, 0.13532402422060513, 0.13532402422060513, 0.022554004036767522, 0.045108008073535044, 0.022554004036767522, 0.022554004036767522, 0.34145631639222723, 0.11807367950011596, 0.10211777686496516, 0.06063243001357306, 0.08297069370278419, 0.07658833264872388, 0.04467652737842226, 0.06382361054060322, 0.06063243001357306, 0.04786770790545242, 0.4339690863340365, 0.5363374538608798, 0.5475774307747997, 0.2570919146564607, 0.12854595732823035, 0.07712757439693821, 0.07712757439693821, 0.07712757439693821, 0.07712757439693821, 0.10283676586258428, 0.05141838293129214, 0.07712757439693821, 0.05141838293129214, 0.24835209429443939, 0.16556806286295958, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.08278403143147979, 0.26640611038314366, 0.15594504022427924, 0.1873506386027799, 0.07472366510746713, 0.0758066167756913, 0.04656692173363894, 0.067143003429898, 0.0476498734018631, 0.044401018397190614, 0.035737405051397324, 0.16033427007349405, 0.10688951338232935, 0.2137790267646587, 0.10688951338232935, 0.10688951338232935, 0.05344475669116468, 0.05344475669116468, 0.05344475669116468, 0.10688951338232935, 0.05344475669116468, 0.15204255178366616, 0.15204255178366616, 0.07602127589183308, 0.07602127589183308, 0.07602127589183308, 0.07602127589183308, 0.15204255178366616, 0.15204255178366616, 0.3952002279604857, 0.25607927443827583, 0.10926049042699768, 0.1673051259663402, 0.09560292912362298, 0.11267488075284136, 0.105846100101154, 0.044387074235967806, 0.034143903258436775, 0.044387074235967806, 0.030729512932593097, 0.39158101625888914, 0.08520512853781384, 0.15953300662399186, 0.08157937838726857, 0.05801200240872431, 0.061637752559269586, 0.05257337718290641, 0.025380251053816888, 0.05619912733345168, 0.030818876279634793, 0.36901026384800106, 0.2724904801981438, 0.2724904801981438, 0.176767030887065, 0.176767030887065, 0.176767030887065, 0.176767030887065, 0.2977707180907314, 0.1488853590453657, 0.1488853590453657, 0.1488853590453657, 0.1488853590453657, 0.3954173201624602, 0.3954173201624602, 0.3223427927969954, 0.3223427927969954, 0.34854205175329434, 0.10299497296121561, 0.10299497296121561, 0.20598994592243122, 0.20598994592243122, 0.10299497296121561, 0.10299497296121561, 0.10299497296121561, 0.13025773632851437, 0.13025773632851437, 0.13025773632851437, 0.13025773632851437, 0.13025773632851437, 0.13025773632851437, 0.23084450015728425, 0.23084450015728425, 0.23084450015728425, 0.23084450015728425, 0.5359928178051733, 0.2424915261359492, 0.1212457630679746, 0.1212457630679746, 0.2424915261359492, 0.1212457630679746, 0.1212457630679746, 0.19423916184750492, 0.09711958092375246, 0.09711958092375246, 0.19423916184750492, 0.09711958092375246, 0.09711958092375246, 0.3010293604568569, 0.1481255583200407, 0.1337908268697142, 0.0764519010684081, 0.04778243816775507, 0.08123014488518361, 0.05733892580130608, 0.04778243816775507, 0.04300419435097956, 0.062117169618081586, 0.3334157206789377, 0.1255022018064499, 0.1492021884136765, 0.07810222859199671, 0.07917950071050701, 0.059788602577321624, 0.05170906168849438, 0.038243160207115635, 0.04632270109594288, 0.03878179626637078, 0.307658079357992, 0.153829039678996, 0.13124863018483143, 0.0903216379766582, 0.07056377966926422, 0.06774122848249364, 0.043749543394943816, 0.04939464576848495, 0.03951571661478796, 0.0451608189883291, 0.3002705938287525, 0.07741351247147525, 0.13606011282865346, 0.08914283254291089, 0.05630073634289109, 0.06333832838575247, 0.06803005641432673, 0.08210524050004951, 0.08679696852862376, 0.042225552257168314, 0.35715476285514386, 0.22835975997215083, 0.3425396399582263, 0.11417987998607541, 0.11417987998607541, 0.11417987998607541, 0.11417987998607541, 0.11417987998607541, 0.28478773257811574, 0.1594811302437448, 0.13441980977687062, 0.09568867814624689, 0.08429716884312226, 0.07290565953999763, 0.043287735351873594, 0.036452829769998814, 0.036452829769998814, 0.050122640933748366, 0.2942005485859536, 0.2942005485859536, 0.22604525218506266, 0.13562715131103759, 0.04520905043701253, 0.09041810087402506, 0.09041810087402506, 0.09041810087402506, 0.04520905043701253, 0.13562715131103759, 0.09041810087402506, 0.04520905043701253, 0.19064057093830084, 0.09532028546915042, 0.19064057093830084, 0.09532028546915042, 0.09532028546915042, 0.09532028546915042, 0.09532028546915042, 0.23266680323594122, 0.07755560107864706, 0.15511120215729413, 0.11633340161797061, 0.15511120215729413, 0.11633340161797061, 0.03877780053932353, 0.03877780053932353, 0.07755560107864706, 0.296372604842535, 0.1573054594933455, 0.155025670225326, 0.0889117814527605, 0.072953256576624, 0.06611388877256551, 0.034196839020292503, 0.0478755746284095, 0.04559578536039, 0.0387564175563315, 0.24865614777028874, 0.04144269129504812, 0.08288538259009624, 0.08288538259009624, 0.12432807388514437, 0.08288538259009624, 0.04144269129504812, 0.1657707651801925, 0.04144269129504812, 0.04144269129504812, 0.4215624733994928, 0.4215624733994928, 0.26678292676884313, 0.1212649667131105, 0.10004359753831617, 0.1394547117200771, 0.07275898002786631, 0.09094872503483288, 0.07882222836352183, 0.0485059866852442, 0.036379490013933154, 0.0485059866852442, 0.17760311893369743, 0.17760311893369743, 0.17760311893369743, 0.17760311893369743, 0.12246956871623353, 0.24493913743246706, 0.12246956871623353, 0.12246956871623353, 0.12246956871623353, 0.24493913743246706, 0.2360613459505453, 0.2360613459505453, 0.2360613459505453], \"Term\": [\"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"abstraction\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"acquire\", \"acquire\", \"acquire\", \"acquire\", \"acquire\", \"acquire\", \"acquire\", \"acquire\", \"acrobot\", \"acrobot\", \"acrobot\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"actuator\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amari\", \"amari\", \"amari\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"ant\", \"antecedent\", \"antecedent\", \"antecedent\", \"antecedent\", \"apparent\", \"apparent\", \"apparent\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximator\", \"approximator\", \"approximator\", \"approximator\", \"approximator\", \"approximator\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"asset\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"atom\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"auction\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"averaging\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bass\", \"bass\", \"bass\", \"bass\", \"bass\", \"bass\", \"bass\", \"bass\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"binarize\", \"binarize\", \"binarize\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"binary\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"biosift\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint\", \"blueprint_strategy\", \"blueprint_strategy\", \"blueprint_strategy\", \"blueprint_strategy\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brightness\", \"brightness\", \"brightness\", \"brightness\", \"brightness\", \"brightness\", \"brnn\", \"brnn\", \"brnn\", \"brnn\", \"brnn\", \"brnn\", \"bucket\", \"bucket\", \"bucket\", \"bundle\", \"bundle\", \"bundle\", \"bundle\", \"burgard\", \"cable\", \"cancer\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cbv\", \"cbv\", \"cbv\", \"cbv\", \"cbv\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"centralized\", \"centralized\", \"centralized\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chaos\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chunk\", \"chunk\", \"chunk\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"clause\", \"closure\", \"closure\", \"closure\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword_bit\", \"codeword_bit\", \"coin\", \"coin\", \"coin\", \"coin\", \"coin\", \"colorization\", \"colorization\", \"colorization\", \"colorization\", \"colorization\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compare\", \"compatible\", \"compatible\", \"compatible\", \"compatible\", \"compatible\", \"compatible\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"competition\", \"composite_action\", \"composite_action\", \"composite_action\", \"composite_action\", \"composite_action\", \"composite_action\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"conditional_densitie\", \"conditional_densitie\", \"conditional_densitie\", \"conditional_densitie\", \"conditional_densitie\", \"conditional_densitie\", \"conditional_densitie\", \"consequent\", \"consequent\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constituent\", \"constituent\", \"consumption\", \"consumption\", \"consumption\", \"consumption\", \"consumption\", \"consumption\", \"contextual_semibandit\", \"contextual_semibandit\", \"contextual_semibandit\", \"contextual_semibandit\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolve\", \"convolve\", \"convolve\", \"convolve\", \"convolve\", \"convolve\", \"cooditioo\", \"cooditioo\", \"cooditioo\", \"cooditioo\", \"cooditioo\", \"cooperative\", \"cooperative\", \"coordination\", \"coordination\", \"coordination\", \"coordination\", \"coordination\", \"corouary\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"covariant\", \"covariant\", \"covariant\", \"cv\", \"cv\", \"cv\", \"cv\", \"cv\", \"cvae_gan\", \"cvae_gan\", \"cvae_gan\", \"cvae_gan\", \"cvae_gan\", \"cvae_gan\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cvpr\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"dashed_line\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"dax\", \"dax\", \"dax\", \"dax\", \"dax\", \"ddp\", \"ddp\", \"ddp\", \"ddp\", \"ddp\", \"ddp\", \"ddp\", \"declarative\", \"declarative\", \"decod\", \"decod\", \"decod\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"definite\", \"deform\", \"deform\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"deletion\", \"deletion\", \"deletion\", \"dene\", \"dene\", \"dene\", \"dene\", \"dene\", \"dene\", \"dene\", \"density_parity\", \"density_parity\", \"density_parity\", \"density_parity\", \"designer\", \"designer\", \"designer\", \"designer\", \"designer\", \"designer\", \"designer\", \"designer\", \"diagnosis\", \"diagnosis\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"dislike\", \"dislike\", \"disneyland\", \"disneyland\", \"disneyland\", \"disorder\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"diversity\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"drastic\", \"drastic\", \"drastic\", \"dss\", \"dss\", \"eager\", \"eager\", \"earn\", \"earn\", \"earn\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"ediss\", \"ediss\", \"ediss\", \"eel\", \"eel\", \"eel\", \"eel\", \"eel\", \"effector\", \"effector\", \"emission\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entity\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"entropy\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"ergodic\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"escort\", \"escort\", \"escort\", \"escort\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"evening\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"evolve\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experimoot\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exploitability\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"facade\", \"facade\", \"facade\", \"facade\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factored\", \"fake\", \"fake\", \"fake\", \"fake\", \"fake\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"finger\", \"finger\", \"finger\", \"finger\", \"finger\", \"finger\", \"fingertip\", \"fir\", \"fir\", \"fir\", \"fir\", \"fir\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"fmo\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forage\", \"forwardbackward\", \"forwardbackward\", \"fuel\", \"fuel\", \"fuel\", \"fuel\", \"fuel\", \"fuel\", \"fuel\", \"fuel\", \"fully_observable\", \"fully_observable\", \"fully_observable\", \"fun\", \"fun\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gan\", \"gan\", \"gan\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gbm\", \"gbm\", \"gbm\", \"gbm\", \"gbm\", \"generative_adversarial\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"gesture\", \"gesture\", \"gesture\", \"gesture\", \"gesture\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gibb\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"gift\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph_cover\", \"graph_cover\", \"graph_cover\", \"graph_cover\", \"graph_cover\", \"greatest\", \"hamming_code\", \"hamming_code\", \"hard_thresholde\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"hash\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hoete\", \"holdem\", \"homomorphism\", \"host\", \"host\", \"host\", \"housing\", \"housing\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"hub\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hurt\", \"hurt\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"identify\", \"ihmm\", \"ihmm\", \"iir\", \"iir\", \"iir\", \"iir\", \"iir\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imperfect_information\", \"imperfect_information\", \"imperfect_information\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"improve\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independence\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"independent\", \"infant\", \"infant\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"infoset\", \"infoset\", \"infoset\", \"infoset\", \"infoset\", \"infoset\", \"infoset\", \"inject\", \"inject\", \"inject\", \"inject\", \"inject\", \"inject\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"insect\", \"insect\", \"insect\", \"insect\", \"insect\", \"insect\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instantaneous_effect\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"intent\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"internal\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"investor\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"ketch\", \"ketch\", \"keyword\", \"keyword\", \"keyword\", \"keyword\", \"keyword\", \"keyword\", \"keyword\", \"keyword\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"knowledge_compilation\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lazy\", \"lbr\", \"lbr\", \"leap\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"lma\", \"lma\", \"lma\", \"lma\", \"lma\", \"lma\", \"lma\", \"lma\", \"lma\", \"lock\", \"lock\", \"lock\", \"lock\", \"lock\", \"lock\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logic\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"logical_variable\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lsh\", \"lsh\", \"lsh\", \"lsh\", \"lung\", \"lvae\", \"lvae\", \"lvae\", \"lvae\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"markov\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"mdlstm\", \"mdlstm\", \"mdlstm\", \"mdlstm\", \"mdlstm\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mdp\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measuremoot\", \"measuremoot\", \"measuremoot\", \"measuremoot\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"meinshausen\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"merge\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"microstate\", \"microstate\", \"minimise\", \"minimise\", \"minimise\", \"minimise\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"modal\", \"modal\", \"modal\", \"modal\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"mvu\", \"mvu\", \"mvu\", \"mvu\", \"mvu\", \"mvu\", \"mvu\", \"mvu\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"negative\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"night\", \"night\", \"night\", \"night\", \"night\", \"night\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"nondescendant\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"note\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nystrm\", \"nystrm\", \"nystrm\", \"nystrm\", \"nystrm\", \"objective_return\", \"objective_return\", \"objective_return\", \"objective_return\", \"objective_return\", \"objective_return\", \"objective_return\", \"objective_return\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"olpomdp\", \"olpomdp\", \"olpomdp\", \"olpomdp\", \"olpomdp\", \"olpomdp\", \"olpomdp\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"ompr\", \"onset\", \"onset\", \"opper\", \"opper\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"opponent\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"oracle\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ordinate\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"orthonormal\", \"ot\", \"outgoing\", \"outgoing\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"outputting_summary\", \"outputting_summary\", \"overestimation\", \"overestimation\", \"overestimation\", \"overestimation\", \"overestimation\", \"overestimation\", \"painting\", \"painting\", \"painting\", \"painting\", \"painting\", \"painting\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parity_check\", \"parity_check\", \"paritycheck\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"particle\", \"passive\", \"passive\", \"passive\", \"passive\", \"passive\", \"passive\", \"passive\", \"passive\", \"patent\", \"patent\", \"patent\", \"patient\", \"patient\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"permute\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pgrd\", \"pittsburgh\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"planner\", \"planner\", \"planner\", \"planner\", \"planner\", \"planner\", \"planner\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"pmin\", \"pmin\", \"pmin\", \"pmin\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"poker\", \"poker\", \"poker\", \"poker\", \"poker\", \"poker\", \"poker\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population_wide\", \"postoperative\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prescribe\", \"prescribe\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"pricing\", \"pricing\", \"pricing\", \"pricing\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"prognosis\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propositional\", \"propositional\", \"propositional\", \"propositional\", \"propositional\", \"propositional\", \"propositional\", \"propositional\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"psd\", \"psd\", \"psd\", \"psd\", \"psd\", \"psd\", \"psd\", \"psd\", \"pth\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"pursuit\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qld\", \"qlds\", \"qlds\", \"qlds\", \"qlds\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"quadratic\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"query\", \"rail\", \"rail\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rank_psd\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"rbm\", \"realism\", \"realism\", \"realism\", \"realism\", \"realism\", \"realism\", \"realism\", \"recency\", \"recency\", \"recency\", \"recency\", \"recency\", \"recording\", \"recording\", \"recording\", \"recording\", \"recording\", \"recording\", \"recording\", \"recording\", \"recording\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regularization_constant\", \"regularization_constant\", \"regularization_constant\", \"reinstate\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"replacement\", \"replacement\", \"replacement\", \"replacement\", \"replacement\", \"replacement\", \"replacement\", \"replacement\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"request\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"require\", \"residnal\", \"residnal\", \"resonance\", \"resonance\", \"resonance\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"reversal\", \"revolution\", \"revolution\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"rip\", \"rip\", \"rip\", \"rip\", \"rip\", \"rip\", \"rip\", \"rip\", \"rip\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"roi\", \"roi\", \"roi\", \"roi\", \"roi\", \"roi\", \"roi\", \"roi\", \"roi\", \"rois\", \"rois\", \"rois\", \"rois\", \"rois\", \"rois\", \"root_binding\", \"root_binding\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"samuelide\", \"samuelide\", \"samuelide\", \"samuelide\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"schatten_norm\", \"schatten_norm\", \"schatten_norm\", \"schatten_norm\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"seduce\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit\", \"semibandit_feedback\", \"semibandit_feedback\", \"semibandit_feedback\", \"semibandit_feedback\", \"semibandit_feedback\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"send\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sensory_adaptation\", \"sensory_adaptation\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequential_labelling\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"skl\", \"skl\", \"sl\", \"slave\", \"slave\", \"slave\", \"slave\", \"slave\", \"slave\", \"slave\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"smoke\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"sociability\", \"solar\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"ssft\", \"ssft\", \"ssft\", \"ssft\", \"ssft\", \"ssft\", \"ssft\", \"ssft\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stdp\", \"stdp\", \"steepest_descent\", \"steepest_descent\", \"steepest_descent\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus_drive\", \"stimulus_drive\", \"stimulus_drive\", \"stimulus_drive\", \"stimulus_selectivity\", \"stimulus_selectivity\", \"stimulus_selectivity\", \"stimulus_selectivity\", \"stimulus_selectivity\", \"stochastic_oscillator\", \"stochastic_oscillator\", \"stochasticity\", \"stochasticity\", \"stochasticity\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"streaming\", \"streaming\", \"streaming\", \"streaming\", \"streaming\", \"streaming\", \"streaming\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"subgame_solve\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"supx\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"tail\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"teammate\", \"teammate\", \"teammate\", \"teammate\", \"teammate\", \"teammate\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"thumbnail\", \"thwart\", \"tic\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tight\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"tightness\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"timino\", \"tow\", \"tow\", \"tow\", \"tow\", \"tow\", \"tow\", \"tow\", \"tow\", \"towing\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trigonometric\", \"turbocode\", \"turbocode\", \"turker\", \"turker\", \"turker\", \"turker\", \"twice_continuously\", \"twice_continuously\", \"twice_continuously\", \"twice_continuously\", \"twice_continuously\", \"udell\", \"udell\", \"ukly\", \"ukly\", \"umichedu\", \"unconditional\", \"unconditional\", \"unconditional\", \"unconditional\", \"unconditional\", \"unconditional\", \"unconditional\", \"underestimation\", \"underestimation\", \"underestimation\", \"underestimation\", \"underestimation\", \"underestimation\", \"unmixe\", \"unmixe\", \"unmixe\", \"unmixe\", \"unsealed\", \"untraine\", \"untraine\", \"untraine\", \"untraine\", \"untraine\", \"untraine\", \"untrained\", \"untrained\", \"untrained\", \"untrained\", \"untrained\", \"untrained\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variate\", \"vcee\", \"vcee\", \"vcee\", \"vcee\", \"vcee\", \"vcee\", \"vcee\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"visitation\", \"visitation\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"warp\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"web\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wfomc\", \"wire\", \"wire\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workstation\", \"workstation\", \"workstation\", \"workstation\", \"worm\", \"worm\", \"worm\", \"worm\", \"worm\", \"worm\", \"ystrom\", \"ystrom\", \"ystrom\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 9, 1, 8, 3, 7, 10, 5, 4, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el19181400403553420322638357784\", ldavis_el19181400403553420322638357784_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el19181400403553420322638357784\", ldavis_el19181400403553420322638357784_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el19181400403553420322638357784\", ldavis_el19181400403553420322638357784_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculating Coherence Score:**\n",
        "- Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic.\n",
        "\n",
        "- It calculates how often two words, and appear together in the corpus\n",
        "- Higher the keywords you will have in your topic the lower the coherence will be\n",
        "- Lower the keywords you will have the coherence could be higher"
      ],
      "metadata": {
        "id": "JRZprx4PAoMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import CoherenceModel"
      ],
      "metadata": {
        "id": "jSnJR7qp-4z4"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C73zXnM_CmG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=clean_words_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "# Note: If you have used only clean_words instead of clean_words_lemmatized then use proper words corpus above."
      ],
      "metadata": {
        "id": "a2a_w4pwAcDR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_lda = coherence_model_lda.get_coherence()"
      ],
      "metadata": {
        "id": "alGuRBYRJgCS"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('LDA Model Coherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsUzOEdbAcnH",
        "outputId": "4ad4971a-0f0e-4567-8193-4f17ca85594c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Model Coherence Score:  0.23779943167776732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2nYJu1t-ITMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}