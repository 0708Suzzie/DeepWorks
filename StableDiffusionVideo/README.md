# Stable Diffusion Video - High-Resolution Image Synthesis with Latent Diffusion Models #

Stable Diffusion is a latent text-to-image diffusion model, trained on 512x512 images from a subset of the LAION-5B database. 
Similar to Google's Imagen, this model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts.
With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM. 

Stable Diffusion Video is a python library to generate video from the 2 or more text prompts while applying Stable Diffusion models.

<table class="table table-striped table-bordered table-vcenter">
    <tr>
        <td align="center"><b>ðŸ”¥&nbsp;Stable Diffusion Video:&nbsp; Step by Step guide to generate video with Stable Diffusion Model in Google colab</b></td>
    </tr>
    <tr>
        <td>
            <div>
                
[![Step by Step guide to generate video with Stable Diffusion Model in Google colab](https://img.youtube.com/vi/oDAVk8QFnWg/0.jpg)](https://www.youtube.com/watch?v=oDAVk8QFnWg)

  </tr>
</table>

## Resources:
- https://stability.ai/
- https://github.com/CompVis/stable-diffusion
- https://github.com/nateraw/stable-diffusion-video

## Various other Hugging Face resources
- https://huggingface.co/CompVis/stable-diffusion-v1-4
- https://huggingface.co/spaces/stabilityai/stable-diffusion
- https://beta.dreamstudio.ai/dream
