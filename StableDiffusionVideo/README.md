# Stable Diffusion Video - High-Resolution Image Synthesis with Latent Diffusion Models #

Stable Diffusion Video is a python library to generate video from the 2 or more text prompts while applying Stable Diffusion models.

Stable Diffusion is a latent text-to-image diffusion model, trained on 512x512 images from a subset of the LAION-5B database. 
Similar to Google's Imagen, this model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts.
With its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM. 

<table class="table table-striped table-bordered table-vcenter">
    <tr>
        <td align="center"><b>ðŸ”¥&nbsp;Stable Diffusion Video:&nbsp; Automated video creation with Stable Diffusion AI Models - A Developer Guide</b></td>
    </tr>
    <tr>
        <td>
            <div>
                
[![Automated video creation with Stable Diffusion AI Models - A Developer Guide](https://img.youtube.com/vi/y5E38ajaZyg/0.jpg)](https://www.youtube.com/watch?v=y5E38ajaZyg)

  </tr>
</table>

## Resources:
- https://stability.ai/
- https://github.com/CompVis/stable-diffusion
- https://github.com/nateraw/stable-diffusion-video
- https://huggingface.co/CompVis/stable-diffusion
- https://huggingface.co/CompVis/stable-diffusion-v1-4

## Various other Hugging Face resources
- https://huggingface.co/CompVis/stable-diffusion-v1-4
- https://huggingface.co/spaces/stabilityai/stable-diffusion
- https://beta.dreamstudio.ai/dream
- https://github.com/huggingface/diffusers
- https://github.com/divamgupta/diffusionbee-stable-diffusion-ui

